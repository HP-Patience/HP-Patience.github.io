<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>【提示词工程】LangGPT结构化提示词编写</title>
      <link href="/2024/09/03/%E3%80%90%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E3%80%91LangGPT%E7%BB%93%E6%9E%84%E5%8C%96%E6%8F%90%E7%A4%BA%E8%AF%8D%E7%BC%96%E5%86%99/"/>
      <url>/2024/09/03/%E3%80%90%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E3%80%91LangGPT%E7%BB%93%E6%9E%84%E5%8C%96%E6%8F%90%E7%A4%BA%E8%AF%8D%E7%BC%96%E5%86%99/</url>
      
        <content type="html"><![CDATA[<h1>参考内容：</h1><p>1.LangGPT社区：<a href="https://langgptai.feishu.cn/wiki/QaArwzc7biR5nqkSo3mcwzGfnhf">‌‌‬﻿⁠﻿⁠⁠﻿‌⁠‬‌⁠‍‬⁠‬‬﻿‬‌‌‌‍﻿﻿‌‌﻿‬⁠LangGPT结构化提示词 - 飞书云文档</a><br>2.浦语开源文档<a href="https://github.com/InternLM/Tutorial/tree/camp3/docs/L1/Prompt">书生浦语-浦语提示词工程实践</a><br>3.文档：<a href="https://mp.weixin.qq.com/s/N9BrkDqvkIHQD7TTnhNk6Q">系统论述文章： 构建高性能 Prompt 之路——结构化 Prompt</a></p><hr><h1>步骤</h1><p>step0：前期准备<br>0.1：创建虚拟环境-&gt;激活虚拟环境-&gt;安装必要包文件<br>0.2：创建项目路径-&gt;进入项目<br>0.3：安装必要软件，如tmux</p><p>step1：模型部署模型下载-&gt;部署模型为OpenAI server-&gt;图形化界面调用<br>‬﻿⁠﻿⁠⁠﻿<br>step3：langgpt结构化提示词⁠‬编写⁠‍‬⁠‬‬﻿‬‌‌‌‍﻿﻿‌‌﻿<br>偷懒大法：GPTS有LangGPT提示词专家，用大模型生成即可</p><hr><h1>tmux扫盲</h1><pre><code>tmux可以在终端中创建终端，将进程维持在后台。当我们下载模型时，使用tmux在后台下载，即便我们断开ssh连接，下载也不会中断。</code></pre><p>step1：部署模型为OpenAI server</p><h2 id="tmux常见命令">tmux常见命令</h2><p>1.<strong>创建窗口命令</strong>：</p><p><mark>PS：t表示target(目标)，用于指定会话、窗口或面板的名称</mark></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tmux new -t &lt;session_name&gt;</span><br></pre></td></tr></table></figure><p>PS：创建完成后，运行下面的命令进入新的命令窗口(<mark>首次创建自动进入，之后需要连接</mark>)：其中<code>a</code> 是 <strong><code>attach</code></strong> 的简写</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tmux a -t &lt;session_name&gt;</span><br></pre></td></tr></table></figure><p>2.<strong>查看当前 tmux 会话</strong>：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tmux ls</span><br></pre></td></tr></table></figure><p>3.<strong>连接到特定的 tmux 会话</strong>：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tmux attach -t &lt;session_name&gt;</span><br></pre></td></tr></table></figure><p>将 <code>&lt;session_name&gt;</code> 替换为你要连接的会话的实际名称或编号。</p><p>4.<strong>杀死整个 tmux 会话：</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tmux kill-session -t &lt;session_name&gt;</span><br></pre></td></tr></table></figure><p>5.<strong>退出tmux</strong>:</p><p>Ctrl+B进入<code>tmux</code>的控制模式，然后按d退出窗口连接</p><h2 id="模型部署">模型部署</h2><p>进入命令窗口后，需要在新窗口中再次激活环境，命令参考<strong>0.1节</strong>。然后，使用LMDeploy进行部署，参考如下命令：</p><p>使用LMDeploy进行部署，参考如下命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=0 lmdeploy serve api_server /share/new_models/Shanghai_AI_Laboratory/internlm2-chat-1_8b --server-port 23333 --api-keys internlm2</span><br></pre></td></tr></table></figure><p>更多设置参考：<a href="https://lmdeploy.readthedocs.io/en/latest/index.html">https://lmdeploy.readthedocs.io/en/latest/index.html</a></p><p>部署成功后，可以利用如下脚本调用部署的InternLM2-chat-1_8b模型并测试是否部署成功。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> openai <span class="keyword">import</span> OpenAI</span><br><span class="line"></span><br><span class="line">client = OpenAI(</span><br><span class="line">    api_key = <span class="string">&quot;internlm2&quot;</span>,</span><br><span class="line">    base_url = <span class="string">&quot;http://0.0.0.0:23333/v1&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">response = client.chat.completions.create(</span><br><span class="line">    model=client.models.<span class="built_in">list</span>().data[<span class="number">0</span>].<span class="built_in">id</span>,</span><br><span class="line">    messages=[</span><br><span class="line">        &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;请介绍一下你自己&quot;</span>&#125;</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(response.choices[<span class="number">0</span>].message.content)</span><br></pre></td></tr></table></figure><p>服务启动完成后，可以按Ctrl+B进入<code>tmux</code>的控制模式，然后按D退出窗口连接，更多操作<a href="https://aik9.top/">参考</a>。</p><hr><h1>作业：</h1><p>基础任务 (完成此任务即完成闯关)：</p><ul class="lvl-0"><li class="lvl-2"><p><strong>背景问题</strong>：近期相关研究发现，LLM在对比浮点数字时表现不佳，经验证，internlm2-chat-1.8b (internlm2-chat-7b)也存在这一问题，例如认为<code>13.8&lt;13.11</code>。</p></li><li class="lvl-2"><p><strong>任务要求</strong>：利用LangGPT优化提示词，使LLM输出正确结果。<strong>完成一次并提交截图即可</strong></p></li></ul><p>使用GPTS中LangGPT提示词专家，配合我们的需求生成LangGPT结构化提示词</p><p><img src="1.png" alt=""><br><mark>生成结果如下</mark>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"># Role: 数学助手</span><br><span class="line"></span><br><span class="line">## Profile</span><br><span class="line">- author: LangGPT</span><br><span class="line">- version: 1.0</span><br><span class="line">- language: 中文</span><br><span class="line">- description: 一个能够进行基本数学加减法运算，并能够比较两个数字大小的助手。</span><br><span class="line"></span><br><span class="line">## Skills</span><br><span class="line">1. 能够进行基本的数学加法和减法运算。</span><br><span class="line">2. 能够比较两个数字的大小，并给出相应的判断。</span><br><span class="line">3. 能够理解用户输入的简单数学表达式或问题描述。</span><br><span class="line"></span><br><span class="line">## Rules</span><br><span class="line">1. 用户输入可以是任意两个数字或一个包含加法、减法的表达式。</span><br><span class="line">2. 当输入两个数字时，助手应比较它们的大小，并返回结果。</span><br><span class="line">3. 当输入一个加法或减法表达式时，助手应计算出结果并返回。</span><br><span class="line">4. 如果用户输入有误或不符合数学表达式规则，助手应给出提示并要求重新输入。</span><br><span class="line"></span><br><span class="line">## Workflows</span><br><span class="line">1. 接收用户输入的数字或数学表达式。</span><br><span class="line">2. 判断输入的类型（两个数字或数学表达式）。</span><br><span class="line">3. 如果是两个数字，执行大小比较，并返回结果。</span><br><span class="line">4. 如果是数学表达式，进行加法或减法计算，返回结果。</span><br><span class="line">5. 如果输入不符合预期格式，返回错误提示，要求用户重新输入。</span><br><span class="line"></span><br><span class="line">## Init</span><br><span class="line">1. 向用户介绍助手的功能和使用方法。</span><br><span class="line">2. 提示用户可以输入两个数字进行比较，或输入一个加法、减法表达式进行计算。</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><mark>加入系统提示词前：</mark><br>PS：估计InternLM2-chat-1_8b版本太久远了，所以回答不出来🤔<br><img src="2.png" alt=""></p><p><mark>加入系统提示词后：</mark><br>PS：效果明显变好了😋<br><img src="3.png" alt=""></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>8G显存玩转书生大模型Demo</title>
      <link href="/2024/08/20/8G%E6%98%BE%E5%AD%98%E7%8E%A9%E8%BD%AC%E4%B9%A6%E7%94%9F%E5%A4%A7%E6%A8%A1%E5%9E%8BDemo/"/>
      <url>/2024/08/20/8G%E6%98%BE%E5%AD%98%E7%8E%A9%E8%BD%AC%E4%B9%A6%E7%94%9F%E5%A4%A7%E6%A8%A1%E5%9E%8BDemo/</url>
      
        <content type="html"><![CDATA[<h1>环境配置</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># 创建环境</span><br><span class="line">conda create -n demo python=3.10 -y</span><br><span class="line"># 激活环境</span><br><span class="line">conda activate demo</span><br><span class="line"># 安装 torch</span><br><span class="line">conda install pytorch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 pytorch-cuda=12.1 -c pytorch -c nvidia -y</span><br><span class="line"># 安装其他依赖</span><br><span class="line">pip install transformers==4.38</span><br><span class="line">pip install sentencepiece==0.1.99</span><br><span class="line">pip install einops==0.8.0</span><br><span class="line">pip install protobuf==5.27.2</span><br><span class="line">pip install accelerate==0.33.0</span><br><span class="line">pip install streamlit==1.37.0</span><br></pre></td></tr></table></figure><p><img src="P1.png" alt=""></p><h1>InternLM2-Chat-1.8B 模型部署</h1><h2 id="一、用Cli-Demo-部署">一、用Cli Demo 部署</h2><p>1.创建<code>demo</code>文件夹，用于存放代码。并创建 <code>cli_demo.py</code>文件</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /root/demo</span><br><span class="line">touch /root/demo/cli_demo.py</span><br></pre></td></tr></table></figure><p><img src="P2.png" alt=""></p><p>其中<code>cli_demo.py</code> 的代码为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer, AutoModelForCausalLM</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model_name_or_path = <span class="string">&quot;/root/share/new_models/Shanghai_AI_Laboratory/internlm2-chat-1_8b&quot;</span></span><br><span class="line"></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, trust_remote_code=<span class="literal">True</span>, device_map=<span class="string">&#x27;cuda:0&#x27;</span>)</span><br><span class="line">model = AutoModelForCausalLM.from_pretrained(model_name_or_path, trust_remote_code=<span class="literal">True</span>, torch_dtype=torch.bfloat16, device_map=<span class="string">&#x27;cuda:0&#x27;</span>)</span><br><span class="line">model = model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">system_prompt = <span class="string">&quot;&quot;&quot;You are an AI assistant whose name is InternLM (书生·浦语).</span></span><br><span class="line"><span class="string">- InternLM (书生·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be helpful, honest, and harmless.</span></span><br><span class="line"><span class="string">- InternLM (书生·浦语) can understand and communicate fluently in the language chosen by the user such as English and 中文.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">messages = [(system_prompt, <span class="string">&#x27;&#x27;</span>)]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;=============Welcome to InternLM chatbot, type &#x27;exit&#x27; to exit.=============&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    input_text = <span class="built_in">input</span>(<span class="string">&quot;\nUser  &gt;&gt;&gt; &quot;</span>)</span><br><span class="line">    input_text = input_text.replace(<span class="string">&#x27; &#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line">    <span class="keyword">if</span> input_text == <span class="string">&quot;exit&quot;</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    length = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> response, _ <span class="keyword">in</span> model.stream_chat(tokenizer, input_text, messages):</span><br><span class="line">        <span class="keyword">if</span> response <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="built_in">print</span>(response[length:], flush=<span class="literal">True</span>, end=<span class="string">&quot;&quot;</span>)</span><br><span class="line">            length = <span class="built_in">len</span>(response)</span><br></pre></td></tr></table></figure><p>2.在终端执行<code>python /root/demo/cli_demo.py</code>命令启动Demo</p><p>3.使用 Cli Demo 完成 InternLM2-Chat-1.8B 模型的部署，并生成 300 字小故事</p><p><img src="P3.png" alt=""></p><h2 id="二、用Streamlit-Web-Demo-部署">二、用Streamlit Web Demo 部署</h2><p>1.clone InternLM 的github仓库 到本地：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /root/demo</span><br><span class="line">git clone https://github.com/InternLM/Tutorial.git</span><br></pre></td></tr></table></figure><p>2.启动Streamlit 服务：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /root/demo</span><br><span class="line">streamlit run /root/demo/Tutorial/tools/streamlit_demo.py --server.address 127.0.0.1 --server.port 6006</span><br></pre></td></tr></table></figure><p><img src="P4.png" alt=""></p><p>3.在<strong>本地</strong>的 PowerShell 中输入以下命令，将端口映射到本地：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -CNg -L 6006:127.0.0.1:6006 root@ssh.intern-ai.org.cn -p 你的 ssh 端口号</span><br></pre></td></tr></table></figure><p><img src="P5.png" alt=""></p><p>4.完成端口映射后，通过浏览器访问 <code>http://localhost:6006</code> 来启动我们的 Demo。</p><p><img src="P6.png" alt=""></p><h1>LMDeploy 部署</h1><h2 id="一、InternLM-XComposer2-VL-1-8B-模型">一、InternLM-XComposer2-VL-1.8B 模型</h2><h3 id="模型介绍：">模型介绍：</h3><p>InternLM-XComposer2 是一款基于 InternLM2 的视觉语言大模型，其擅长自由形式的文本图像合成和理解。其主要特点包括：</p><ul class="lvl-0"><li class="lvl-2"><p>自由形式的交错文本图像合成：InternLM-XComposer2 可以根据大纲、详细文本要求和参考图像等不同输入，生成连贯且上下文相关，具有交错图像和文本的文章，从而实现高度可定制的内容创建。</p></li><li class="lvl-2"><p>准确的视觉语言问题解决：InternLM-XComposer2 基于自由形式的指令准确地处理多样化和具有挑战性的视觉语言问答任务，在识别，感知，详细标签，视觉推理等方面表现出色。</p></li></ul><h3 id="部署步骤：">部署步骤：</h3><p>1.激活环境并安装 LMDeploy 以及其他依赖。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conda activate demo</span><br><span class="line">pip install lmdeploy[all]==0.5.1</span><br><span class="line">pip install timm==1.0.7</span><br></pre></td></tr></table></figure><p><img src="P7.png" alt=""></p><p>2.使用 LMDeploy 启动一个与 InternLM-XComposer2-VL-1.8B 模型交互的 Gradio 服务。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lmdeploy serve gradio /share/new_models/Shanghai_AI_Laboratory/internlm-xcomposer2-vl-1_8b --cache-max-entry-count 0.1</span><br></pre></td></tr></table></figure><p><img src="P8.png" alt=""></p><p>3.若已关闭端口映射，重新输入以下代码即可:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -CNg -L 6006:127.0.0.1:6006 root@ssh.intern-ai.org.cn -p 36558</span><br></pre></td></tr></table></figure><p><img src="P9.png" alt=""></p><p>通过浏览器访问 <code>http://localhost:6006</code> 来启动<mark>InternLM-XComposer2-VL-1.8B</mark>模型</p><p><img src="P10.png" alt=""></p><p>输入图片并询问图片里有什么：</p><p><img src="cat.png" alt=""></p><p>输出：</p><p><img src="P11.png" alt=""></p><h2 id="二、InternVL2-2B-模型">二、InternVL2-2B 模型</h2><h3 id="模型介绍">模型介绍:</h3><p>InternVL2 是上海人工智能实验室推出的新一代视觉-语言多模态大模型，是首个综合性能媲美国际闭源商业模型的开源多模态大模型。InternVL2 系列从千亿大模型到端侧小模型全覆盖，通专融合，支持多种模态。</p><h3 id="部署步骤：-2">部署步骤：</h3><p>1.通过下面的命令来启动 InternVL2-2B 模型的 Gradio 服务:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda activate demo</span><br><span class="line">lmdeploy serve gradio /share/new_models/OpenGVLab/InternVL2-2B --cache-max-entry-count 0.1</span><br></pre></td></tr></table></figure><p>2.若已关闭端口映射，重新输入以下代码即可:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -CNg -L 6006:127.0.0.1:6006 root@ssh.intern-ai.org.cn -p 36558</span><br></pre></td></tr></table></figure><p><img src="P9.png" alt=""></p><p>通过浏览器访问 <code>http://localhost:6006</code> 来启动<mark>InternVL2-2B</mark>模型</p><p>输入图片并询问详细描述图片内容：</p><p><img src="cat2.png" alt=""><br>输出：</p><p><img src="P12.png" alt=""></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>博客：书生·浦语大模型全链路开源开放体系及其最新发展</title>
      <link href="/2024/08/08/%E4%B9%A6%E7%94%9F%C2%B7%E6%B5%A6%E8%AF%AD%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%85%A8%E9%93%BE%E8%B7%AF%E5%BC%80%E6%BA%90%E5%BC%80%E6%94%BE%E4%BD%93%E7%B3%BB%E5%8F%8A%E5%85%B6%E6%9C%80%E6%96%B0%E5%8F%91%E5%B1%95/"/>
      <url>/2024/08/08/%E4%B9%A6%E7%94%9F%C2%B7%E6%B5%A6%E8%AF%AD%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%85%A8%E9%93%BE%E8%B7%AF%E5%BC%80%E6%BA%90%E5%BC%80%E6%94%BE%E4%BD%93%E7%B3%BB%E5%8F%8A%E5%85%B6%E6%9C%80%E6%96%B0%E5%8F%91%E5%B1%95/</url>
      
        <content type="html"><![CDATA[<h1>博客：书生·浦语大模型全链路开源开放体系及其最新发展</h1><p><img src="1.png" alt=""></p><p>在现代人工智能技术的迅猛发展浪潮中，书生·浦语大模型全链路开源开放体系以其独特的优势和卓越的性能，在各个领域中不断取得突破性进展。本文将详细介绍该体系的发展历程、最新版本的特征、基于规则、模型和反馈的数据生成方法，以及mind search项目、开源数据提取工具和预训练框架、EXTINA的评测和部署、知识管理工具等各个方面的应用与优化策略。</p><h2 id="书生·浦语大模型全链路开源开放体系的历程及最新版本的特征">书生·浦语大模型全链路开源开放体系的历程及最新版本的特征</h2><p>书生·浦语大模型开源开放体系在多个方面表现出色，包括数据收集整理、模型训练、微调、评测和搜索引擎AI应用的部署等方面。最新版本书生·浦语大模型2.5在推理能力和短期记忆等方面有质的飞跃，并开放了label LLM项目，方便标注数据。此外，视频还介绍了模型的性能天梯和应用前景。</p><ul class="lvl-0"><li class="lvl-2"><p><strong>书生浦语大模型开源开放体系</strong></p></li><li class="lvl-2"><p><strong>InputLM2.5性能飞跃</strong></p></li><li class="lvl-2"><p><strong>迭代发展过程中的数据驱动模型性能</strong></p></li></ul><h2 id="基于规则、模型和反馈的数据生成方法，以及如何使用开源项目进行标注和推理">基于规则、模型和反馈的数据生成方法，以及如何使用开源项目进行标注和推理</h2><p>反映模型的数据生成方法在模型优化和训练过程中至关重要，以下是一些关键方法的介绍：</p><ul class="lvl-0"><li class="lvl-2"><p><strong>基于模型的反馈数据生成方法</strong>：包括相似度对齐和基于反馈的强化训练。</p></li><li class="lvl-2"><p><strong>大海捞针实验</strong>：介绍模型的推理能力和大海捞针实验，模型在处理稀长背景知识的表现。</p></li><li class="lvl-2"><p><strong>问题匹配分块</strong>：介绍问题匹配分块的方法，可以用于语言模型的索引和问题理解。</p></li></ul><h2 id="mind-search项目">mind search项目</h2><p>mind search项目展示了其在语言模型、预训练模型、微调框架、部署工具等方面的强大功能和应用潜力。</p><ul class="lvl-0"><li class="lvl-2"><p><strong>Mindsearch项目和书生普与开源模型谱系</strong></p></li><li class="lvl-2"><p><strong>部署工具和评测工具</strong></p></li><li class="lvl-2"><p><strong>应用方面的工具和框架</strong></p></li></ul><h2 id="开源数据提取工具Minor-U和预训练框架XTNER">开源数据提取工具Minor U和预训练框架XTNER</h2><p>Minor U和XTNER提供了无缝衔接和数据格式兼容性的功能，极大地加速了模型的训练和优化过程。</p><ul class="lvl-0"><li class="lvl-2"><p><strong>智能体框架和开源工具无缝衔接</strong></p></li><li class="lvl-2"><p><strong>微调框架和数据格式兼容性</strong></p></li><li class="lvl-2"><p><strong>使用XTNER进行微调的方法和流程</strong></p></li></ul><h2 id="EXTINA的评测和部署">EXTINA的评测和部署</h2><p>EXTINA通过微调和Open Compass评测模型，以及lm deploy的推理性能对比，构建了智能体框架建设方案。</p><ul class="lvl-0"><li class="lvl-2"><p><strong>使用EXTINA微调和Open Compass评测模型</strong></p></li><li class="lvl-2"><p><strong>lm deploy模型部署框架和智能体框架</strong></p></li><li class="lvl-2"><p><strong>基于AI的搜索引擎和知识插件</strong></p></li></ul><h2 id="知识管理工具笞香豆的企业级应用">知识管理工具笞香豆的企业级应用</h2><p>知识管理工具笞香豆通过可视化、强生和知识图谱生成，支持搜索和思考过程的展示，推动了开源生态系统的完善和实践营的创新发展。</p><ul class="lvl-0"><li class="lvl-2"><p><strong>思维可视化</strong>：通过搜索和思考1900年和1924年的相关信息，展示了模拟人脑思维逻辑的可视化过程。</p></li><li class="lvl-2"><p><strong>支持检索增强生成和知识图谱</strong>：理解群体行为。</p></li><li class="lvl-2"><p><strong>赋能创新</strong>：通过开源生态实践营，持续以高质量的开源赋能创新。</p></li></ul><p>在人工智能的快速发展中，书生·浦语大模型全链路开源开放体系无疑是一颗璀璨的明珠。它不仅在技术上不断推陈出新，在应用上也不断拓展，为各行各业带来了无限的可能。期待未来它能为更多领域提供支持，推动社会的智能化发展。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>电力预测task3笔记</title>
      <link href="/2024/07/20/%E7%94%B5%E5%8A%9B%E9%A2%84%E6%B5%8Btask3%E7%AC%94%E8%AE%B0/"/>
      <url>/2024/07/20/%E7%94%B5%E5%8A%9B%E9%A2%84%E6%B5%8Btask3%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Datawhale AI夏令营</span><br></pre></td></tr></table></figure><p>时间序列分析中的特征提取与优化策略</p><p>在时间序列分析中，特征提取是影响模型性能的关键步骤。以下是关键特征提取方法及其分析：</p><h4 id="1-日期变量">1. 日期变量</h4><p>时间序列数据通常包含日期信息，可以细分为年、月、周、日、小时等。将这些日期变量转换为数值特征，便于模型处理。</p><h4 id="2-周期性">2. 周期性</h4><p>许多时间序列表现出周期性，如每日、每周或每月的模式。识别并利用这些周期特征有助于捕捉数据的内在规律。</p><h4 id="3-趋势性">3. 趋势性</h4><p>趋势性是指时间序列的长期变化趋势。可以通过移动平均或线性回归提取，作为模型的输入特征。</p><h4 id="4-时间差">4. 时间差</h4><p>计算与特定日期的时间差（如重要事件日），帮助模型了解数据点的相对位置。</p><h4 id="5-时间特征组合">5. 时间特征组合</h4><p>组合不同的时间单位（如年和周）提供更丰富的时间信息，揭示复杂模式。</p><h4 id="6-特殊日期">6. 特殊日期</h4><p>识别特殊事件（如节假日）并将其作为特征，有助于解释相关数据波动。</p><h4 id="7-异常点">7. 异常点</h4><p>异常点与其他数据显著不同，正确处理这些点对提高预测精度至关重要。</p><h4 id="8-时序相关特征">8. 时序相关特征</h4><ul class="lvl-0"><li class="lvl-2"><p><strong>历史平移</strong>：使用过去的值预测未来。</p></li><li class="lvl-2"><p><strong>滑窗统计</strong>：在时间窗口内计算统计量，如均值、中位数等，帮助捕捉局部数据特性。</p></li></ul><h4 id="9-强相关特征">9. 强相关特征</h4><p>识别与目标变量强相关的特征，构建预测模型。</p><h3 id="特征优化方法">特征优化方法</h3><ol><li class="lvl-3"><p><strong>提取更多特征</strong>：思考哪些信息能提高预测精度，并将其转化为模型输入。</p></li><li class="lvl-3"><p><strong>尝试不同模型</strong>：通过实验和试错，找到最佳模型组合。</p></li></ol><h3 id="特征优化技术">特征优化技术</h3><ul class="lvl-0"><li class="lvl-2"><p><strong>历史平移特征</strong>：获取过去阶段的信息。</p></li><li class="lvl-2"><p><strong>差分特征</strong>：捕捉相邻阶段的增长变化，构建相邻数据比值变化和二阶差分。</p></li><li class="lvl-2"><p><strong>窗口统计特征</strong>：不同窗口大小下的统计量反映最近阶段的数据变化。</p></li></ul><h3 id="模型融合">模型融合</h3><p>使用多个模型结果进行融合（如CatBoost、XGBoost、LightGBM），常用方法包括加权平均和Stacking：</p><ul class="lvl-0"><li class="lvl-2"><p><strong>Stacking</strong>：</p><ul class="lvl-2"><li class="lvl-4"><strong>第一层</strong>：对各个模型进行交叉验证，生成预测标签。</li><li class="lvl-4"><strong>第二层</strong>：使用第一层输出作为特征，再次训练模型。</li></ul></li></ul><h3 id="总结">总结</h3><p>时间序列预测不断发展，以下是未来的研究方向：</p><ul class="lvl-0"><li class="lvl-2"><p><strong>复杂模型结构</strong>：如引入注意力机制的LSTM模型。</p></li><li class="lvl-2"><p><strong>多模态数据融合</strong>：结合时间序列与其他数据类型。</p></li><li class="lvl-2"><p><strong>模型解释性</strong>：提高对预测结果的理解。</p></li><li class="lvl-2"><p><strong>自动化特征工程</strong>：减少手动特征提取。</p></li><li class="lvl-2"><p><strong>实时预测</strong>：提高实时数据预测能力。</p></li><li class="lvl-2"><p><strong>模型鲁棒性</strong>：增强对异常值和噪声的处理能力。</p></li></ul><p>随着技术进步，时间序列预测的准确性和应用范围将显著提升。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>python-debug</title>
      <link href="/2024/07/19/python-debug/"/>
      <url>/2024/07/19/python-debug/</url>
      
        <content type="html"><![CDATA[<h1>任务一</h1><p>请用Python实现一个wordcount函数，统计英文字符串中每个单词出现的次数。返回一个字典，key为单词，value为对应单词出现的次数。</p><h2 id="源程序：">源程序：</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;  请用Python实现一个wordcount函数，统计英文字符串中每个单词出现的次数。返回一个字典，key为单词，value为对应单词出现的次数。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    TIPS：记得先去掉标点符号,然后把每个单词转换成小写。不需要考虑特别多的标点符号，只需要考虑实例输入中存在的就可以。&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">text = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Got this panda plush toy for my daughter&#x27;s birthday,</span></span><br><span class="line"><span class="string">who loves it and takes it everywhere. It&#x27;s soft and</span></span><br><span class="line"><span class="string">super cute, and its face has a friendly look. It&#x27;s</span></span><br><span class="line"><span class="string">a bit small for what I paid though. I think there</span></span><br><span class="line"><span class="string">might be other options that are bigger for the</span></span><br><span class="line"><span class="string">same price. It arrived a day earlier than expected,</span></span><br><span class="line"><span class="string">so I got to play with it myself before I gave it</span></span><br><span class="line"><span class="string">to her.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">wordcount</span>(<span class="params">text</span>):</span><br><span class="line"></span><br><span class="line">    text=text.replace(<span class="string">&quot;,&quot;</span>,<span class="string">&quot;&quot;</span>)</span><br><span class="line">    text=text.replace(<span class="string">&quot;.&quot;</span>,<span class="string">&quot;&quot;</span>)</span><br><span class="line">    text=text.replace(<span class="string">&quot;\n&quot;</span>,<span class="string">&quot;&quot;</span>)</span><br><span class="line"></span><br><span class="line">    text_list=text.split(<span class="string">&quot; &quot;</span>)</span><br><span class="line">    text_dict=&#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> text_list:</span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> text_dict:</span><br><span class="line">            text_dict[i]=<span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            text_dict[i]+=<span class="number">1</span></span><br><span class="line">            </span><br><span class="line">    <span class="keyword">return</span> text_dict</span><br><span class="line">    </span><br><span class="line"><span class="built_in">print</span>(wordcount(text))</span><br></pre></td></tr></table></figure><h1>任务二</h1><p>请使用本地vscode连接远程开发机，将上面你写的wordcount函数在开发机上进行debug，体验debug的全流程，并完成一份debug笔记(需要截图)。</p><p>1.首先重命名debug命令</p><p>在bashrc配置文件中输入:<br><code>alias pyd='python -m debugpy --wait-for-client --listen 5678'</code></p><p>再输入保存命令：<br><code>source ~/.bashrc</code></p><p><img src="1.png" alt=""></p><p>2.执行debug命令，启动服务端</p><p><code>pyd ./wordcount.py </code></p><p><img src="2.png" alt=""></p><p>3.启动客户端</p><p><img src="3.png" alt=""></p><p>响应返回：</p><p><img src="4.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>时间序列</title>
      <link href="/2024/05/17/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/"/>
      <url>/2024/05/17/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> 数学建模 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>🍉Book-10章-降维与度量学习</title>
      <link href="/2024/05/16/%F0%9F%8D%89Book-10%E7%AB%A0-%E9%99%8D%E7%BB%B4%E4%B8%8E%E5%BA%A6%E9%87%8F%E5%AD%A6%E4%B9%A0/"/>
      <url>/2024/05/16/%F0%9F%8D%89Book-10%E7%AB%A0-%E9%99%8D%E7%BB%B4%E4%B8%8E%E5%BA%A6%E9%87%8F%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> 🍉Book </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>🍉Book-9章-聚类</title>
      <link href="/2024/05/16/%F0%9F%8D%89Book-9%E7%AB%A0-%E8%81%9A%E7%B1%BB/"/>
      <url>/2024/05/16/%F0%9F%8D%89Book-9%E7%AB%A0-%E8%81%9A%E7%B1%BB/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> 🍉Book </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>🍉Book-8章-集成学习</title>
      <link href="/2024/05/16/%F0%9F%8D%89Book-8%E7%AB%A0-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/"/>
      <url>/2024/05/16/%F0%9F%8D%89Book-8%E7%AB%A0-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> 🍉Book </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>🍉Book-7章-贝叶斯分类器</title>
      <link href="/2024/05/16/%F0%9F%8D%89Book-7%E7%AB%A0-%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8/"/>
      <url>/2024/05/16/%F0%9F%8D%89Book-7%E7%AB%A0-%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> 🍉Book </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>🍉Book-6章-支持向量机</title>
      <link href="/2024/05/16/%F0%9F%8D%89Book-6%E7%AB%A0-%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/"/>
      <url>/2024/05/16/%F0%9F%8D%89Book-6%E7%AB%A0-%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/</url>
      
        <content type="html"><![CDATA[<h1>章节介绍</h1><p>统计学领域名声赫赫的<strong>SVM</strong>与<strong>核方法</strong>是时至今日仍在高频使用的经典算法。</p><h1>笔记介绍</h1><p>对本章各节知识点进行汇总，主要分为<u>引入原因，原理思想，和一些思考</u>，对于数学推导内容介绍较少，有需要的可以先阅读西瓜书，再参考南瓜书的数学推导。</p><h1>数学知识</h1><p>大部分都是规划类、最优化的问题，最好先进行相关知识的学习。</p><p>这里<strong>推荐一本书</strong>：最优化：建模、算法与理论 (刘浩洋 户将 李勇锋 文再文)</p><h1>SVM-支持向量机</h1><h2 id="引入原因：">引入原因：</h2><p>在<strong>线性可分</strong>的条件下，我们在训练集做分类任务时，最基本的想法就是在样本空间中找到一个<strong>超平面</strong>进行划分,<br>但是对于分类任务，我们可以画出很多个超平面，这时候就需要引入<strong>损失函数</strong>，对超平面进行选择，而使得<mark>两个异类支持向量</mark>的<u>距离最大化</u>，就是我们所说的支持向量机的<strong>基本型</strong>。</p><p><img src="1.jpg" alt=""></p><h2 id="数学公式及其原理：">数学公式及其原理：</h2><p>仍用<strong>线性模型</strong>来表示一个<strong>超平面</strong>：<br>$$ w ^ { T } x + b = 0$$<br>而<strong>点到超平面的距离</strong>表示为：参考<u>点到直线距离公式</u>即可理解<br>$$ r = \frac { | w ^ { T } x + b | } { | | w | | }$$<br>两个<strong>异类支持向量到超平面的距离</strong>（称为<mark>间隔</mark> margin）表示为：参考<u>平行直线间的距离公式</u>即可理解（此处分子为2的原因是<mark>假设</mark>正负类标记为+1与-1）<br>$$ \gamma = \frac { 2 } { | | w | | }$$</p><p><img src="2.jpg" alt=""></p><p>我们的目标是使得<u>间隔最大化</u>，即意味着要取得$| | w | |$​最小化，也就是$| | w | | ^ { 2 }$​最小化所以我们最终可以的到SVM基本型：<br><img src="3.jpg" alt=""></p><h2 id="求解方法：">求解方法：</h2><p>涉及到二次规划问题，使用<mark>拉格朗日乘子法</mark>解决问题，我们会得到<u>基本型</u>的“<strong>对偶问题</strong>”</p><p>具体方法不做详解，此处仅做大概阐述：</p><ol><li class="lvl-3"><p>在SVM基本型的每条约束上增加一个拉格朗日乘子a，得到新的函数</p></li><li class="lvl-3"><p>新函数对w和b分别求偏导=0，得到w和b关于a的表达式</p></li><li class="lvl-3"><p>将表达式回代入函数，就得到了仅依赖于a的函数，就将约束问题转化成无约束问题</p></li><li class="lvl-3"><p>此时使用梯度下降、牛顿法等无约束优化算法可得出a，回代表达式得出w和b，完成原本函数的求解</p></li></ol><h1>核函数</h1><h2 id="引入原因：-2">引入原因：</h2><p>由于前面的讨论都是基于训练集是<mark>线性可分的假设</mark>而对于非线性可分的数据集，我们就可以采用核方法将<strong>数据集</strong>变成<u>线性可分</u>的</p><h2 id="升维思想：">升维思想：</h2><blockquote><p>找到一个函数(即核函数)将非线性可分的数据映射为线性可分的数据</p></blockquote><h2 id="常用核函数：">常用核函数：</h2><p>下面给出常用核函数：</p><p><img src="4.jpg" alt=""></p><h1>软间隔和正则化：</h1><h2 id="引入原因：-3">引入原因：</h2><p>前面进行分类任务都是基于训练样本<u>线性可分的假设</u>，而实际应用中，训练集存在噪声 或 难以找到合适的核函数将数据转化为线性可分的数据如果找到了核函数也很有可能这个<u>线性可分的结果</u>是因为<u>模型过拟合</u>造成的。</p><p>所以我们引入了<mark>软间隔</mark><strong>Soft Magrin</strong>这个概念，即<u>允许部分样本划分出错</u>。而相应的，先前我们<u>让所有样本正确分类</u>就叫做<mark>硬间隔</mark>。</p><h2 id="正则化思想：">正则化思想：</h2><p>其实软间隔也就是一种正则化，通过对不希望的到的结果进行惩罚，使得优化过程趋向于希望目标。</p><h1>支持向量回归</h1><h2 id="引入原因：-4">引入原因：</h2><p>我们一开始引入SVM就是为了解决分类问题，而对于回归问题是否也能通过SVM解决呢？🤔</p><p>为了解决回归问题，我们引入了<mark>支持向量回归</mark>，简称SVR(Support Vector Regression)</p><h2 id="方法思想：">方法思想：</h2><p>在<strong>损失函数</strong>方面，与<u>传统的回归模型</u>用预测和标记的差别计算损失<u>不同</u>，</p><p>SVR<u>容忍</u>预测和标记之间<u>存在偏差</u>e，在偏差2e内都被判定为正确预测</p>]]></content>
      
      
      <categories>
          
          <category> 🍉Book </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>🍉Book-5章-神经网络</title>
      <link href="/2024/05/16/%F0%9F%8D%89Book-5%E7%AB%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
      <url>/2024/05/16/%F0%9F%8D%89Book-5%E7%AB%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<h1>神经网络模型</h1><p>1943年一直沿用至今的M-P神经网络模型</p><h2 id="M-P神经网络模型">M-P神经网络模型</h2><h3 id="模型解释："><strong>模型解释</strong>：</h3><p>将输入神经元的x乘上相应<mark>权重w</mark>并求和，将结果与<mark>阈值</mark>$\theta$做差，再经过<mark>激活函数f</mark>得到输出值y</p><h3 id="名词解释："><strong>名词解释</strong>：</h3><p><strong>阈值</strong>(threshold / bias):<br>表示神经元电位超过阈值则被激活</p><p><strong>激活函数</strong>(activation function)：也称<u>挤压函数</u>或<u>响应函数</u>，用于将输入值映射为0/1或(0，1)</p><h3 id="训练目标："><strong>训练目标</strong>：</h3><p>通过训练模型，得出合适的w和$\theta$，其中训练算法最常见的就是下面会说到的BP算法</p><p><img src="1.png" alt=""></p><h2 id="激活函数">激活函数</h2><p>回顾第三章线性模型中的<strong>对数几率回归</strong>模型和<strong>单位阶跃函数</strong></p><p>最理想状态是用<mark>单位阶跃函数</mark>输入值映射为0/1，但由于其不连续、不光滑的性质，我们使用<mark>Sigmoid函数</mark>将输入值映射为(0，1)，Sigmoid函数即型为S的函数，其中我们最常用的就是对数几率函数：<br>$$ s i g m o i d ( x ) = \frac { 1 } { 1 + e ^ { - x } }$$<br><strong>对率函数</strong>有很好的<mark>性质</mark>：$$ f ^ { \prime } ( x ) = f \left( x \right) ( 1 - f \left( x \right) )$$</p><h1>万有逼近能力</h1><h3 id="名词概念：">名词概念：</h3><p>仅需一个包含足够多神经元的隐层，多层前馈神经网络就能以任意精度逼近任意复杂度的连续函数</p><h3 id="引入原因：">引入原因：</h3><p>很多算法都具有万有逼近能力，不是神经网络所特有的，如决策树、支持向量机等等。而之所以在神经网络中强调其万有逼近能力，是因为其数学公理方面的理论薄弱，为了证明其有效性而进行说明。</p><h1>BP算法</h1><p><strong>误差逆传播</strong>(error BackPropagation，简称BP)算法，亦称<strong>反向传播算法</strong></p><p>BP算法是一种迭代算法，基于<mark>梯度下降</mark>(gradient descent)策略，数学推导过程不多做阐述，详见西瓜书or南瓜书</p><p><img src="2.png" alt=""></p><h1>缓解过拟合</h1><p>由于神经网络强大的表示能力，其经常容易<strong>过拟合</strong>，为此我们有以下两种<strong>策略</strong></p><h2 id="1-早停-early-stopping">1.早停(early stopping)</h2><p>将数据集分为训练集和验证集，若验证集得到的误差升高，则停止训练。</p><p>但是很显然神经网络的误差可能是细微的波动，但却造成了训练的停止，有点像决策树中的预剪枝，基于贪心的策略。</p><p>所以采用：</p><ul class="lvl-0"><li class="lvl-2"><p>若训练误差<strong>连续α轮</strong>的变化小于b，则停止训练使用验证集</p></li><li class="lvl-2"><p>若训练误差降低、验证误差升高，则停止训练</p></li></ul><h2 id="2-正则化-regularization">2.正则化(regularization)</h2><p>在误差目标函数中增加一项描述网络复杂度</p><p>$$ E = \lambda \frac { 1 } { m } \sum _ { k = 1 } ^ { m } E _ { k } + ( 1 - \lambda ) \sum _ { i } w _ { i } ^ { 2 }$$</p><p>偏好比较小的连接权和阀值，使网络输出更“光滑”</p>]]></content>
      
      
      <categories>
          
          <category> 🍉Book </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>🍉Book-5章-神经网络</title>
      <link href="/2024/05/16/%F0%9F%8D%89Book-8%E7%AB%A0-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/%F0%9F%8D%89Book-5%E7%AB%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
      <url>/2024/05/16/%F0%9F%8D%89Book-8%E7%AB%A0-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/%F0%9F%8D%89Book-5%E7%AB%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<h1>神经网络模型</h1><p>1943年一直沿用至今的M-P神经网络模型</p><h2 id="M-P神经网络模型">M-P神经网络模型</h2><h3 id="模型解释："><strong>模型解释</strong>：</h3><p>将输入神经元的x乘上相应<mark>权重w</mark>并求和，将结果与<mark>阈值</mark>$\theta$做差，再经过<mark>激活函数f</mark>得到输出值y</p><h3 id="名词解释："><strong>名词解释</strong>：</h3><p><strong>阈值</strong>(threshold / bias):<br>表示神经元电位超过阈值则被激活</p><p><strong>激活函数</strong>(activation function)：也称<u>挤压函数</u>或<u>响应函数</u>，用于将输入值映射为0/1或(0，1)</p><h3 id="训练目标："><strong>训练目标</strong>：</h3><p>通过训练模型，得出合适的w和$\theta$，其中训练算法最常见的就是下面会说到的BP算法</p><p>![[Pasted image 20240531074642.png]]</p><h2 id="激活函数">激活函数</h2><p>回顾第三章线性模型中的<strong>对数几率回归</strong>模型和<strong>单位阶跃函数</strong></p><p>最理想状态是用<mark>单位阶跃函数</mark>输入值映射为0/1，但由于其不连续、不光滑的性质，我们使用<mark>Sigmoid函数</mark>将输入值映射为(0，1)，Sigmoid函数即型为S的函数，其中我们最常用的就是对数几率函数：<br>$$ s i g m o i d ( x ) = \frac { 1 } { 1 + e ^ { - x } }$$<br><strong>对率函数</strong>有很好的<mark>性质</mark>：$$ f ^ { \prime } ( x ) = f \left( x \right) ( 1 - f \left( x \right) )$$</p><h1>万有逼近能力</h1><h3 id="名词概念：">名词概念：</h3><p>仅需一个包含足够多神经元的隐层，多层前馈神经网络就能以任意精度逼近任意复杂度的连续函数</p><h3 id="引入原因：">引入原因：</h3><p>很多算法都具有万有逼近能力，不是神经网络所特有的，如决策树、支持向量机等等。而之所以在神经网络中强调其万有逼近能力，是因为其数学公理方面的理论薄弱，为了证明其有效性而进行说明。</p><h1>BP算法</h1><p><strong>误差逆传播</strong>(error BackPropagation，简称BP)算法，亦称<strong>反向传播算法</strong></p><h1>缓解过拟合</h1>]]></content>
      
      
      <categories>
          
          <category> 🍉Book </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>🍉Book-4章-决策树</title>
      <link href="/2024/05/16/%F0%9F%8D%89Book-4%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/"/>
      <url>/2024/05/16/%F0%9F%8D%89Book-4%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/</url>
      
        <content type="html"><![CDATA[<h1>递归终止条件</h1><p>决策树使用递归实现，而递归终止条件有以下三种：</p><ol><li class="lvl-3"><p>当前结点所有样本属于同类，无需划分</p></li><li class="lvl-3"><p>当前属性集为空，无法划分，选取<mark>此节点</mark>中数量更多的标记作为类别标记</p></li><li class="lvl-3"><p>当前样本集为空，不能划分，依据<mark>父节点</mark>中数量更多的标记作为类别标记</p></li></ol><h1>名词概念</h1><p>1.纯度：同类聚集程度高、不同类越分散，则纯度越高<br>2.信息熵：纯度的量化指标，来源于信息论<br>3.剪枝：防止决策树过拟合，减去部分划分属性。分为预剪枝和后剪枝</p><h1>信息熵</h1><p><mark>信息熵计算公式</mark>：<br>$$ E n t ( D ) = - \sum _ { k = 1 } ^ { | y | } p _ { k } \log _ { 2 } p _ { k }$$<br><mark>信息熵用于衡量信息的不确定性或信息的混乱程度</mark>，我们可以将其用于<strong>量化纯度</strong><br>信息熵越大，数据分布越均匀、随机、杂乱无章，明显这不是我们想要的。我们想要的是相同类靠近，不同类远离的效果，即<strong>需要越小的信息熵</strong></p><p>$p_k$表示选到k类别的<strong>概率</strong>，而 $-\log _ { 2 } p _ { k }$则表示<strong>信息量</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">我们可以理解对于某一事件，其发生的概率越小，那么其信息量越大；发生的概率越大，那么其信息量越小。所有对两者求期望即得到信息熵。</span><br></pre></td></tr></table></figure><p><mark>注意</mark>：此处计算公式里的Y的<strong>输出值种类</strong>，如二分类问题中Y=2</p><h1>划分选择</h1><p>决策树中<u>最重要</u>的部分，用于<strong>选择最佳划分属性</strong></p><h2 id="1-信息增益-Information-Gain">1.信息增益(Information Gain)</h2><p>计算<mark>某属性</mark>的信息增益，用<u>根节点</u>的信息熵-属性<u>各个</u>属性值的<u>信息熵的加权平均值</u><br><strong>信息增益越大，意味着使用属性a进行划分获得的纯度提升越大</strong><br>$$ Gain ( D , a ) = E n t ( D ) - \sum _ { v = 1 } ^ { V } \frac { | D ^ { v } | } { | D | } E n t ( D ^ { v } )$$</p><h2 id="2-增益率-Gain-Ratio">2.增益率(Gain Ratio)</h2><p>由于<strong>信息增益</strong>对于<u>取值数目较多</u>的属性<mark>有所偏好</mark>，所以引进<strong>增益率</strong>进行选择最优划分属性，比如著名的<u>C4.5决策树算法</u></p><p><mark>当属性a的可能取值数目越多时(即V越大)，IV(a)越小，相应的增益率就越大</mark></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">我们可以这样理解，IV(a)计算的其实就是信息熵，当属性值数目越多时，样本分类就越多且彼此之间就越分散越混乱，而我们希望分类效果越好，就需要减少属性值可能取值个数。</span><br></pre></td></tr></table></figure><p>$$ Gain \space R a t i o ( D , a ) = \frac { G ain( D , a ) } { I V ( a ) }$$<br>$$ I V ( a ) = - \sum _ { v } ^ { V } \frac { | D ^ { v } | } { D } \log _ { 2 } \frac { | D ^ { v } | } { D }$$</p><h3 id="思考🤔：">思考🤔：</h3><p>增益率可以减少 <u>信息增益对于属性值较多的属性有所偏好</u> 的问题，但是同样的，<mark>增益率对于属性值较少的属性有所偏好</mark>所以实际处理时，对于不同的属性的划分选择可以采取不同的方法，但是在<mark>同一层</mark>属性划分选择时只能使用同一种方法。</p><h2 id="3-基尼指数-Gini-Index">3.基尼指数(Gini Index)</h2><p>含义：<mark>反映从数据集中随机抽取两个样本，其类别标记不一致的概率</mark></p><p>用于<strong>CART决策树</strong>，既可以用于<mark>分类</mark>问题，也可以用于<mark>回归</mark>问题</p><p><strong>基尼指数越小，则数据集纯度越高</strong><br>$$ G i n i ( D ) = 1 - \sum _ { k = 1 } ^ { | y | } p _ { k } ^ { 2 }$$$$ G i n i \space I n d e x ( D , a ) = \sum _ { v = 1 } ^ { V } \frac { | D ^ { v } | } { | D | } G i n i ( D ^ { v } )$$</p><h1>剪枝(Pruning)</h1><p>为了<mark>防止决策树模型过拟合</mark>而采取的手段分为<strong>预剪枝</strong>与<strong>后剪枝</strong>两种方法</p><p><mark>PS</mark>：需要先选定 <u>评估方法</u>和<u>性能度量</u>（第二章知识内容）下列假设使用<strong>留出法</strong>，以<strong>精度</strong>为性能度量</p><h2 id="预剪枝-Prepruning">预剪枝(Prepruning)</h2><p>运用<mark>贪心思想</mark>，可能有弊端</p><p>在建立决策树的<u>过程中</u>进行剪枝，代入测试数据将 当前精度 与 增加划分属性后的精度 进行比较，<br><strong>判断是否需要增加划分属性</strong></p><h2 id="后剪枝-Postpruning">后剪枝 (Postpruning)</h2><p>在决策树建立<u>完成后</u>进行剪枝，代入测试数据将 当前精度 与 把该结点属性变成叶子节点后的精度 进行比较<br><strong>判断是否需要剪去不要的树枝</strong><br><strong>优点</strong>：欠拟合风险小，泛化性能较好</p>]]></content>
      
      
      <categories>
          
          <category> 🍉Book </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>🍉Book-3章-线性模型</title>
      <link href="/2024/05/16/%F0%9F%8D%89Book-3%E7%AB%A0-%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/"/>
      <url>/2024/05/16/%F0%9F%8D%89Book-3%E7%AB%A0-%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<h1>所需数学知识</h1><ol><li class="lvl-3">求偏导</li><li class="lvl-3">矩阵求导</li><li class="lvl-3">求逆矩阵</li></ol><h1>名词解释</h1><p>1.<strong>序关系</strong></p><pre><code>有序：属性之间可进行相对比较（如大、中、小）无序：属性之间不可进行相对比较（如南瓜、西瓜、冬瓜）</code></pre><p>2.<strong>符号</strong>arg与s.t.</p><pre><code>arg：即argument（参数），用于表示求出指定函数时的**参数取值**例如：arg min 就是使后面这个式子达到最小值时的 变量的取值arg max 就是使后面这个式子达到最大值时的 变量的取值s.t.：即subject to，意思是受限于...，后面紧跟约束条件</code></pre><p>3.<strong>闭式解</strong></p><pre><code>也叫做 解析解，闭式解就是一些严格的公式,给出任意的自变量就可以求出其因变量,也就是问题的解南瓜书中说闭式解是指可以通过具体的表达式解出待解参数</code></pre><h1>模型介绍</h1><h2 id="表示形式">表示形式</h2><p>对于拥有d个属性的示例 x，表示为：$$x = ( x _ { 1 } ; x _ { 2 } ; \ldots ; x _ { d } )$$<br>其中$x_i$表示第i个属性的<strong>属性值</strong><br>而我们将<strong>各属性的线性组合</strong>作为线性模型，表示为：<br>$$ f ( x ) = w _ { 1 } x _ { 1 } + w _ { 2 } x _ { 2 } + \ldots + w _ { d } x _ { d } + b $$</p><center>也可写成向量形式</center>$$ f ( x ) = w ^ { T } x + b ,$$其中$w$和$x$均为列向量，其中$w$可以理解成为不同属性的**偏好**而赋予的**权重**故线性模型具有很强的**可解释性**<h2 id="模型优点">模型优点</h2><ol><li class="lvl-3"><p>简单（模型表示、数学公式简单）</p></li><li class="lvl-3"><p>基本（通过引入<strong>层级结构</strong>或<strong>高维映射</strong>可以得到许多<strong>非线性模型</strong>）</p></li><li class="lvl-3"><p>可理解性好（通过<strong>权重</strong>可以看出对属性的<strong>偏好</strong>）</p></li></ol><h1>属性数值化</h1><p><strong>总结</strong>：<mark>离散属性的处理：若有“序”(order)，则连续化；否则，转化为 𝑘维向量</mark></p><p>对于线性模型的求解，我们首先需要明确<strong>参数</strong>的<u>输入</u>和<u>求解</u>两个部分</p><p>我们知道<strong>模型的输入</strong>为各个示例 $x_i$，其中的$x_i$由d个属性组成，而我们用<strong>d个属性值</strong>表示一个<strong>具体</strong>的示例$x_i$作为输入</p><p>这时我们会发现我们需要注意属性值的<strong>数据类型</strong><br>于是这里我们把属性分为两类</p><ol><li class="lvl-3"><p>连续属性</p></li><li class="lvl-3"><p>离散属性</p><ul class="lvl-2"><li class="lvl-6"><strong>有序</strong>的离散属性</li><li class="lvl-6"><strong>无序</strong>的离散属性</li></ul></li></ol><p>对于<strong>有序</strong>的属性，我们用<strong>相对值</strong>表示属性值，如大、中、小分别用1，0.5，0来表示</p><p>对于<strong>无序</strong>的属性，我们用<strong>0/1</strong>表示属性值，我们记改属性有m种属性值，则一个属性值需要<strong>m维列向量</strong>进行表示。</p><p>比如对于属性瓜的类别，有西瓜，南瓜，冬瓜 三种属性值，则表示为<br>$$ x _ { 1 } = ( 1 ; 0 ; 0 ) , x _ { 2 } = (  0 ; 1 ; 0 ) , x _ { 3 } = (  0 ; 0 ; 1 ) $$<br>这里表示示例$x_1,x_2,x_3$<strong>分别</strong>为西瓜，南瓜，冬瓜</p><hr><p>对于<mark>回归</mark>，<mark>二分类</mark>，<mark>多分类</mark>任务，我们给出不同的线性模型</p><p>![[西瓜书学习/西瓜书-第3章/1.png]]</p><h1>回归任务</h1><h2 id="最小二乘法">最小二乘法</h2><blockquote><p>在<strong>第二章</strong>中我们知道均方误差是<strong>回归</strong>任务的常见<strong>性能度量</strong><br>均方误差本身也具有很好的<strong>几何意义</strong>，对于<strong>欧氏距离</strong></p></blockquote><p><strong>定义</strong>：基于<strong>均方误差最小化</strong>进行模型求解，使得样本到直线的欧式距离之和最小</p><p><strong>数学知识</strong>：涉及求偏导数</p><h2 id="1-一元线性回归">1.一元线性回归</h2><center>1.假设方程</center>$$f\left(x_{i}\right)=w x_{i}+b, 使得 f\left(x_{i}\right) \simeq y_{i}.$$<center>2.均方误差最小化时的w和b的值</center>$$\begin{aligned}\left(w^{*}, b^{*}\right) & =\underset{(w, b)}{\arg \min } \sum_{i=1}^{m}\left(f\left(x_{i}\right)-y_{i}\right)^{2} \\ & =\underset{(w, b)}{\arg \min } \sum_{i=1}^{m}\left(y_{i}-w x_{i}-b\right)^{2} .\end{aligned}$$<center>3.均方误差对𝑤与𝑏求偏导</center>$$\begin{array}{l}\frac{\partial E_{(w, b)}}{\partial w}=2\left(w \sum_{i=1}^{m} x_{i}^{2}-\sum_{i=1}^{m}\left(y_{i}-b\right) x_{i}\right), \\ \frac{\partial E_{(w, b)}}{\partial b}=2\left(m b-\sum_{i=1}^{m}\left(y_{i}-w x_{i}\right)\right),\end{array}$$此处$E_{(w, b)}$是是关于w和b的凸函数**注意**：此处凸函数定义与 数学分析 中相同，与 高等数学 中相反<center>4.令偏导为0，得到闭式解，解得w和b</center>$$\begin{array}{c}w=\frac{\sum_{i=1}^{m} y_{i}\left(x_{i}-\bar{x}\right)}{\sum_{i=1}^{m} x_{i}^{2}-\frac{1}{m}\left(\sum_{i=1}^{m} x_{i}\right)^{2}}, \\ b=\frac{1}{m} \sum_{i=1}^{m}\left(y_{i}-w x_{i}\right)\end{array}$$<h2 id="2-多元线性回归">2.多元线性回归</h2><p><strong>额外数学知识</strong>:</p><p><mark>矩阵求导</mark></p><blockquote><p>基于本人数学系所教授的高等代数中无此内容，故认为需要额外补充学习</p></blockquote><p>详见西瓜书附录P400 <code>A.2 导数</code></p><center>1.假设方程</center>$$f\left(\boldsymbol{x}_{i}\right)=\boldsymbol{w}^{\mathrm{T}} \boldsymbol{x}_{i}+b, 使得 f\left(\boldsymbol{x}_{i}\right) \simeq y_{i},$$<center>2.为便于讨论，把w和b吸收入向量形式 ，数据集表示为</center><p>$$<br>\mathbf{X}=\left(\begin{array}{ccccc}x_{11} &amp; x_{12} &amp; \ldots &amp; x_{1 d} &amp; 1 \ x_{21} &amp; x_{22} &amp; \ldots &amp; x_{2 d} &amp; 1 \ \vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots \ x_{m 1} &amp; x_{m 2} &amp; \ldots &amp; x_{m d} &amp; 1\end{array}\right)=\left(\begin{array}{cc}\boldsymbol{x}<em>{1}^{\mathrm{T}} &amp; 1 \ \boldsymbol{x}</em>{2}^{\mathrm{T}} &amp; 1 \ \vdots &amp; \vdots \ \boldsymbol{x}_{m}^{\mathrm{T}} &amp; 1\end{array}\right)<br>$$<br><strong>示例中的属性值为列向量</strong>，同时将<strong>标记</strong>写成<strong>向量形式</strong>  $y = ( y _ { 1 } ; y _ { 2 } ; \ldots ; y _ { m } )$</p><p><strong>注意</strong>：此处将$f\left(\boldsymbol{x}<em>{i}\right)=\boldsymbol{w}^{\mathrm{T}} \boldsymbol{x}</em>{i}+b$中的 $b$ 拆成<code>b*1</code>的形式，用$x$吸收$1$，用$w$吸收$b$变成$\hat{\boldsymbol{w}}$</p><p>![[西瓜书学习/西瓜书-第3章/2.png]]<br><code>[图片源于周志华老师]</code></p><center>3.解得w</center>$$\hat{\boldsymbol{w}}^{*}=\left(\mathbf{X}^{\mathrm{T}} \mathbf{X}\right)^{-1} \mathbf{X}^{\mathrm{T}} \boldsymbol{y}$$<center>4.最终解得模型为：</center>$$f\left(\hat{\boldsymbol{x}}_{i}\right)=\hat{\boldsymbol{x}}_{i}^{\mathrm{T}}\left(\mathbf{X}^{\mathrm{T}} \mathbf{X}\right)^{-1} \mathbf{X}^{\mathrm{T}} \boldsymbol{y}.$$<p>$1.若 X ^ { T } X 满 秩 或 正 定 , 则 w ^ { * } = ( X ^ { T } X ) ^ { - 1 } X ^ { T } y$<br>$2.若X ^ { T } X 不 满 秩 , 则 可 解 出 多 个 \widehat { w }$<br>此时需求助于<strong>归纳偏好</strong>，常见做法是引入 <strong>正则化项</strong>（详见6.4节，11.4节）</p><blockquote><p>通过在损失函数中添加惩罚项来限制模型的复杂度，常见的正则化方法包括岭回归（Ridge Regression）、Lasso回归和弹性网（Elastic Net）</p></blockquote><p>PS：$\widehat { w } ^ { * }$转换成<strong>二次型</strong>矩阵相乘还挺有意思的，推导详见南瓜书P35，P36</p><h2 id="3-广义线性模型-GLM">3.广义线性模型(GLM)</h2><blockquote><p>令预测值逼近 y 的衍生物</p></blockquote><h3 id="对数线性模型">对数线性模型</h3><blockquote><p>假设我们认为示例所对应的输出标记是在<strong>指数尺度</strong>上变化，那就可将<strong>输出标记的对数</strong>作为线性模型逼近的目标</p></blockquote><p><strong>个人理解</strong>：</p><p>其实就是我们在原样本中，通过数值或者散点图，观察到<strong>输出标记</strong>在<strong>指数尺度</strong>上变化，故<strong>很难直接</strong>用一条直线拟合输出标记，因为标记值本身为<strong>非线性增长</strong>。</p><p>而对在指数尺度上变化的输出标记<strong>取对数</strong>后，就可以将输出标记<strong>映射</strong>到<strong>线性尺度</strong>上变化，故易于用直线拟合</p><p>$$ y = w ^ { T } x + b $$</p><center>将输出标记 y 取对数转变为形式上的线性回归方程</center><p>$$ \ln y = w ^ { T } x + b $$</p><blockquote><p>实际上是在试图让$e ^ { w ^T x} + b$逼近y</p><p>这里的<strong>对数函数</strong>起到了将线性回归模型的<strong>预测值</strong>与<strong>真实标记</strong>联系起来的作用</p><p>但实质上已是在求取输入空间到输出空间的<strong>非线性函数映射</strong></p></blockquote><hr><p>我们知道，<strong>对数线性模型</strong>是使用<strong>对数函数</strong>将输出标记进行<strong>映射</strong></p><p>那么如果我们选取不同的<strong>函数</strong>对输出标记进行<strong>映射</strong>，就能将一个<strong>非线性变化</strong>的样本用<strong>线性模型</strong>进行拟合了。</p><p>而此时问题就转变为<strong>映射函数的寻找</strong>了，需要找到一个合适的映射函数，将原来的标记值<strong>数据形态</strong>映射成线性的🤔</p><p>这里就涉及到模型的<strong>优化</strong>了，找到映射函数得到<strong>新的</strong>线性模型，并在<strong>某一性能度量</strong>下进行比较，结合<strong>需求</strong>选择模型。</p><hr><p>而由此我们引出了<strong>广义线性模型</strong>（Generalized Linear Model）的定义：</p><p>$$ y = g ^ { - 1 } ( w ^ { T } x + b )$$<br>其中$g ( \cdot )$为<strong>连续</strong>且<strong>充分光滑</strong>的<strong>单调可微</strong>函数，称为<strong>联系函数</strong>(link function)</p><blockquote><p>广义线性模型的<strong>参数估计</strong>常通过加权最小二乘法或极大似然法进行</p></blockquote><p>显然，<strong>对数线性回归</strong>是<strong>广义线性模型</strong>在 $g ( \cdot )$=$ln ( \cdot )$时的特例显然，<strong>一元线性回归</strong>也是如此</p><h1>分类任务</h1><h2 id="引导">引导</h2><p>在先前的文章：<code>西瓜书-第3章-线性模型 (Part 1) 中 我们介绍了</code><U>一元线性回归、多元线性回归、广义线性回归（对数线性回归）</U>的模型,<br>用于解决<mark>回归类</mark>问题</p><p>那么对于<mark>分类</mark>问题，我们又该使用哪种模型呢？我们知道分类问题可以分成<U>二分类</U>与<U>多分类</U>问题</p><p>此处我们先介绍<U>二分类</U>问题所使用的模型</p><p>我们刚学过回归类问题的模型，此时我们运用<mark>广义线性回归</mark>的思想，只要我们能找到一个<mark>联系函数</mark>，能够将<U>连续值变成离散值</U>，即可将<U>回归类模型</U>运用到<U>分类问题</U>上。</p><h2 id="对数几率回归">对数几率回归</h2><p>这里我们先给出“单位阶跃函数“(unit-step function)</p><p>此函数能够将输出范围在R上的标记 转换为离散值</p><blockquote><p>若预测值大于零就判为正例，小于零则判为反例，预测值为临界值零则可任意判别</p></blockquote><p><img src="https://img-blog.csdnimg.cn/direct/b1e0d606699d4ad0bf0fb4904882bd78.jpeg#pic_center" alt="在这里插入图片描述"><br>我们可以看出这个函数的效果是很不错的但是因为其函数性质很差，不连续也不可微，不符合联系函数的定义</p><p>所以我们引进了<mark>对数几率函数</mark>，简称“对率函数”<br>$$ y = \frac { 1 } { 1 + e ^ { - z } } .$$<br>故有<br>$$ \ln \frac { y } { 1 - y } = w ^ { T } x + b .$$<br><img src="https://img-blog.csdnimg.cn/direct/62ffa64366c94340af6113681861aed6.png" alt="在这里插入图片描述"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">若将y 视为样本x 作为正例的可能性，则1 - y 是其反例可能性,两者的比值称为“几率”(odds),反映了x作为正例的相对可能性。</span><br></pre></td></tr></table></figure><p>最小二乘法仅可解决凸函数的问题，并对于高阶函数不易用，而且对于多元回归的函数，矩阵可能无法求逆，因为其可能是不满秩的(奇异矩阵/非正定矩阵)</p><p>故我们通过极大似然法+梯度下降法进行求解</p>]]></content>
      
      
      <categories>
          
          <category> 🍉Book </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>🍉Book-2章-模型评估与选择</title>
      <link href="/2024/05/16/%F0%9F%8D%89Book-2%E7%AB%A0-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%B8%8E%E9%80%89%E6%8B%A9/"/>
      <url>/2024/05/16/%F0%9F%8D%89Book-2%E7%AB%A0-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%B8%8E%E9%80%89%E6%8B%A9/</url>
      
        <content type="html"><![CDATA[<h1>术语名词</h1><p>1.泛化误差与经验误差</p><blockquote><p>泛化误差：在“未来”样本上的误差</p><p>经验误差：在训练集上的误差，亦称“训练误差”</p></blockquote><p>训练集样本数越接近数据集数量，经验误差就越小。但是经验误差越小，模型效果就越好吗？</p><p>请注意，我们是为了得到泛化能力强的模型，而<strong>经验误差≠泛化误差</strong></p><p>经验误差很小，会使模型学习到训练样本中的许多<strong>无用特征</strong>，导致<strong>泛化能力变弱</strong><br>我们称其为<strong>过拟合</strong>(overfitting)</p><p>而与之相对的概念，我们称为<strong>欠拟合</strong>(underfitting)，其表示的就是模型<strong>没有很好的学习</strong>到训练样本上的特征，从而也导致<strong>泛化能力变弱</strong></p><p>2.过拟合与欠拟合</p><blockquote><p>过拟合：模型在训练数据上表现得过于复杂，以至于在未见过的数据上表现不佳。欠拟合：模型在训练数据上表现得过于简单，无法捕捉到数据的内在结构和模式。</p></blockquote><p><strong>出现原因</strong>：<br>1.出现<strong>欠拟合</strong>的情况，一般是由于<u>样本特征少</u>，<u>模型复杂度低</u>等</p><p>2.出现<strong>过拟合</strong>的情况，一般是由于<u>样本数量少、噪声多</u>，<u>模型复杂度过高</u>等</p><p>经验误差就是<strong>训练程度</strong>的体现，<u>经验误差越小则训练程度越强</u>所以现在，我们可以得出训练程度<strong>不能过大也不能过小</strong>的结论</p><p>那我们能找到一个<strong>最佳方案</strong>得出<strong>最佳的训练程度</strong>吗🤔</p><blockquote><p>答案是---------------&gt;不能🙅‍</p></blockquote><p><strong>原因</strong>是：对于千禧年七大数学问题之——“P=NP&quot;问题，只要我们相信&quot;P≠NP”，就无法找出最优解</p><p>但是我们依然有相应的解决方法，用于欠拟合与过拟合的问题此处的解决方法我们留待以后解决…</p><p>好了，回归本章主题–模型评估与选择</p><p>对于<strong>模型的选择</strong>，我们有三个<strong>关键问题</strong>：</p><blockquote><p>如何获得<strong>测试集</strong>？------&gt;<u>评估方法</u></p><p>如何评价<strong>性能</strong>优劣？------&gt;<u>性能度量</u></p><p>如何判断模型<strong>实质</strong>差别------&gt;<u>比较检验</u></p></blockquote><h1>1.评估方法</h1><p>因为我们无法得知未来数据的输出标记故而需要得到<strong>测试集</strong>用来评估模型</p><p>而测试集有多种<strong>划分方法</strong>，这里我们给出<strong>以下三种</strong></p><h2 id="1-1-留出法-hold-out-：">1.1 <strong>留出法</strong>(hold-out)：</h2><blockquote><p>将数据集<strong>直接划分</strong>为训练集和测试集</p></blockquote><p>留出法：对数据集的<strong>划分方法</strong>会影响模型结果；训练集和测试集的<strong>数据分布</strong>必须保持一致；测试集过大会使模型拟合效果变差，太小会使得测试估计偏小；有一些数据可能从未被训练过</p><p><strong>总结</strong>：</p><ol><li class="lvl-3"><p>保证数据分布一致性（比如分层取样）</p></li><li class="lvl-3"><p>多次重复划分 (例如: 100次随机划分)</p></li><li class="lvl-3"><p>测试集不能太大或太小（例如：1/5~1/3，其实二八分偏多）</p></li><li class="lvl-3"><p>可能遗漏数据（随机划分没取到该数据进行训练）</p></li></ol><h2 id="1-2-交叉验证法">1.2 交叉验证法</h2><p>对于 <strong>留出法</strong>出现 可能<strong>遗漏数据</strong>（随机划分没取到该数据进行训练）的问题</p><p>我们引入<strong>新的划分方法</strong> <u>k-折交叉验证法</u> 可以有效解决该问题</p><p><img src="1.jpg" alt=""></p><p>以该图为例：</p><blockquote><p>首先将数据集D随机划分为10个子集，进行十次操作，每一次取其中1个子集为测试集，其余为训练集（实际也可以选取多个子集为测试集）将结果做平均处理</p></blockquote><p>而对于再划分子集的阶段，将测试集中只留有一个数据的方法叫做<strong>留一法</strong><br>留一法，使得<strong>训练集</strong>极大地逼近了真实模型，但是却让<strong>测试误差变得很大</strong></p><p><strong>优缺点</strong>：从而我们能得出，尽管交叉检验法保证了<u>所有的数据均被训练</u>，但仍然存在<u>受限于样本大小</u>的问题；</p><p>并且对于<u>较大的k值</u>，会使得<u>计算成本显著增加</u>；</p><p>而且对于<u>子集的划分</u>，仍然是一个难题，如果测试集和训练集之间的划分不够随机或不够独立，可能会导致数据泄露，影响模型评估的准确性。</p><h2 id="1-3-自助法">1.3 自助法</h2><p><img src="2.jpg" alt=""></p><p>“自助法”(bootstrapping)<br>基于<mark>放回取样</mark> 亦称“可重复采样”</p><p>故其可以使最终<U>训练集</U>的样本个数=<U>数据集</U>的样本个数，我们记数据集的样本个数为m，则由<U>洛必达法则</U>可得出 未被取出即未进行训练的样本，我们称为<mark>包外估计</mark>(out-of-bag estimate)的占比为：<br>$$ \lim _ { m \rightarrow \infty } ( 1 - \frac { 1 } { m } ) ^ { m } \rightarrow \frac { 1 } { e } \approx 0 . 3 6 8$$<br>我们将其作为训练集即可</p><p><strong>优缺点</strong>：</p><p><strong>优点</strong>：自助法在数据集较小、难以有效划分训练/测试集时很有用，自助法能从初始数据集中产生多个不同的训练集,这对<mark>集成学习</mark>等方法有很大的好处。</p><p><strong>缺点</strong>：自助法产生的数据集改变了初始数据集的分布，这会引入估计偏差。但是通过增加数据划分的次数，就可以缓解该影响。</p><h2 id="1-4-调参与验证集">1.4 调参与验证集</h2><p>在模型评估与选择的过程中，我们既要选择学习算法，还要对算法的参数进行设定</p><p>训练过程中的参数分为<strong>两种</strong>：</p><ul class="lvl-0"><li class="lvl-2"><p>算法参数：亦称“超参数”，由人工设定</p></li><li class="lvl-2"><p>模型参数：由训练集训练而成</p></li></ul><h2 id="1-5-重新训练">1.5 重新训练</h2><p><strong>重新训练</strong>：在调整和优化模型之后，可能需要使用整个数据集（包括之前划分的训练集和测试集）重新训练模型，以利用所有可用数据来提高模型的性能。</p><p>故之所以<strong>划分训练集和测试集</strong>，仅仅是为了选定<mark>算法</mark>的<strong>种类</strong>和<strong>参数</strong><br>当我们确定使用该算法后，我们应将<strong>整个数据集</strong>放入该算法进行训练，从而得到<strong>模型的参数</strong></p><h1>2.性能度量</h1><h2 id="2-1-错误率和精度">2.1 错误率和精度</h2><p>错误率定义：</p><p>$$<br>E(f;D)=\frac{1}{m}\sum_{i=1}^{m}\mathbb{I}\left(f\left(\boldsymbol{x}<em>{i}\right)\neq y</em>{i}\right)<br>$$<br>精度定义：</p><p>$$<br>\begin{aligned}\operatorname{acc}(f;D)&amp;=\quad\frac{1}{m}\sum_{i=1}^{m}\mathbb{I}\left(f\left(\boldsymbol{x}<em>{i}\right)=y</em>{i}\right)\&amp;=\quad1-E(f;D) \end{aligned}<br>$$</p><p>然而对于不同的任务需求，仅仅用错误率和精度是不够的，故引出<code>查准率、查全率、F1</code>的概念</p><h2 id="2-2-查准率、查全率、F1">2.2 查准率、查全率、F1</h2><h3 id="二分类任务：">二分类任务：</h3><pre><code>现有一瓜田含10000个瓜，其中有100个好瓜，利用学习器挑瓜查准率：即准确率（precision），如挑出瓜中好瓜的比例查全率：即召回率（recall），如所有好瓜中被挑出的比例F1-score：即查准率与查全率的调和平均</code></pre><p>在选瓜任务中我们的目标是：</p><ol><li class="lvl-3"><p>在挑出来的瓜中尽可能都是好瓜</p></li><li class="lvl-3"><p>瓜田中的好瓜尽可能多地被挑出来很直观的可以感受到查全率越大(如挑出越多的瓜，好瓜被挑出的比例也就越大），查准率就会越低</p></li></ol><p><mark>混淆矩阵</mark>：</p><p><img src="3.png" alt=""></p><p>其中查准率P和查全率R的定义为：<br>$$<br>P=\frac{TP}{TP+FP}<br>$$</p><p>$$<br>R=\frac{TP}{TP+FN}<br>$$</p><p>F1即综合考虑两者效果:</p><p>$$<br>\frac1{F1}=\frac12\cdot\left(\frac1P+\frac1R\right)<br>$$</p><h3 id="多分类任务：">多分类任务：</h3><h2 id="2-3-ROC与AUC">2.3 ROC与AUC</h2><h1>3.比较检验</h1>]]></content>
      
      
      <categories>
          
          <category> 🍉Book </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>🍉Book-1章-绪论</title>
      <link href="/2024/05/15/%F0%9F%8D%89Book-1%E7%AB%A0-%E7%BB%AA%E8%AE%BA/"/>
      <url>/2024/05/15/%F0%9F%8D%89Book-1%E7%AB%A0-%E7%BB%AA%E8%AE%BA/</url>
      
        <content type="html"><![CDATA[<h1>本书的使用：</h1><p><img src="1.png" alt=""><br>第1章-绪论</p><h2 id="计算学习理论">计算学习理论</h2><p><strong>概率近似正确</strong> 模型：<strong>PAC</strong> (Probably Approximate Correct)</p><p>公式：$$ P ( | f ( x ) - y | \leq \epsilon ) \geq 1 - \delta$$</p><p>其中 f 表示模型，y表示真相，x为样本</p><p><strong>公式分析</strong>：</p><p>其中$ | f ( x ) - y | \leq \epsilon$  用于计算模型的误差，判断模型的优劣</p><p>由于模型基于不同的算法和数据是不唯一的</p><p>故用$$ P ( … ) \geq 1 - \delta$$ 表示取得该模型的概率</p><p>故当$$ \delta=0，\epsilon=0$$时，即表示每次都取到最优解的模型</p><p>这时就出现了P=NP的问题</p><p>只要我们相信P≠NP，那么就不可能每次都取到最优模型</p><blockquote><p>P=NP问题是计算机科学中的一个著名未解之谜，它询问的是两个问题类别——P类问题和NP类问题——是否相等。P类问题是指那些可以被快速解决的计算问题，即存在一个多项式时间算法来解决这些问题。NP类问题则是指那些虽然可能很难快速解决，但如果给出一个解决方案，我们可以快速验证这个解决方案是否正确的问题。</p><p>简单来说，P=NP问题问的是：所有可以快速验证答案的问题，是否都可以快速解决？</p></blockquote><h2 id="术语名词">术语名词</h2><p>1.示例 = 特征向量，样本</p><ul class="lvl-0"><li class="lvl-2"><p>名词解释:<code>即对某个事件或者对象的 全局 描述</code></p></li><li class="lvl-2"><p>构成元素:<code>多组(特征:特征值)</code></p></li><li class="lvl-2"><p>样本 要根据上下文来判断含义</p></li></ul><p>2.特征 = 属性</p><ul class="lvl-0"><li class="lvl-2"><p>名词解释：<code>即对某个事件或对象的一个 具体 特征的描述</code></p></li></ul><p>3.样本空间 = 属性空间 = 输入空间</p><ul class="lvl-0"><li class="lvl-2"><p>名词解释：<code>即特征张成的空间，空间中每个点对应一个特征向量即样本</code></p></li></ul><p>4.数据集，训练集，测试集</p><ul class="lvl-0"><li class="lvl-2"><p>数据集=训练集+测试集（一般二八分，训练集更多）</p></li></ul><p>数据集一般这样表示：</p><p>$$<br>D =\left{x_{ 1 },x_{2},\ldots,x_{ m }\right}<br>$$</p><p>由m个样本X构成，每个样本有相同的d个特征，即样本的维数为d</p><p>5.样例，标记，标记空间</p><ul class="lvl-0"><li class="lvl-2"><p>样例=样本+标记</p></li></ul><p><strong>标记</strong>：即想预测的结果的 实际信息，比如想预测瓜的好坏，实际样本中的信息为&quot;好瓜&quot;/“坏瓜”，</p><p>一般这样表示：<br>$$ ( x _ { i } , y _ { i } )$$</p><p><strong>标记空间</strong> or <strong>输出空间</strong>：所有标记的集合</p><p>6.假设空间，版本空间</p><pre><code>假设：学得模型关于数据的潜在规律真实or真相：潜在规律本身假设空间：所有假设构成的集合版本空间：与训练集一致的假设构成的集合，由一个或多个假设空间的子集构成</code></pre><p>…</p><h2 id="基本假设">基本假设</h2><p>我们知道训练出的模型是为了对<strong>未知数据</strong>进行结果预测</p><p>但是为什么模型可以对未知数据进行预测呢？</p><p>这里我们引出了机器学习的基本假设。</p><h3 id="1-未知分布D">1.未知分布D</h3><blockquote><p>通常假设样本空间中全体样本服从一个未知“分布” D</p><p>此处的“分布”指的是概率论中的概率分布</p></blockquote><p>我们假设数据（包括 源数据集 和 未知数据）背后满足某种规律，</p><p>即数据的<strong>采样</strong>来自一个未知的、潜在的 <strong>分布</strong>D</p><h3 id="2-独立同分布（i-i-d）">2.独立同分布（i.i.d）</h3><p>我们获得的每个样本都是独立地从这个分布上采样获得的，即“独立同分布”（简称i.i.d）</p><p>或者说 所有样本都是独立同分布的</p><p>一般而言，训练样本越多，我们得到的关于D的信息也越多</p><h3 id="3-一些思考">3.一些思考</h3><p>在现实生活中，大多数样本之间不是独立同分布的，而是相互影响的。</p><p>比如说：在淘宝上 买衣服的人 和 买裤子的人，它们之间可能来自不同的分布，可能买衣服的人推荐买裤子的人来淘宝购物。</p><p>所以现在在机器学习的前沿领域，</p><p><strong>如何突破独立同分布的限制</strong> 是一个重大课题</p><h2 id="归纳偏好">归纳偏好</h2><blockquote><p>归纳偏好对应了学习算法本身所做出的关于“什么样的模型更好”的假设</p></blockquote><p>对假设空间 筛选 后所得到的 版本空间中 可能有多个假设这些假设都能够匹配训练集中的训练样本</p><p>而如何对版本空间中的假设进行选择呢？🤔</p><p>这里引入一个原则or方法论：</p><p><strong>奥卡姆剃刀</strong>：</p><blockquote><p>若非必要勿增实体</p><p>选取多个假设中最简单的。</p></blockquote><p>但是其实感觉没啥用，因为”简单“的定义难以量化。</p><blockquote><p>一个“随机乱猜”的算法有可能优于精心选择的算法</p></blockquote><p><strong>“没有免费的午餐”（NFL）定理：</strong></p><pre><code>任意算法的“训练集外误差”相等，即不同算法的误差期望相同，无绝对意义上的更优算法。</code></pre><p><img src="2.jpg" alt=""></p><p>所以 <strong>不能摆脱具体问题</strong> 谈论算法的<strong>优劣</strong></p><p><strong>实际上</strong>：还是看<strong>测试集</strong>再模型上的效果，以及结合<strong>特定领域的需求</strong>对模型进行选择</p><h2 id="机器学习分类">机器学习分类</h2><h3 id="1-监督学习-有导师学习">1.监督学习-有导师学习</h3><p><strong>样本有标记</strong></p><p>1.1 <strong>分类</strong>问题-预测 <strong>离散值</strong></p><ul class="lvl-0"><li class="lvl-2"><p>二分类-正类/负类(反类)</p><p><code>一般取值0/1，文本可通过 特征工程 转换为数值型变量</code></p><p><code>一般假设正类和负类是可交换的</code></p></li><li class="lvl-2"><p>多分类<br><code>涉及 多类别 的预测输出</code></p><p><code>可以转换成二分类问题</code></p></li></ul><p>1.2 <strong>回归</strong>问题-预测 <strong>连续值</strong></p><pre><code>预测结果 ∈ R</code></pre><h3 id="2-非监督学习-无导师学习">2.非监督学习-无导师学习</h3><p><strong>样本无标记</strong></p><p>2.1 <strong>聚类</strong>算法</p><ul class="lvl-0"><li class="lvl-2"><p>离散型变量的分类、分组别</p></li><li class="lvl-2"><p>连续型变量的统计个数，进行密度估计</p><p>了解数据内在规律</p></li></ul><p>2.2 <strong>降维</strong>算法</p><ul class="lvl-0"><li class="lvl-2"><p>如PCA主成分分析等</p></li></ul><p>…</p><h2 id="机器学习的发展">机器学习的发展</h2><ul class="lvl-0"><li class="lvl-2"><p><strong>符号主义</strong>：源于数学逻辑，产生明确的概念表示</p><p>符号主义认为人工智能源于数理逻辑后来又发展了 启发式算法&gt;专家系统&gt;知识工程理论与技术</p><p>主要方向：决策树 和 基于逻辑的学习</p><pre><code>  决策树-&gt;模拟人类对概念的判定树形过程    基于逻辑的学习--&gt;典型代表：归纳逻辑程序设计(ILP)</code></pre></li><li class="lvl-2"><p><strong>连接主义</strong>：基于神经网络</p><p>算法复杂度高，假设空间大，且参数设置缺乏理论指导</p><p>经典代表：BP反向传播算法</p></li><li class="lvl-2"><p><strong>统计学习</strong>：支持向量机(SVM)，核方法</p><p>与连接主义关系密切</p></li><li class="lvl-2"><p><strong>深度学习</strong>：早期连接主义的衍生，基于神经网络，现阶段很流行</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 🍉Book </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>定义类和方法</title>
      <link href="/2024/05/14/%E5%AE%9A%E4%B9%89%E7%B1%BB%E5%92%8C%E6%96%B9%E6%B3%95/"/>
      <url>/2024/05/14/%E5%AE%9A%E4%B9%89%E7%B1%BB%E5%92%8C%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<p>对象是实例化的类，所以对象也叫做实例。</p><p>一个实例(对象)由 <strong>属性</strong> (变量or数据)和 <strong>方法</strong> (行为)构成</p><p>所以属性和方法叫做对象的 <strong>成员</strong></p><p>对象的  属性  叫做 成员变量or实例变量(这俩也有点区别)</p><p>对象的  方法  叫做 成员方法</p><hr><p>在面向对象编程中，成员变量和实例变量通常指的是相同的概念，但它们的使用和含义略有不同，具体取决于上下文：</p><ol><li class="lvl-3"><p><strong>成员变量</strong>：</p><ul class="lvl-2"><li class="lvl-5">成员变量是类的一部分，它们定义了类的状态或属性。</li><li class="lvl-5">每个成员变量都是类的蓝图，用于创建对象时存储数据。</li><li class="lvl-5">成员变量可以是静态的或非静态的（实例变量）。</li></ul></li><li class="lvl-3"><p><strong>实例变量</strong>（非静态变量）：</p><ul class="lvl-2"><li class="lvl-5">实例变量是成员变量的一种，它们属于类的特定实例（对象）。</li><li class="lvl-5">每个实例变量的副本都存储在创建的对象中，这意味着每个对象都有自己的实例变量副本。</li><li class="lvl-5">实例变量的值对于每个对象都是独立的，一个对象的实例变量改变不会影响另一个对象的相应变量。</li></ul></li><li class="lvl-3"><p><strong>静态变量</strong>（类变量）：</p><ul class="lvl-2"><li class="lvl-5">静态变量也是成员变量的一种，但它们不属于任何特定的实例。</li><li class="lvl-5">静态变量只有单一的副本，所有类的实例共享这个副本。</li><li class="lvl-5">静态变量通常用于存储类级别的数据，如配置信息或计数器。</li></ul></li></ol><p>以下是一些关键点的对比：</p><ul class="lvl-0"><li class="lvl-2"><p><strong>作用域</strong>：实例变量属于对象，每个对象都有其独立的副本；静态变量属于类，所有实例共享同一个副本。</p></li><li class="lvl-2"><p><strong>生命周期</strong>：实例变量随对象的创建而存在，随对象的销毁而消失；静态变量随类的加载而存在，随程序结束或类被卸载而消失。</p></li><li class="lvl-2"><p><strong>访问</strong>：实例变量可以通过对象的引用访问；静态变量可以通过类名直接访问，也可以通过对象引用访问。</p></li></ul><p>下面是一个简单的Java类示例，展示了实例变量和静态变量的使用：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Car</span> &#123;</span><br><span class="line">    <span class="comment">// 实例变量，每个Car对象都有自己的颜色和速度</span></span><br><span class="line">    String color;</span><br><span class="line">    <span class="type">int</span> speed;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 静态变量，所有Car对象共享同一个制造数量</span></span><br><span class="line">    <span class="keyword">static</span> <span class="type">int</span> <span class="variable">manufacturingCount</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">Car</span><span class="params">(String color)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.color = color;</span><br><span class="line">        <span class="comment">// 每创建一个Car对象，制造数量增加</span></span><br><span class="line">        manufacturingCount++;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">drive</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="comment">// 实例方法，影响特定对象的速度</span></span><br><span class="line">        speed += <span class="number">10</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="type">int</span> <span class="title function_">getManufacturingCount</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="comment">// 静态方法，返回所有Car对象共享的制造数量</span></span><br><span class="line">        <span class="keyword">return</span> manufacturingCount;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在这个例子中，<code>color</code> 和 <code>speed</code> 是实例变量，因为它们属于每个 <code>Car</code> 对象。而 <code>manufacturingCount</code> 是一个静态变量，因为它属于 <code>Car</code> 类本身，并且所有 <code>Car</code> 实例共享这个变量。<code>drive</code> 方法是一个实例方法，因为它操作特定 <code>Car</code> 对象的速度。<code>getManufacturingCount</code> 是一个静态方法，因为它返回的是类级别的信息。</p><hr><p>在Java中，类（Class）是用来创建对象的模板或蓝图。类本身不直接持有数据，但类定义中可以包含成员变量（也称为字段或属性），这些成员变量是用来存储数据的。当你根据类创建一个对象（实例）时，每个对象都会有自己的成员变量副本，这些副本中存储的就是数据。</p><p>例如，假设有一个名为 <code>Person</code> 的类：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Person</span> &#123;</span><br><span class="line">    String name;</span><br><span class="line">    <span class="type">int</span> age;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">Person</span><span class="params">(String name, <span class="type">int</span> age)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.name = name;</span><br><span class="line">        <span class="built_in">this</span>.age = age;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 其他方法...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在这个 <code>Person</code> 类中，<code>name</code> 和 <code>age</code> 就是成员变量，它们可以在类的实例中存储数据。当你创建 <code>Person</code> 类的对象时：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Person</span> <span class="variable">person1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Person</span>(<span class="string">&quot;Alice&quot;</span>, <span class="number">30</span>);</span><br><span class="line"><span class="type">Person</span> <span class="variable">person2</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Person</span>(<span class="string">&quot;Bob&quot;</span>, <span class="number">25</span>);</span><br></pre></td></tr></table></figure><p><code>person1</code> 和 <code>person2</code> 都是 <code>Person</code> 类的实例，它们各自拥有自己的 <code>name</code> 和 <code>age</code> 数据。<code>person1</code> 的 <code>name</code> 是 “Alice”，<code>age</code> 是 30；而 <code>person2</code> 的 <code>name</code> 是 “Bob”，<code>age</code> 是 25。</p><p>类本身只是一个定义，它不包含数据，但是它定义了如何创建可以包含数据的对象。</p><hr><p>在面向对象编程（OOP）中，成员是类的一部分，它代表了类的特性（属性）或行为（方法）。成员是构成类的基本元素，它们定义了类的功能和数据结构。以下是成员的两种主要类型：</p><ol><li class="lvl-3"><p><strong>成员变量（属性）</strong>：</p><ul class="lvl-2"><li class="lvl-5">成员变量是类的一部分，用于存储数据。它们是类的属性，通常用于描述对象的状态。</li><li class="lvl-5">成员变量可以是私有的（private），这意味着它们只能被类内部的方法访问，或者可以是公有的（public），这意味着它们可以被任何其他类访问。</li><li class="lvl-5">成员变量可以有默认的访问修饰符（没有显式指定），这通常是包级私有的（即同一个包内的其他类可以访问）。</li></ul></li><li class="lvl-3"><p><strong>成员方法（行为）</strong>：</p><ul class="lvl-2"><li class="lvl-5">成员方法是类的一部分，定义了对象的行为。它们是类的操作，用于描述对象可以执行的动作。</li><li class="lvl-5">成员方法可以有不同的访问修饰符，如public、private或protected，这决定了它们可以被谁调用。</li><li class="lvl-5">方法还可以是静态的（static），这意味着它们属于类而不是类的实例，并且可以在不创建类实例的情况下被调用。</li></ul></li></ol><p>除了成员变量和成员方法，类的成员还可以包括：</p><ul class="lvl-0"><li class="lvl-2"><p><strong>构造方法</strong>：特殊的方法，用于创建类的对象。它们的名字必须与类名相同，并且没有返回类型。</p></li><li class="lvl-2"><p><strong>静态初始化块</strong>：用于初始化静态变量的代码块，它在类加载时执行一次。</p></li><li class="lvl-2"><p><strong>实例初始化块</strong>：用于初始化非静态变量的代码块，它在每次创建类的新实例时执行。</p></li><li class="lvl-2"><p><strong>内部类</strong>：定义在另一个类内部的类，它可以访问外部类的成员，包括私有成员。</p></li></ul><p>成员变量和方法的可见性和行为可以通过使用不同的访问修饰符和非访问修饰符来控制。例如：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ExampleClass</span> &#123;</span><br><span class="line">    <span class="comment">// 成员变量</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> privateVar;</span><br><span class="line">    <span class="keyword">protected</span> <span class="type">int</span> protectedVar;</span><br><span class="line">    <span class="type">int</span> packageVar; <span class="comment">// 默认访问修饰符，也称为包级私有</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> publicVar;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 构造方法</span></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">ExampleClass</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="comment">// 构造逻辑</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 成员方法</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">publicMethod</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="comment">// 方法逻辑</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">privateMethod</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="comment">// 私有方法逻辑</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 静态方法</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">staticMethod</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="comment">// 静态方法逻辑</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 实例初始化块</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">// 实例初始化逻辑</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 静态初始化块</span></span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        <span class="comment">// 静态初始化逻辑</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在这个例子中，<code>ExampleClass</code> 包含了不同类型的成员，包括私有和公有的成员变量，一个构造方法，公有和私有的成员方法，以及静态方法。静态初始化块和实例初始化块分别用于初始化静态成员和非静态成员。</p><hr><p>在Java语言中，<code>this</code> 是一个特殊的关键字，它指向当前对象的引用。每个对象都有一个隐式的 <code>this</code> 引用，指向它自己。以下是 <code>this</code> 关键字的一些常见用法：</p><ol><li class="lvl-3"><p><strong>区分成员变量和局部变量</strong>：当局部变量名与成员变量名相同时，可以使用 <code>this</code> 关键字来区分它们。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyClass</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> number;</span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">MyClass</span><span class="params">(<span class="type">int</span> number)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.number = number; <span class="comment">// 使用 this 来引用成员变量</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li class="lvl-3"><p><strong>在构造函数中调用另一个构造函数</strong>：可以使用 <code>this()</code> 来调用同一个类中的另一个构造函数。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyClass</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> number;</span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">MyClass</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>(<span class="number">0</span>); <span class="comment">// 默认构造函数调用带参数的构造函数</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">MyClass</span><span class="params">(<span class="type">int</span> number)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.number = number;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li class="lvl-3"><p><strong>在方法中返回当前对象的引用</strong>：有时，方法需要返回调用该方法的对象的引用，这时可以使用 <code>this</code>。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyClass</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> MyClass <span class="title function_">getNext</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="comment">// 一些逻辑...</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">this</span>; <span class="comment">// 返回当前对象的引用</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li class="lvl-3"><p><strong>在参数中传递当前对象</strong>：当需要将当前对象作为参数传递给另一个方法时，可以使用 <code>this</code>。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyClass</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">doSomething</span><span class="params">(MyClass other)</span> &#123;</span><br><span class="line">        other.copy(<span class="built_in">this</span>); <span class="comment">// 将当前对象作为参数传递</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">copy</span><span class="params">(MyClass other)</span> &#123;</span><br><span class="line">        <span class="comment">// 复制逻辑...</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li class="lvl-3"><p><strong>在匿名类和内部类中引用外部类的实例</strong>：在匿名类或内部类中，可以使用 <code>this</code> 关键字来引用外部类的实例。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">OuterClass</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">doSomething</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Thread</span>(<span class="keyword">new</span> <span class="title class_">Runnable</span>() &#123;</span><br><span class="line">            <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">                OuterClass.<span class="built_in">this</span>.doWork(); <span class="comment">// 调用外部类的 doWork 方法</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;).start();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">doWork</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="comment">// 工作逻辑...</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li class="lvl-3"><p><strong>在重载方法中使用</strong>：当类中有多个同名方法但参数列表不同时，可以使用 <code>this</code> 调用其他重载的方法。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyClass</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">print</span><span class="params">(<span class="type">int</span> number)</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;Number: &quot;</span> + number);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">print</span><span class="params">(String text)</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;Text: &quot;</span> + text);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">printAll</span><span class="params">(<span class="type">int</span> number, String text)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.print(number); <span class="comment">// 调用第一个 print 方法</span></span><br><span class="line">        <span class="built_in">this</span>.print(text); <span class="comment">// 调用第二个 print 方法</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><p><code>this</code> 关键字是Java中一个非常有用的工具，它允许程序员在各种情况下引用当前对象。</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Hexo搭建实遇问题</title>
      <link href="/2024/05/13/Hexo%E6%90%AD%E5%BB%BA%E5%AE%9E%E9%81%87%E9%97%AE%E9%A2%98/"/>
      <url>/2024/05/13/Hexo%E6%90%AD%E5%BB%BA%E5%AE%9E%E9%81%87%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h1>1.spawn_failed问题</h1><h2 id="原因分析：">原因分析：</h2><p>其实出现这个问题，很大可能是因为https和http的proxy的对应的分别是https和http开proxy server，</p><p>而https的proxy server可能无法正常工作。</p><h2 id="解决办法：">解决办法：</h2><p>修改_config.yml文件的deploy部分，将https 修改为http url 或者 设置为git url, 配置为https oauth2 加token</p><ul class="lvl-0"><li class="lvl-2"><p>设置为git url(推荐) 亲测有效</p></li></ul><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">deploy:</span><br><span class="line">    type: git</span><br><span class="line">    repo: git@github.com:your_github_id/your_github_id.github.io.git</span><br><span class="line">    branch: gh-pages</span><br></pre></td></tr></table></figure><h1>2.头像无法显示问题</h1><h2 id="原因分析：-2">原因分析：</h2><p>不明原因，猜测是路径问题</p><h2 id="解决方法1：">解决方法1：</h2><ol><li class="lvl-3"><p>将想要显示的头像图片存入本地文件夹</p></li><li class="lvl-3"><p>在根目录下进入git bash使用hexo g和hexo d上传代码到github仓库</p></li><li class="lvl-3"><p>在github仓库找到该图片，鼠标右键复制图片链接</p></li><li class="lvl-3"><p>修改主题配置文件，如我修改的为config.butterfly.yml文件</p></li></ol><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Avatar (頭像)</span></span><br><span class="line"><span class="attr">avatar:</span></span><br><span class="line">  <span class="attr">img:</span> <span class="string">输入你复制的图片链接</span></span><br><span class="line">  <span class="comment"># effect为true 则鼠标放于图片上，会使图片一直旋转</span></span><br><span class="line">  <span class="attr">effect:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure><h2 id="解决方法2：">解决方法2：</h2><p>更改默认头像路径</p><p>默认路径：<code>&quot;C:\Users\陈荣伟\Desktop\Blog\Hexo-blog\blog\themes\butterfly\source\img\friend_404.gif&quot;</code></p><p>把需要的 头像 名称改为<code>friend_404.gif</code>，把<code>friend_404.gif</code> 重命名 成别的即可</p><p>_config.butterfly.yml内的配置文件</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Replace Broken Images (替换无法显示的图片)</span></span><br><span class="line"><span class="attr">error_img:</span></span><br><span class="line">  <span class="attr">flink:</span> <span class="string">/img/friend_404.gif</span></span><br><span class="line">  <span class="attr">post_page:</span> <span class="string">/img/404.jpg</span></span><br></pre></td></tr></table></figure><h1>3.本地预览正常，但部署到GitHub 网站背景图片不加载</h1><h2 id="解决方法：">解决方法：</h2><ol><li class="lvl-3"><p>分清背景图片是放在本地还是别处？</p></li><li class="lvl-3"><p>记得用图片的网络链接，确保图片地址没有错误。</p></li><li class="lvl-3"><p>然后<strong>清除浏览器缓存</strong>再试试</p></li></ol><h2 id="hexo-clean命令">hexo clean命令</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo clean</span><br></pre></td></tr></table></figure><p>清除缓存文件 <code>db.json</code> 和已生成的静态文件 <code>public</code>。</p><ul class="lvl-0"><li class="lvl-2"><p>网站显示异常时可以执行这条命令试试。</p></li></ul><p>接着依次运行代码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo g</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo d</span><br></pre></td></tr></table></figure><h2 id="终极方法">终极方法</h2><p>删除<code>.deploy_git</code>和<code>public</code>文件</p><h1>4.插入图片的显示问题</h1><p>参考文章：</p><p><a href="https://blog.csdn.net/2301_77285173/article/details/130189857">在hexo博客中插入图片的方法_hexo插入图片-CSDN博客</a></p><p>插入图片的方法在完成了博客搭建、发布文章后，如果我们想在文章中插入图片，该怎么做呢？</p><p>如果图片保存在本地</p><h2 id="方法一：全局资源文件夹">方法一：全局资源文件夹</h2><p>即，将所有文章的资源统一用一个全局资源文件夹管理。</p><p>此方法的优点是比较简便，并且当多篇文章需要引用同一资源时，也比较方便。</p><p>缺点是当文章很多时，各个文章的图片都在同一文件夹，不便管理。</p><p><strong>具体方法</strong>：在hexo文件夹下的source目录下，新建一个文件夹叫images(名字随意)，将要插入的图片放在该文件夹中。<br>md文档内，使用<code>![图片](图片链接地址)</code>的格式，圆括号内的链接地址写<code>(/images/name.jpeg)</code>。这里的 / 指的是根目录，对于hexo，资源文件的根目录就是source(可以在config文件里修改资源的根目录)</p><p>例如，在md文档中写：<code>![图片](/images/20.jpeg &quot;甘雨&quot;)</code>同时将“20.jpeg”这个图片文件放在hexo文件夹<code>/source/images</code>下，则图片可以上传到博客。</p><h2 id="方法二：文章资源文件夹">方法二：文章资源文件夹</h2><p>即，对于每篇文章，使用一个文件夹管理资源。</p><p>此方法的优点是，当文章很多时，便于结构化管理。</p><p>缺点是，比方法一麻烦一点。</p><p><strong>具体方法</strong>：</p><p>2.1 修改hexo文件夹中的_config.yml文件，如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">post_asset_folder:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">marked:</span></span><br><span class="line">  <span class="attr">prependRoot:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">postAsset:</span> <span class="literal">true</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>2.2 在终端cd到hexo文件夹，<code>hexo new 文章名   </code>命令创建一篇新文章，此时会在hexo文件夹的source目录下，自动创建一个文件夹和文章名.md文件。</p><p><strong>注</strong>：如果文章名中有空格，务必将整个文章名用双引号引起来。如果文章名中没有空格，可以加双引号，也可以不加。</p><p>例如，执行hexo new “如何发布文章到hexo博客上”，如下：</p><p>会在<code>source/_post</code>文件夹下生成一个&quot;<a href="http://xn--hexo-394fj2eh8hiucp4ai03bhvfv7hwm1a9j2e.md">如何发布文章到hexo博客上.md</a>&quot;文件。如下：</p><p>可以看到，同时还生成了一个同名的资源文件夹。</p><p>2.3 我们可以将所有与该文章有关的资源（包括图片）放在这个关联文件夹中<br>2.4 通过<strong>相对路径</strong>来引用图片资源。</p><p>例如，将“1.jpeg”这个图片资源放在该文件夹中，并在.md文件中像这样引用图片：<code>![图片](1.jpeg)</code>，这个方法在资源较多时方便管理。</p><p>另附Typora编辑器中不显示图片的解决方案：安装下面的插件，可以使Typora等Markdown编辑器预览以及Hexo发布预览时，均能正常显示图片。<code>npm install hexo-asset-img --save</code><br>这样，如果你使用Typora编辑markdown文档，在typora内也可以显示图片了。</p><h1>5.4000端口占用问题</h1><h2 id="查看端口">查看端口:</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">netstat -ano</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">  每一列分别对应：协议、本地地址、外部地址、状态、PID  </span><br><span class="line"></span><br><span class="line">参数详解：</span><br><span class="line">  -a            显示所有连接和侦听端口。</span><br><span class="line">  -n            以数字形式显示地址和端口号。</span><br><span class="line">  -o            显示拥有的与每个连接关联的进程 ID。</span><br></pre></td></tr></table></figure><p>注：其余参数可使用help命令查看：</p><p><code>netstat -help</code></p><p>​        查询出的端口数量很多，我们可使用findstr命令进行过滤：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">netstat -ano | findstr &quot;被占用的端口&quot;</span><br></pre></td></tr></table></figure><h2 id="释放被占用的端口："><strong>释放被占用的端口</strong>：</h2><p>​      过滤出需要释放的端口后，在cmd窗口输入<code>task kill命令 </code>可释放被占用的端口：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">taskkill -f -t /pid &quot;占用端口的程序的pid&quot;</span><br></pre></td></tr></table></figure><h1>6.网页渲染Latex问题</h1><p>修改主题配置文件<code>_config.butterfly.yml</code>：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">mathjax:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="comment"># true 表示每一頁都加載mathjax.js</span></span><br><span class="line">  <span class="comment"># false 需要時加載，須在使用的Markdown Front-matter 加上 mathjax: true</span></span><br><span class="line">  <span class="attr">per_page:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure><p>以下操作在你 hexo 博客的目录下 (不是 Butterfly 的目录):</p><ol><li class="lvl-3"><p>安装插件</p></li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">npm uninstall hexo-renderer-marked --save</span><br><span class="line">npm install hexo-renderer-kramed --save</span><br></pre></td></tr></table></figure><ol start="2"><li class="lvl-3"><p>配置 hexo 根目录的配置文件<code>_config.yml</code></p></li></ol><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kramed:</span></span><br><span class="line">  <span class="attr">gfm:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">pedantic:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">sanitize:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">tables:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">breaks:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">smartLists:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">smartypants:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><h1>7.引入CSS文件</h1><p>打开config.butterfly.yml文件</p><p>CTRL+F 搜索下面的代码，增加<code>&lt;link&gt;</code>标签即可</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">inject:</span></span><br><span class="line">  <span class="attr">head:</span></span><br><span class="line">    <span class="comment"># - &lt;link rel=&quot;stylesheet&quot; href=&quot;/xxx.css&quot;&gt;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&lt;link</span> <span class="string">rel=&quot;stylesheet&quot;</span> <span class="string">href=&quot;/css/categories_dark_fit.css&quot;&gt;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&lt;link</span> <span class="string">rel=&quot;stylesheet&quot;</span> <span class="string">href=&quot;/css/butterfly_article_double_row.css&quot;&gt;</span></span><br><span class="line">  <span class="attr">bottom:</span></span><br><span class="line">    <span class="comment"># - &lt;script src=&quot;xxxx&quot;&gt;&lt;/script&gt;</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Blog搭建 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Front-matter模板</title>
      <link href="/2024/05/12/Front-matter%E6%A8%A1%E6%9D%BF/"/>
      <url>/2024/05/12/Front-matter%E6%A8%A1%E6%9D%BF/</url>
      
        <content type="html"><![CDATA[<p><code>Front-matter</code> 是 markdown 文件最上方以<code>---</code>分隔的区域，用于指定个别档案的变数</p><ul class="lvl-0"><li class="lvl-2">Page Front-matter 用于页面配置</li><li class="lvl-2">Post Front-matter 用于文章页配置</li></ul><p>如果标注可选的参数，可根据自己需要添加，不用全部都写</p><p><strong>Page Front-matter：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">MARKDOWN</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">title:</span><br><span class="line">date:</span><br><span class="line">updated:</span><br><span class="line">type:</span><br><span class="line">comments:</span><br><span class="line">description:</span><br><span class="line">keywords:</span><br><span class="line">top_img:</span><br><span class="line">mathjax:</span><br><span class="line">katex:</span><br><span class="line">aside:</span><br><span class="line">aplayer:</span><br><span class="line">highlight_shrink:</span><br><span class="line">---</span><br></pre></td></tr></table></figure><table><thead><tr><th style="text-align:left">写法</th><th>解释</th></tr></thead><tbody><tr><td style="text-align:left">title</td><td>【必需】页面标题</td></tr><tr><td style="text-align:left">date</td><td>【必需】页面创建日期</td></tr><tr><td style="text-align:left">type</td><td>【必需】标籤、分类和友情链接三个页面需要配置</td></tr><tr><td style="text-align:left">updated</td><td>【可选】页面更新日期</td></tr><tr><td style="text-align:left">description</td><td>【可选】页面描述</td></tr><tr><td style="text-align:left">keywords</td><td>【可选】页面关键字</td></tr><tr><td style="text-align:left">comments</td><td>【可选】显示页面评论模块(默认 true)</td></tr><tr><td style="text-align:left">top_img</td><td>【可选】页面顶部图片</td></tr><tr><td style="text-align:left">mathjax</td><td>【可选】显示mathjax(当设置mathjax的per_page: false时，才需要配置，默认 false)</td></tr><tr><td style="text-align:left">kates</td><td>【可选】显示katex(当设置katex的per_page: false时，才需要配置，默认 false)</td></tr><tr><td style="text-align:left">aside</td><td>【可选】显示侧边栏 (默认 true)</td></tr><tr><td style="text-align:left">aplayer</td><td>【可选】在需要的页面加载aplayer的js和css,请参考文章下面的音乐 配置</td></tr><tr><td style="text-align:left">highlight_shrink</td><td>【可选】配置代码框是否展开(true/false)(默认为设置中highlight_shrink的配置)</td></tr></tbody></table><p><strong>Post Front-matter：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">MARKDOWN</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">title:</span><br><span class="line">date:</span><br><span class="line">updated:</span><br><span class="line">tags:</span><br><span class="line">categories:</span><br><span class="line">keywords:</span><br><span class="line">description:</span><br><span class="line">top_img:</span><br><span class="line">comments:</span><br><span class="line">cover:</span><br><span class="line">toc:</span><br><span class="line">toc_number:</span><br><span class="line">toc_style_simple:</span><br><span class="line">copyright:</span><br><span class="line">copyright_author:</span><br><span class="line">copyright_author_href:</span><br><span class="line">copyright_url:</span><br><span class="line">copyright_info:</span><br><span class="line">mathjax:</span><br><span class="line">katex:</span><br><span class="line">aplayer:</span><br><span class="line">highlight_shrink:</span><br><span class="line">aside:</span><br><span class="line">---</span><br></pre></td></tr></table></figure><table><thead><tr><th>写法</th><th>解释</th></tr></thead><tbody><tr><td>title</td><td>【必需】文章标题</td></tr><tr><td>date</td><td>【必需】文章创建日期</td></tr><tr><td>updated</td><td>【可选】文章更新日期</td></tr><tr><td>tags</td><td>【可选】文章标籤</td></tr><tr><td>categories</td><td>【可选】文章分类</td></tr><tr><td>keywords</td><td>【可选】文章关键字</td></tr><tr><td>description</td><td>【可选】文章描述</td></tr><tr><td>top_img</td><td>【可选】文章顶部图片</td></tr><tr><td>cover</td><td>【可选】文章缩略图(如果没有设置top_img,文章页顶部将显示缩略图，可设为false/图片地址/留空)</td></tr><tr><td>comments</td><td>【可选】显示文章评论模块(默认 true)</td></tr><tr><td>toc</td><td>【可选】显示文章TOC(默认为设置中toc的enable配置)</td></tr><tr><td>toc_number</td><td>【可选】显示toc_number(默认为设置中toc的number配置)</td></tr><tr><td>toc_style_simple</td><td>【可选】显示 toc 简洁模式</td></tr><tr><td>copyright</td><td>【可选】显示文章版权模块(默认为设置中post_copyright的enable配置)</td></tr><tr><td>copyright_author</td><td>【可选】文章版权模块的文章作者</td></tr><tr><td>copyright_author_href</td><td>【可选】文章版权模块的文章作者链接</td></tr><tr><td>copyright_url</td><td>【可选】文章版权模块的文章连结链接</td></tr><tr><td>copyright_info</td><td>【可选】文章版权模块的版权声明文字</td></tr><tr><td>mathjax</td><td>【可选】显示mathjax(当设置mathjax的per_page: false时，才需要配置，默认 false)</td></tr><tr><td>katex</td><td>【可选】显示katex(当设置katex的per_page: false时，才需要配置，默认 false)</td></tr><tr><td>aplayer</td><td>【可选】在需要的页面加载aplayer的js和css,请参考文章下面的音乐 配置</td></tr><tr><td>highlight_shrink</td><td>【可选】配置代码框是否展开(true/false)(默认为设置中highlight_shrink的配置)</td></tr><tr><td>aside</td><td>【可选】显示侧边栏 (默认 true)</td></tr></tbody></table><p>注意：我的博客根目录路径为 【D:/Blog/】，下文所说的根目录都是此路径，将用[BlogRoot]代替。</p>]]></content>
      
      
      <categories>
          
          <category> Blog搭建 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>My first blog</title>
      <link href="/2024/04/23/My-first-blog/"/>
      <url>/2024/04/23/My-first-blog/</url>
      
        <content type="html"><![CDATA[<h1>大事件</h1><p>芜湖！成功部署blog！૮(˶ᵔ ᵕ ᵔ˶)ა</p><p>以后就在这上面写学习总结输出了！</p><p>之后还要完善页面渲染哈，今天就先收工啦 ૮(∪｡∪)ა｡｡｡zzzzz</p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
