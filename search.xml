<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title></title>
      <link href="/2024/10/19/%E3%80%90Note2%E3%80%91%E9%87%91%E8%9E%8D%E5%B8%82%E5%9C%BA%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/"/>
      <url>/2024/10/19/%E3%80%90Note2%E3%80%91%E9%87%91%E8%9E%8D%E5%B8%82%E5%9C%BA%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/</url>
      
        <content type="html"><![CDATA[<h2 id="宏观经济学基础概念"><a href="#宏观经济学基础概念" class="headerlink" title="宏观经济学基础概念"></a>宏观经济学基础概念</h2><h3 id="1-社会融资规模（社融）"><a href="#1-社会融资规模（社融）" class="headerlink" title="1. 社会融资规模（社融）"></a>1. <strong>社会融资规模（社融）</strong></h3><p>社融是指居民和企业从金融体系里拿到的资金总量，可以理解为金融部门给企业和个人提供的“贷款和投资的总包裹”。社融里包含两大块：</p><ul><li><strong>表内业务</strong>：计入银行账本的，比如普通的人民币贷款。</li><li><strong>表外业务</strong>：不计入银行账本的，比如一些信托贷款等。</li></ul><p>通常看社融新增的部分，主要看 <strong>人民币贷款、政府债券和企业债券</strong>，这三项加起来占社融的90%。这些数据可以帮助判断各类部门对资金的需求，比如：</p><ul><li><strong>人民币贷款</strong>：看居民贷款多不多，反映他们对未来经济的信心。</li><li><strong>政府债券</strong>：政府借钱搞建设，通常在经济下行时加大投入，拉动经济。</li></ul><h3 id="2-广义货币供应量（M2）"><a href="#2-广义货币供应量（M2）" class="headerlink" title="2. 广义货币供应量（M2）"></a>2. <strong>广义货币供应量（M2）</strong></h3><p>M2简单来说就是“市场上流通的现金+存款的总量”，它代表货币供应的总量。如果M2增速加快，说明市场上钱变多了，大家手头的钱多了，消费可能增加，但也可能带来 <strong>通货膨胀</strong>（东西涨价）。</p><ul><li><strong>社融-M2增速差</strong>：如果社融增速快，说明企业借债融资的需求比较旺盛。</li><li><strong>M1-M2增速差</strong>：M1是现金和活期存款，增速差值大表示流动性强，投资环境好。</li></ul><h3 id="3-利率"><a href="#3-利率" class="headerlink" title="3. 利率"></a>3. <strong>利率</strong></h3><p>利率可以简单理解为“借钱的成本”。利率越高，借钱越贵，企业和个人就会少借钱；利率越低，借钱成本低，企业更愿意借钱投入生产。常见的几种利率：</p><ul><li><strong>SHIBOR</strong>：银行间互相借钱的利率，反映了银行间资金的充裕程度。降了说明市场上资金充裕。</li><li><strong>LPR</strong>：银行借钱给企业或居民的利率。企业融资成本增加还是减少，直接影响生产和投资。</li><li><strong>国债收益率</strong>：政府债券的利率，政府通过调节债券收益来影响经济。</li></ul><h3 id="4-存款准备金"><a href="#4-存款准备金" class="headerlink" title="4. 存款准备金"></a>4. <strong>存款准备金</strong></h3><p>银行每吸收一笔存款，必须预留一部分钱上交央行，确保银行有足够的钱应付客户提取存款。这就是 <strong>存款准备金</strong>。央行通过调整 <strong>存款准备金率</strong>，来影响市场的资金流动性。比如“降准”就是让银行交的准备金减少，银行手里钱多了，可以多放贷，市场上钱就变多。</p><h3 id="5-CPI（消费者价格指数）"><a href="#5-CPI（消费者价格指数）" class="headerlink" title="5. CPI（消费者价格指数）"></a>5. <strong>CPI（消费者价格指数）</strong></h3><p>CPI是用来衡量居民日常生活中买的商品和服务的价格变化，比如食品、衣服、房租等。CPI上涨，说明物价涨了，生活成本也高了。通常，CPI增幅超过3%，就代表通货膨胀。</p><h3 id="6-社会消费品零售总额（社零）"><a href="#6-社会消费品零售总额（社零）" class="headerlink" title="6. 社会消费品零售总额（社零）"></a>6. <strong>社会消费品零售总额（社零）</strong></h3><p>社零就是社会上所有卖给个人或单位用于消费的商品和服务的总金额，比如日常买的衣服、鞋子、食品等消费品。这个数据反映了整个经济体内的消费能力和意愿。经济好，大家有钱消费，社零就高；经济不好，消费就少。</p><h3 id="7-固定资产投资"><a href="#7-固定资产投资" class="headerlink" title="7. 固定资产投资"></a>7. <strong>固定资产投资</strong></h3><p>固定资产投资是指用于建设或购买长久使用的资产，比如修路、建工厂等。它对GDP增长影响很大，尤其是 <strong>基建投资</strong>，比如修桥铺路，能带动原材料需求和就业。</p><h3 id="8-PPI（工业生产者出厂价格指数）"><a href="#8-PPI（工业生产者出厂价格指数）" class="headerlink" title="8. PPI（工业生产者出厂价格指数）"></a>8. <strong>PPI（工业生产者出厂价格指数）</strong></h3><p>PPI是企业卖出产品时的价格变化，主要反映生产领域的价格波动。它通常滞后于经济形势的变化，比如经济变好，企业生产多了，才会导致PPI上涨。PPI上涨说明工业产品的成本增加，经济可能过热。</p><h3 id="9-PMI（采购经理人指数）"><a href="#9-PMI（采购经理人指数）" class="headerlink" title="9. PMI（采购经理人指数）"></a>9. <strong>PMI（采购经理人指数）</strong></h3><p>PMI是通过调查企业采购经理人得到的指标，反映经济活动的整体状况。它是一个 <strong>先行指标</strong>，能快速反映经济的变化。如果PMI大于50，说明经济活动在扩张，小于50说明在收缩。PMI可以帮助预测经济走势。</p><p>这些指标帮助我们了解经济运行情况，从货币供应、物价、消费到企业的生产和投资计划。</p><h2 id="投资学基础概念简介"><a href="#投资学基础概念简介" class="headerlink" title="投资学基础概念简介"></a>投资学基础概念简介</h2><p>投资学是一门研究投资行为与市场定价的学科，涵盖了金融市场的复杂性与投资者行为的多样性。以下是投资学中的几个关键概念，帮助理解投资的基本框架。</p><h4 id="1-什么是投资？"><a href="#1-什么是投资？" class="headerlink" title="1. 什么是投资？"></a>1. 什么是投资？</h4><p>投资是指为了获得未来的回报而牺牲当下的消费。著名经济学家William F. Sharpe（1990年诺贝尔经济学奖获得者）将投资定义为在不确定的未来收益中做出确定的当前投入。</p><p>投资有三大特点：</p><ul><li><strong>时间性</strong>：投资是当下消费的牺牲，换取未来的更大收益。</li><li><strong>不确定性</strong>：未来的回报存在风险，收益无法保证。</li><li><strong>收益性</strong>：投资者期望通过投资增加财富以满足未来的消费需求。</li></ul><h4 id="2-投资学的主要内容"><a href="#2-投资学的主要内容" class="headerlink" title="2. 投资学的主要内容"></a>2. 投资学的主要内容</h4><p>投资学的核心是研究投资行为及定价机制，包括以下几个部分。</p><h4 id="2-1-金融市场与投资环境"><a href="#2-1-金融市场与投资环境" class="headerlink" title="2.1 金融市场与投资环境"></a>2.1 金融市场与投资环境</h4><p>金融市场通过提供资金流动，连接了投资者与融资者。市场中的金融资产大致分为以下几类：</p><ul><li><strong>固定收益证券</strong>：如债券，提供相对稳定的利息收入。</li><li><strong>权益型证券</strong>：如股票，收益取决于公司表现。</li><li><strong>基金</strong>：将投资者资金集中投资于多种证券。</li><li><strong>衍生品</strong>：如期货、期权，通过与其他资产价格相关获得收益。</li></ul><h4 id="2-2-债券市场的意义"><a href="#2-2-债券市场的意义" class="headerlink" title="2.2 债券市场的意义"></a>2.2 债券市场的意义</h4><p>债券市场是金融市场中重要的一部分，起到融资和利率平衡的作用。债券市场通过利率的波动反映市场的资金成本，并影响整体经济活动。</p><h4 id="2-3-金融市场与经济"><a href="#2-3-金融市场与经济" class="headerlink" title="2.3 金融市场与经济"></a>2.3 金融市场与经济</h4><p>金融市场的信息流动性为资本分配提供了依据，并通过帮助企业融资推动经济发展。投资者通过金融市场分散风险、储存财富以及规划消费时机。</p><h4 id="3-投资过程"><a href="#3-投资过程" class="headerlink" title="3. 投资过程"></a>3. 投资过程</h4><p>投资过程包括两个主要步骤：</p><ul><li><strong>资产配置</strong>：选择不同类别的资产（如股票、债券）进行分散投资。</li><li><strong>证券选择</strong>：根据市场分析，选择具体的证券进行投资。</li></ul><h4 id="4-市场参与者与市场类型"><a href="#4-市场参与者与市场类型" class="headerlink" title="4. 市场参与者与市场类型"></a>4. 市场参与者与市场类型</h4><p>金融市场中包括了以下参与者：</p><ul><li><strong>公司</strong>：通过市场借款进行投资。</li><li><strong>家庭</strong>：通过储蓄向市场提供资金。</li><li><strong>政府</strong>：在不同的时期可能是借款者或储蓄者。</li><li><strong>金融中介</strong>：如银行、保险公司，通过集资投资。</li></ul><h4 id="5-主要市场"><a href="#5-主要市场" class="headerlink" title="5. 主要市场"></a>5. 主要市场</h4><p>投资市场可以分为多个类别，包括债券市场、外汇市场、贵金属市场、大宗商品市场和股票市场。每个市场有不同的特点与投资机会，例如债券市场中，利率与债券价格成反比，外汇市场则受汇率波动影响较大。</p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>投资学作为一门学科，研究的是如何通过市场配置资本，获得最佳收益的科学。它涵盖了金融市场、风险分配、资产配置等多方面内容，帮助投资者更好地理解市场运作和投资策略。</p><h2 id="货币金融学基础概念简述"><a href="#货币金融学基础概念简述" class="headerlink" title="货币金融学基础概念简述"></a><strong>货币金融学基础概念简述</strong></h2><p>在当今经济生活中，金融学是一门与我们密切相关的学科，而货币金融学则是其中的重要组成部分。理解金融市场、货币政策、利率等基础概念，不仅能够帮助我们更好地参与金融活动，还可以使我们更好地把握经济趋势。这篇博客将简要介绍货币金融学的几个核心概念。</p><h3 id="1-金融市场概述"><a href="#1-金融市场概述" class="headerlink" title="1. 金融市场概述"></a>1. 金融市场概述</h3><p><strong>金融市场</strong>是资金从盈余方流向短缺方的场所，它在促进资金流动、提高经济效率方面发挥了重要作用。金融市场的两大主要市场是<strong>债券市场</strong>和<strong>股票市场</strong>。</p><ul><li><p><strong>债券市场</strong>：这是发行和买卖债券的地方。债券可以看作是“借款的欠条”，借款人通过发行债券承诺未来定期支付利息。债券市场的重要性在于它提供了企业和政府筹集长期资金的渠道。</p></li><li><p><strong>股票市场</strong>：这是买卖股票的场所。股票代表的是公司所有权的凭证，持有股票的人拥有公司的一部分权利，如参与分红和资产分配。</p></li></ul><p>除了这两个市场，<strong>外汇市场</strong>也是重要的一部分。外汇市场是国家间货币兑换的场所，汇率的波动能够影响进出口和整体经济状况。</p><h3 id="2-货币与货币政策"><a href="#2-货币与货币政策" class="headerlink" title="2. 货币与货币政策"></a>2. 货币与货币政策</h3><p><strong>货币</strong>是普遍被接受用于付款或还债的物品。在货币体系中，政府和中央银行通过<strong>货币政策</strong>来管理一国的货币供应和利率。货币政策能够对通货膨胀、就业和经济增长产生重大影响。</p><ul><li><p><strong>通货膨胀</strong>指的是物价水平的持续上涨，这会削弱货币的购买力。为应对通胀，中央银行可以调整利率，控制货币供应，维持物价稳定。</p></li><li><p><strong>货币政策</strong>通常由中央银行实施，如美国的美联储（Fed）。通过调节货币供应和利率，央行可以稳定经济、控制通货膨胀和促进就业。</p></li></ul><h3 id="3-利率与债券"><a href="#3-利率与债券" class="headerlink" title="3. 利率与债券"></a>3. 利率与债券</h3><p><strong>利率</strong>是借贷成本的表现形式。它不仅影响债务成本，还直接关系到储蓄、投资以及整体经济的健康。</p><ul><li><p><strong>现值</strong>（PV）概念：现值是未来某笔收入在今天的价值，它反映了货币时间价值的概念。在利率计算中，我们可以用现值公式计算投资的回报。</p></li><li><p><strong>信用市场工具</strong>：常见的有普通贷款、固定支付贷款、息票债券和贴现债券。每种工具都有不同的付息方式和本金偿还模式，这些工具为金融市场中的借贷方和贷款方提供了多样化的选择。</p></li></ul><p><strong>名义利率</strong>与<strong>实际利率</strong>是评估借贷成本时的两个重要指标。名义利率是未调整通货膨胀的利率，而实际利率则是调整后的真实借贷成本。根据<strong>费雪定理</strong>，名义利率等于实际利率加上通货膨胀率。</p><h3 id="4-利率的风险结构与期限结构"><a href="#4-利率的风险结构与期限结构" class="headerlink" title="4. 利率的风险结构与期限结构"></a>4. 利率的风险结构与期限结构</h3><p>债券和贷款的<strong>利率结构</strong>受到多种因素影响，尤其是<strong>违约风险</strong>和<strong>流动性</strong>。违约风险指借款人无法按时支付本金或利息的风险。违约风险高的债券通常会提供更高的收益率来补偿投资者。与此类似，流动性差的债券也会提供较高的收益率，称为<strong>流动性溢价</strong>。</p><p><strong>期限结构</strong>反映了同一类债券中不同到期期限的利率差异。收益率曲线通常向上倾斜，意味着长期债券的利率通常高于短期债券，这是因为投资者要求更高的回报来补偿长期的不确定性。</p><h3 id="5-货币供给过程"><a href="#5-货币供给过程" class="headerlink" title="5. 货币供给过程"></a>5. 货币供给过程</h3><p><strong>货币供给</strong>指的是一国银行系统向经济中投入、创造、扩张或收缩货币的过程。在这个过程中，<strong>中央银行</strong>、<strong>商业银行</strong>和<strong>储户</strong>是主要的参与者。中央银行通过公开市场操作、调整法定准备金率等方式调节货币供给，而商业银行则通过存款和贷款机制影响货币创造。</p><p>货币供给的扩展可以通过<strong>多倍存款创造</strong>的方式实现。银行体系中的存款增加会引发贷款增加，最终引发整个货币供应量的扩张。货币政策的有效性往往与这些机制息息相关。</p><h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><p>货币金融学涉及许多复杂的概念，但其核心在于理解金融市场的运作机制、货币政策的影响以及利率对经济的调节作用。通过掌握这些基础知识，我们可以更好地理解金融市场的动态，进而在个人和企业层面做出更明智的经济决策。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>【Note1】投资与量化投资</title>
      <link href="/2024/10/15/%E3%80%90Note1%E3%80%91%E6%8A%95%E8%B5%84%E4%B8%8E%E9%87%8F%E5%8C%96%E6%8A%95%E8%B5%84/"/>
      <url>/2024/10/15/%E3%80%90Note1%E3%80%91%E6%8A%95%E8%B5%84%E4%B8%8E%E9%87%8F%E5%8C%96%E6%8A%95%E8%B5%84/</url>
      
        <content type="html"><![CDATA[<h2 id="投资与量化投资"><a href="#投资与量化投资" class="headerlink" title="投资与量化投资"></a>投资与量化投资</h2><h3 id="1-1-什么是投资"><a href="#1-1-什么是投资" class="headerlink" title="1.1 什么是投资"></a>1.1 什么是投资</h3><p>投资是为获得一定的预期社会经济效益而进行的资金或资本物的投入及其活动过程。投资可以发生在很多领域，如固定资产投资、证券投资、教育投资等。投资的风险与利益并存，有可能产生资产减值、时间浪费等损失。</p><h3 id="1-2-股票投资的基本流程"><a href="#1-2-股票投资的基本流程" class="headerlink" title="1.2 股票投资的基本流程"></a>1.2 股票投资的基本流程</h3><p>股票交易流程大致包括选择证券公司、开户、转入资金、选股、买入、持有和卖出等步骤。</p><h3 id="1-3-常见的股票投资分析流派"><a href="#1-3-常见的股票投资分析流派" class="headerlink" title="1.3 常见的股票投资分析流派"></a>1.3 常见的股票投资分析流派</h3><ul><li><strong>宏观策略分析法</strong>：从宏观经济变化的大方向入手，应用到具体的股票投资中。</li><li><strong>价值投资法</strong>：选股，选出有巨大增值潜力的股票，长期持有。</li><li><strong>主题事件投资法</strong>：对某一事件发展趋势进行判断，寻找投资机会。</li><li><strong>技术分析法</strong>：以股价为研究对象，从股价变化的历史走势着手，预测未来价格趋势。</li><li><strong>量化投资法</strong>：利用统计学、数学、信息技术等方法取代人工作出决策，通过模型完成股票交易。</li></ul><h3 id="1-4-什么是量化投资"><a href="#1-4-什么是量化投资" class="headerlink" title="1.4 什么是量化投资"></a>1.4 什么是量化投资</h3><p>量化投资是一种利用计算机技术和数学模型来实现投资策略的方法。它通过数量化和程序化的方式来进行买卖，具有客观、系统、自动化的特点。</p><h3 id="1-5-量化投资的历史发展"><a href="#1-5-量化投资的历史发展" class="headerlink" title="1.5 量化投资的历史发展"></a>1.5 量化投资的历史发展</h3><p>量化投资起源于60年代的美国，由爱德华·索普创立，后发展为科学股票市场系统。90年代是量化投资发展的黄金期，各大理论全面发展。</p><h3 id="1-6-量化投资的一般流程"><a href="#1-6-量化投资的一般流程" class="headerlink" title="1.6 量化投资的一般流程"></a>1.6 量化投资的一般流程</h3><p>量化投资的一般流程包括策略设计、回测验证、模拟盘验证、实盘交易等步骤。</p><h3 id="1-7-常见的量化投资平台"><a href="#1-7-常见的量化投资平台" class="headerlink" title="1.7 常见的量化投资平台"></a>1.7 常见的量化投资平台</h3><p>常见的量化投资平台包括聚宽（JoinQuant）、掘金（Myquant）、Bigquant、米筐（Ricequant）、真格量化等，它们提供了数据、研究、回测、模拟交易和实盘交易等功能。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>【cv-AI攻防】-Task1：赛题方案解读</title>
      <link href="/2024/10/12/%E3%80%90cv-AI%E6%94%BB%E9%98%B2%E3%80%91-Task1%EF%BC%9A%E8%B5%9B%E9%A2%98%E6%96%B9%E6%A1%88%E8%A7%A3%E8%AF%BB/"/>
      <url>/2024/10/12/%E3%80%90cv-AI%E6%94%BB%E9%98%B2%E3%80%91-Task1%EF%BC%9A%E8%B5%9B%E9%A2%98%E6%96%B9%E6%A1%88%E8%A7%A3%E8%AF%BB/</url>
      
        <content type="html"><![CDATA[<h1 id="步骤一：构建YOLO数据集"><a href="#步骤一：构建YOLO数据集" class="headerlink" title="步骤一：构建YOLO数据集"></a>步骤一：构建YOLO数据集</h1><p>由于比赛原始数据集较大，我们采样部分数据构建训练集和验证集：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> os.path.exists(<span class="string">&#x27;yolo_seg_dataset&#x27;</span>):</span><br><span class="line">    shutil.rmtree(<span class="string">&#x27;yolo_seg_dataset&#x27;</span>)</span><br><span class="line"></span><br><span class="line">os.makedirs(<span class="string">&#x27;yolo_seg_dataset/train&#x27;</span>)</span><br><span class="line">os.makedirs(<span class="string">&#x27;yolo_seg_dataset/valid&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">normalize_polygon</span>(<span class="params">polygon, img_width, img_height</span>):</span><br><span class="line">    <span class="keyword">return</span> [(x / img_width, y / img_height) <span class="keyword">for</span> x, y <span class="keyword">in</span> polygon]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 采样训练集</span></span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> training_anno.iloc[:<span class="number">10000</span>].iterrows():</span><br><span class="line">    shutil.copy(row[<span class="number">1</span>].Path, <span class="string">&#x27;yolo_seg_dataset/train&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    img = cv2.imread(row[<span class="number">1</span>].Path)</span><br><span class="line">    img_height, img_width = img.shape[:<span class="number">2</span>]</span><br><span class="line">    txt_filename = os.path.join(<span class="string">&#x27;yolo_seg_dataset/train/&#x27;</span> + row[<span class="number">1</span>].Path.split(<span class="string">&#x27;/&#x27;</span>)[-<span class="number">1</span>][:-<span class="number">4</span>] + <span class="string">&#x27;.txt&#x27;</span>)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(txt_filename, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> up:</span><br><span class="line">        <span class="keyword">for</span> polygon <span class="keyword">in</span> row[<span class="number">1</span>].Polygons:</span><br><span class="line">            normalized_polygon = normalize_polygon(polygon, img_width, img_height)</span><br><span class="line">            normalized_coords = <span class="string">&#x27; &#x27;</span>.join([<span class="string">f&#x27;<span class="subst">&#123;coord[<span class="number">0</span>]:<span class="number">.3</span>f&#125;</span> <span class="subst">&#123;coord[<span class="number">1</span>]:<span class="number">.3</span>f&#125;</span>&#x27;</span> <span class="keyword">for</span> coord <span class="keyword">in</span> normalized_polygon])</span><br><span class="line">            up.write(<span class="string">f&#x27;0 <span class="subst">&#123;normalized_coords&#125;</span>\n&#x27;</span>)</span><br><span class="line"> </span><br><span class="line"> <span class="comment"># 采用验证集     </span></span><br><span class="line"> <span class="keyword">for</span> row <span class="keyword">in</span> training_anno.iloc[<span class="number">10000</span>:<span class="number">10150</span>].iterrows():</span><br><span class="line">    shutil.copy(row[<span class="number">1</span>].Path, <span class="string">&#x27;yolo_seg_dataset/valid&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    img = cv2.imread(row[<span class="number">1</span>].Path)</span><br><span class="line">    img_height, img_width = img.shape[:<span class="number">2</span>]</span><br><span class="line">    txt_filename = os.path.join(<span class="string">&#x27;yolo_seg_dataset/valid/&#x27;</span> + row[<span class="number">1</span>].Path.split(<span class="string">&#x27;/&#x27;</span>)[-<span class="number">1</span>][:-<span class="number">4</span>] + <span class="string">&#x27;.txt&#x27;</span>)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(txt_filename, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> up:</span><br><span class="line">        <span class="keyword">for</span> polygon <span class="keyword">in</span> row[<span class="number">1</span>].Polygons:</span><br><span class="line">            normalized_polygon = normalize_polygon(polygon, img_width, img_height)</span><br><span class="line">            normalized_coords = <span class="string">&#x27; &#x27;</span>.join([<span class="string">f&#x27;<span class="subst">&#123;coord[<span class="number">0</span>]:<span class="number">.3</span>f&#125;</span> <span class="subst">&#123;coord[<span class="number">1</span>]:<span class="number">.3</span>f&#125;</span>&#x27;</span> <span class="keyword">for</span> coord <span class="keyword">in</span> normalized_polygon])</span><br><span class="line">            up.write(<span class="string">f&#x27;0 <span class="subst">&#123;normalized_coords&#125;</span>\n&#x27;</span>)</span><br></pre></td></tr></table></figure></p><h1 id="逐行代码分析"><a href="#逐行代码分析" class="headerlink" title="逐行代码分析"></a>逐行代码分析</h1><p>好的，我们逐行分析这段代码，它的主要功能是将训练集和验证集的数据从原始数据集中复制到新的目录中，并将多边形的坐标标准化为相对坐标。</p><h3 id="代码逐行分析"><a href="#代码逐行分析" class="headerlink" title="代码逐行分析"></a>代码逐行分析</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> os.path.exists(<span class="string">&#x27;yolo_seg_dataset&#x27;</span>):</span><br><span class="line">    shutil.rmtree(<span class="string">&#x27;yolo_seg_dataset&#x27;</span>)</span><br></pre></td></tr></table></figure><ul><li><strong>功能</strong>: 检查<code>yolo_seg_dataset</code>目录是否存在。如果存在，则使用<code>shutil.rmtree</code>删除该目录及其内容。<code>shutil</code>常用于文件与目录的处理。</li><li><strong>目的</strong>: 确保每次运行代码时，数据集是干净的，没有旧的数据。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">os.makedirs(<span class="string">&#x27;yolo_seg_dataset/train&#x27;</span>)</span><br><span class="line">os.makedirs(<span class="string">&#x27;yolo_seg_dataset/valid&#x27;</span>)</span><br></pre></td></tr></table></figure><ul><li><strong>功能</strong>: 创建两个新的子目录<code>train</code>和<code>valid</code>，用于存放训练集和验证集数据。</li><li><strong>目的</strong>: 为之后的文件复制和标签文件创建所需的目录结构。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">normalize_polygon</span>(<span class="params">polygon, img_width, img_height</span>):</span><br><span class="line">    <span class="keyword">return</span> [(x / img_width, y / img_height) <span class="keyword">for</span> x, y <span class="keyword">in</span> polygon]</span><br></pre></td></tr></table></figure><ul><li><strong>功能</strong>: 定义一个函数<code>normalize_polygon</code>，它接受一个多边形的坐标（列表形式），以及图像的宽度和高度。该函数返回归一化后的坐标，归一化的方式是将每个坐标除以图像的宽度和高度。</li><li><strong>目的</strong>: ==将坐标转换为相对坐标，使其在不同尺寸的图像中具有一致性==。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 采样训练集</span></span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> training_anno.iloc[:<span class="number">10000</span>].iterrows():</span><br></pre></td></tr></table></figure><ul><li><strong>功能</strong>: 遍历<code>training_anno</code>数据框的前10000行。<code>iterrows()</code>方法用于<font color="#ff0000">逐行迭代数据框</font>，并返回行的索引和行的内容。</li><li><strong>目的</strong>: 处理训练集中的前10000条数据。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shutil.copy(row[<span class="number">1</span>].Path, <span class="string">&#x27;yolo_seg_dataset/train&#x27;</span>)</span><br></pre></td></tr></table></figure><ul><li><strong>功能</strong>: 将当前行的图像文件从原始路径复制到<code>yolo_seg_dataset/train</code>目录。</li><li><strong>目的</strong>: 将图像文件放入训练集目录中。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">img = cv2.imread(row[<span class="number">1</span>].Path)</span><br><span class="line">img_height, img_width = img.shape[:<span class="number">2</span>]</span><br></pre></td></tr></table></figure><ul><li><strong>功能</strong>: 使用OpenCV读取图像文件，并获取其高度和宽度。</li><li><strong>目的</strong>: 获取图像的尺寸，以便后续进行坐标归一化。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">txt_filename = os.path.join(<span class="string">&#x27;yolo_seg_dataset/train/&#x27;</span> + row[<span class="number">1</span>].Path.split(<span class="string">&#x27;/&#x27;</span>)[-<span class="number">1</span>][:-<span class="number">4</span>] + <span class="string">&#x27;.txt&#x27;</span>)</span><br></pre></td></tr></table></figure><ul><li><strong>功能</strong>: 生成对应的文本文件名，该文件名是基于图像文件名生成的（去掉扩展名并添加<code>.txt</code>）。</li><li><strong>目的</strong>: 为每个图像文件创建一个对应的标签文件。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(txt_filename, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> up:</span><br></pre></td></tr></table></figure><ul><li><strong>功能</strong>: 打开或创建文本文件进行写入，使用<code>with</code>语句可以确保文件在写入完成后正确关闭。</li><li><strong>目的</strong>: 准备写入归一化后的坐标数据。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> polygon <span class="keyword">in</span> row[<span class="number">1</span>].Polygons:</span><br><span class="line">    normalized_polygon = normalize_polygon(polygon, img_width, img_height)</span><br></pre></td></tr></table></figure><ul><li><strong>功能</strong>: 遍历当前行的所有多边形坐标，调用<code>normalize_polygon</code>函数进行归一化。</li><li><strong>目的</strong>: 将多边形的坐标转化为相对坐标。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">normalized_coords = <span class="string">&#x27; &#x27;</span>.join([<span class="string">f&#x27;<span class="subst">&#123;coord[<span class="number">0</span>]:<span class="number">.3</span>f&#125;</span> <span class="subst">&#123;coord[<span class="number">1</span>]:<span class="number">.3</span>f&#125;</span>&#x27;</span> <span class="keyword">for</span> coord <span class="keyword">in</span> normalized_polygon])</span><br></pre></td></tr></table></figure><ul><li><strong>功能</strong>: 这是一个列表推导式，用于遍历<code>normalized_polygon</code>中的每个坐标<code>coord</code>。每个<code>coord</code>都是一个包含两个元素的元组（<code>(x, y)</code>），表示一个点的坐标。</li><li><strong>格式化</strong>:<ul><li><code>coord[0]:.3f</code>：将<code>coord</code>中的第一个元素（x坐标）==格式化为小数点后三位的浮点数==。</li><li><code>coord[1]:.3f</code>：将第二个元素（y坐标）格式化为小数点后三位的浮点数。</li></ul></li><li><strong>结果</strong>: 列表推导式生成一个字符串列表，其中每个字符串都包含格式化后的坐标，例如：<code>[&quot;0.123 0.456&quot;, &quot;0.789 0.012&quot;]</code>。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">up.write(<span class="string">f&#x27;0 <span class="subst">&#123;normalized_coords&#125;</span>\n&#x27;</span>)</span><br></pre></td></tr></table></figure><ul><li><strong>内容</strong>:<ul><li><code>&#39;0 &#39;</code>：这是一个常量字符串，通常用于表示==类别标签==。在YOLO格式中，<code>0</code>可能表示某个特定的类别（例如，一个物体的类别，具体取决于数据集的类别定义）。</li><li><code>up</code>是一个文件对象，通过<code>with open(...) as up:</code>创建的。调用<code>write</code>方法将构建的字符串写入到文件中。</li></ul></li><li><strong>功能</strong>: 将归一化后的坐标写入文本文件。</li><li><strong>目的</strong>: 保存标签信息，以便YOLO模型使用。</li></ul><h3 id="验证集处理"><a href="#验证集处理" class="headerlink" title="验证集处理"></a>验证集处理</h3><p>接下来的代码与训练集处理相似，只是处理的是验证集数据。它从<code>training_anno</code>的第10000到第10150行进行迭代，重复上述步骤，复制图像到<code>yolo_seg_dataset/valid</code>目录，并创建相应的标签文件。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 采用验证集     </span></span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> training_anno.iloc[<span class="number">10000</span>:<span class="number">10150</span>].iterrows():</span><br><span class="line">    shutil.copy(row[<span class="number">1</span>].Path, <span class="string">&#x27;yolo_seg_dataset/valid&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    img = cv2.imread(row[<span class="number">1</span>].Path)</span><br><span class="line">    img_height, img_width = img.shape[:<span class="number">2</span>]</span><br><span class="line">    txt_filename = os.path.join(<span class="string">&#x27;yolo_seg_dataset/valid/&#x27;</span> + row[<span class="number">1</span>].Path.split(<span class="string">&#x27;/&#x27;</span>)[-<span class="number">1</span>][:-<span class="number">4</span>] + <span class="string">&#x27;.txt&#x27;</span>)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(txt_filename, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> up:</span><br><span class="line">        <span class="keyword">for</span> polygon <span class="keyword">in</span> row[<span class="number">1</span>].Polygons:</span><br><span class="line">            normalized_polygon = normalize_polygon(polygon, img_width, img_height)</span><br><span class="line">            normalized_coords = <span class="string">&#x27; &#x27;</span>.join([<span class="string">f&#x27;<span class="subst">&#123;coord[<span class="number">0</span>]:<span class="number">.3</span>f&#125;</span> <span class="subst">&#123;coord[<span class="number">1</span>]:<span class="number">.3</span>f&#125;</span>&#x27;</span> <span class="keyword">for</span> coord <span class="keyword">in</span> normalized_polygon])</span><br><span class="line">            up.write(<span class="string">f&#x27;0 <span class="subst">&#123;normalized_coords&#125;</span>\n&#x27;</span>)</span><br></pre></td></tr></table></figure><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>这段代码的主要目的是将多边形标注数据从原始数据集中提取出来，规范化并保存到新的训练集和验证集目录中，以供YOLO模型使用。通过归一化坐标，模型可以更好地适应不同尺寸的输入图像。</p><h1 id="步骤二：写入YOLO配置文件"><a href="#步骤二：写入YOLO配置文件" class="headerlink" title="步骤二：写入YOLO配置文件"></a>步骤二：写入YOLO配置文件</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;yolo_seg_dataset/data.yaml&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> up:</span><br><span class="line">    data_root = os.path.abspath(<span class="string">&#x27;yolo_seg_dataset/&#x27;</span>)</span><br><span class="line">    up.write(<span class="string">f&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">path: <span class="subst">&#123;data_root&#125;</span></span></span><br><span class="line"><span class="string">train: train</span></span><br><span class="line"><span class="string">val: valid</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">names:</span></span><br><span class="line"><span class="string">    0: alter</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span>)</span><br></pre></td></tr></table></figure><h1 id="逐行代码分析-1"><a href="#逐行代码分析-1" class="headerlink" title="逐行代码分析"></a>逐行代码分析</h1><p>这一段代码的目的是创建一个名为 <code>data.yaml</code> 的配置文件，通常用于YOLO等深度学习模型的数据配置。我们来逐步分析这段代码的结构和含义。</p><h3 id="代码解析"><a href="#代码解析" class="headerlink" title="代码解析"></a>代码解析</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;yolo_seg_dataset/data.yaml&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> up:</span><br></pre></td></tr></table></figure><ul><li><strong>功能</strong>: 使用 <code>with open(...) as ...:</code> 语句打开（或创建）一个名为 <code>data.yaml</code> 的文件，并以写入模式（<code>&#39;w&#39;</code>）打开。<code>up</code> 是一个文件对象，用于后续的写入操作。</li><li><strong>上下文管理</strong>: 使用 <code>with</code> 语句可以确保文件在操作完成后自动关闭，避免文件未关闭导致的资源泄漏。</li></ul><h3 id="2-获取数据根路径"><a href="#2-获取数据根路径" class="headerlink" title="2. ==获取数据根路径=="></a>2. ==获取数据根路径==</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data_root = os.path.abspath(<span class="string">&#x27;yolo_seg_dataset/&#x27;</span>)</span><br></pre></td></tr></table></figure><ul><li><strong>功能</strong>: <code>os.path.abspath(...)</code> 返回给定路径的==绝对路径==。在这里，它将  <code>&#39;yolo_seg_dataset/&#39;</code> 转换为绝对路径并存储在 <code>data_root</code> 变量中。</li><li><strong>示例</strong>: 如果当前工作目录是 <code>/home/user/projects</code>，那么 <code>data_root</code> 的值将是 <code>/home/user/projects/yolo_seg_dataset</code>。</li></ul><h3 id="3-写入内容到文件"><a href="#3-写入内容到文件" class="headerlink" title="3. 写入内容到文件"></a>3. 写入内容到文件</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">up.write(<span class="string">f&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">path: <span class="subst">&#123;data_root&#125;</span></span></span><br><span class="line"><span class="string">train: train</span></span><br><span class="line"><span class="string">val: valid</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">names:</span></span><br><span class="line"><span class="string">    0: alter</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span>)</span><br></pre></td></tr></table></figure><ul><li><strong>功能</strong>: 使用 <code>write(...)</code> 方法将格式化的字符串写入到 <code>data.yaml</code> 文件中。字符串的内容使用了多行字符串的语法（即用三个单引号包裹的字符串）。</li><li><strong>内容解释</strong>:<ul><li><code>path: &#123;data_root&#125;</code>: 写入<strong>数据集</strong>根路径的==绝对路径==。</li><li><code>train: train</code>: 指定训练数据的子目录名（==相对路径==）。</li><li><code>val: valid</code>: 指定验证数据的子目录名（==相对路径==）。</li><li><code>names:</code>: 这是一个字典，用于==映射类别ID到类别名称==。在这里，<code>0</code> 映射到类别名称 <code>alter</code>。</li></ul></li></ul><h3 id="完整内容示例"><a href="#完整内容示例" class="headerlink" title="完整内容示例"></a>完整内容示例</h3><p>假设 <code>data_root</code> 的绝对路径为 <code>/home/user/projects/yolo_seg_dataset</code>，最终写入 <code>data.yaml</code> 文件的内容将类似于：<br><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">path:</span> <span class="string">/home/user/projects/yolo_seg_dataset</span></span><br><span class="line"><span class="attr">train:</span> <span class="string">train</span></span><br><span class="line"><span class="attr">val:</span> <span class="string">valid</span></span><br><span class="line"></span><br><span class="line"><span class="attr">names:</span></span><br><span class="line">    <span class="attr">0:</span> <span class="string">alter</span></span><br></pre></td></tr></table></figure></p><h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><p>这段代码生成了一个用于YOLO数据集配置的 <code>data.yaml</code> 文件，包含了数据集的根路径、训练和验证集的目录，以及类别的映射信息。该配置文件通常用于训练模型，帮助模型了解数据集的结构和类别定义。</p><h1 id="步骤三：训练YOLO分割模型"><a href="#步骤三：训练YOLO分割模型" class="headerlink" title="步骤三：训练YOLO分割模型"></a>步骤三：训练YOLO分割模型</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> ultralytics <span class="keyword">import</span> YOLO</span><br><span class="line"></span><br><span class="line">model = YOLO(<span class="string">&quot;./yolov8n-seg.pt&quot;</span>)  </span><br><span class="line">results = model.train(data=<span class="string">&quot;./yolo_seg_dataset/data.yaml&quot;</span>, epochs=<span class="number">10</span>, imgsz=<span class="number">640</span>)</span><br></pre></td></tr></table></figure><h1 id="逐行代码分析-2"><a href="#逐行代码分析-2" class="headerlink" title="逐行代码分析"></a>逐行代码分析</h1><p>以下是对代码的逐行分析：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> ultralytics <span class="keyword">import</span> YOLO</span><br></pre></td></tr></table></figure><ul><li>这行代码导入了 <code>ultralytics</code> 库中的 <code>YOLO</code> 类。</li><li><code>ultralytics</code> 是一个用于目标检测的库，提供了易于使用的接口来训练和推理 YOLO 模型，尤其是 <code>YOLOv8</code> 模型。</li><li><code>YOLO</code> 类是用于创建并管理 YOLO 模型的类，包括加载预训练模型、训练模型和进行推理。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = YOLO(<span class="string">&quot;./yolov8n-seg.pt&quot;</span>)</span><br></pre></td></tr></table></figure><ul><li>这行代码使用 <code>YOLO</code> 类创建了一个 <code>model</code> 实例。</li><li><code>YOLO(&quot;./yolov8n-seg.pt&quot;)</code> 加载一个预训练的 YOLOv8 模型，该模型文件是 <code>yolov8n-seg.pt</code>。这是 YOLOv8 模型的小型版本（<code>n</code> 代表 nano纳米），同时具有分割功能（<code>-seg</code> 代表分割任务）。</li><li>通过这种加载方式，可以直接基于预训练模型进行进一步训练或推理。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">results = model.train(data=<span class="string">&quot;./yolo_seg_dataset/data.yaml&quot;</span>, epochs=<span class="number">10</span>, imgsz=<span class="number">640</span>)</span><br></pre></td></tr></table></figure><ul><li><code>model.train()</code> 是 YOLO 模型的训练方法。</li><li><code>data=&quot;./yolo_seg_dataset/data.yaml&quot;</code> 指定了用于训练的数据集配置文件。<code>data.yaml</code> 文件通常包含训练集、验证集的路径，以及类别名称等信息。</li><li><code>epochs=10</code> 指定模型要进行 10 个==训练周期==（<font color="#ff0000">epochs</font>）。每个周期意味着模型将遍历完整的训练数据集一次。</li><li><code>imgsz=640</code> 设置了输入图像的尺寸为 640 像素。YOLO 模型会将训练数据的图像调整到 640x640 的尺寸进行训练。</li></ul><p>训练完成后，<code>results</code> 会包含训练过程中的结果和性能指标（如损失值、准确度等），这些结果可以用于评估模型的训练效果。</p><h3 id="总结-2"><a href="#总结-2" class="headerlink" title="总结"></a>总结</h3><p>这段代码从 <code>ultralytics</code> 库中导入 YOLO 模型，加载了一个 YOLOv8 分割模型，并基于指定的数据集文件进行 10 个周期的训练，使用了 640x640 的图像输入尺寸。</p><h1 id="步骤四：预测测试集"><a href="#步骤四：预测测试集" class="headerlink" title="步骤四：预测测试集"></a>步骤四：预测测试集</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> ultralytics <span class="keyword">import</span> YOLO</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line">model = YOLO(<span class="string">&quot;./runs/segment/train6/weights/best.pt&quot;</span>)  </span><br><span class="line">test_imgs = glob.glob(<span class="string">&#x27;./test_set_A_rename/*/*&#x27;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">Polygon = []</span><br><span class="line"><span class="keyword">for</span> path <span class="keyword">in</span> tqdm(test_imgs[:]):</span><br><span class="line">    results = model(path, verbose=<span class="literal">False</span>)</span><br><span class="line">    result = results[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">if</span> result.masks <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        Polygon.append([])</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        Polygon.append([mask.astype(<span class="built_in">int</span>).tolist() <span class="keyword">for</span> mask <span class="keyword">in</span> result.masks.xy])</span><br><span class="line">        </span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">submit = pd.DataFrame(&#123;</span><br><span class="line">    <span class="string">&#x27;Path&#x27;</span>: [x.split(<span class="string">&#x27;/&#x27;</span>)[-<span class="number">1</span>] <span class="keyword">for</span> x <span class="keyword">in</span> test_imgs[:]],</span><br><span class="line">    <span class="string">&#x27;Polygon&#x27;</span>: Polygon</span><br><span class="line">&#125;)</span><br><span class="line">submit.to_csv(<span class="string">&#x27;track2_submit.csv&#x27;</span>, index=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><h1 id="逐行分析代码"><a href="#逐行分析代码" class="headerlink" title="逐行分析代码"></a>逐行分析代码</h1><p>这段代码使用预训练的YOLO模型来处理图像集，并将结果保存到CSV文件中。下面是逐行的分析：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> ultralytics <span class="keyword">import</span> YOLO</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br></pre></td></tr></table></figure><ul><li><strong><code>from ultralytics import YOLO</code></strong>: 从 <code>ultralytics</code> 库中导入 YOLO 类，这个类用于加载并使用预训练的 YOLO 模型进行推理和处理图像。</li><li><strong><code>import glob</code></strong>: <code>glob</code> 模块用于文件操作，它可以根据特定的模式匹配文件路径。</li><li><strong><code>from tqdm import tqdm</code></strong>: <code>tqdm</code> 模块用于显示进度条，常用于长时间运行的循环或任务中，帮助可视化处理进度。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = YOLO(<span class="string">&quot;./runs/segment/train6/weights/best.pt&quot;</span>)</span><br></pre></td></tr></table></figure><ul><li>这行代码加载了一个训练好的YOLO模型，权重文件位于 <code>./runs/segment/train6/weights/best.pt</code>。这个模型是预训练的权重，专门用于图像分割任务。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">test_imgs = glob.glob(<span class="string">&#x27;./test_set_A_rename/*/*&#x27;</span>)</span><br></pre></td></tr></table></figure><ul><li>使用 <code>glob.glob()</code> 函数获取<font color="#ff0000">所有</font>位于 <code>./test_set_A_rename/</code> 路径下的图像文件。</li><li><code>&#39;*/*&#39;</code> 匹配所有子目录中的文件路径，因此它会抓取该目录下所有的图像路径，并存储在 <code>test_imgs</code> 列表中。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Polygon = []</span><br><span class="line"><span class="keyword">for</span> path <span class="keyword">in</span> tqdm(test_imgs[:]):</span><br><span class="line">    results = model(path, verbose=<span class="literal">False</span>)</span><br><span class="line">    result = results[<span class="number">0</span>]</span><br></pre></td></tr></table></figure><ul><li><strong><code>Polygon = []</code></strong>: 初始化一个空列表 <code>Polygon</code>，用于存储每张图片的分割结果。</li><li><strong><code>for path in tqdm(test_imgs[:]):</code></strong>: 通过 <code>tqdm</code> 包裹循环，遍历 <code>test_imgs</code> 中的每个图像路径，并显示进度条。</li><li><strong><code>results = model(path, verbose=False)</code></strong>: 调用模型对当前图片（<code>path</code>）进行推理，得到分割结果。<code>verbose=False</code> 表示不打印详细信息。</li><li><strong><code>result = results[0]</code></strong>: YOLO 返回的结果可能包含多张图片（批处理），这里仅取第一个结果（当前处理的图片）。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> result.masks <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">    Polygon.append([])</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    Polygon.append([mask.astype(<span class="built_in">int</span>).tolist() <span class="keyword">for</span> mask <span class="keyword">in</span> result.masks.xy])</span><br></pre></td></tr></table></figure><ul><li><strong><code>if result.masks is None:</code></strong>: 检查结果是否包含分割的掩码（masks）。如果没有分割掩码（即 <code>result.masks</code> 为 <code>None</code>），则向 <code>Polygon</code> 列表中添加一个空列表。</li><li><p><strong><code>Polygon.append([mask.astype(int).tolist() for mask in result.masks.xy])</code></strong>: 如果存在分割掩码，将掩码的边界坐标（<code>result.masks.xy</code>）转换为整数并存储为 Python 列表的形式，然后将其添加到 <code>Polygon</code> 列表中。</p><p>  ==掩码（Mask）==在计算机视觉中是一个非常重要的概念，它通常用于表示图像中的特定区域。掩码的作用是突出或分离出图像中的某些部分（例如物体、背景等），便于后续的处理。掩码通常是一个与原始图像尺寸相同的二值化矩阵，每个像素点要么是 1（代表属于目标区域），要么是 0（代表不属于目标区域）。</p><p>  在你的代码中，掩码（<code>mask</code>）与图像分割任务相关。模型返回的 <code>mask</code> 描述的是在图像中哪一部分属于分割出的对象。这些掩码可以是二值化的矩阵，也可以是其对应的轮廓坐标（多边形）。</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">submit = pd.DataFrame(&#123;</span><br><span class="line">    <span class="string">&#x27;Path&#x27;</span>: [x.split(<span class="string">&#x27;/&#x27;</span>)[-<span class="number">1</span>] <span class="keyword">for</span> x <span class="keyword">in</span> test_imgs[:]],</span><br><span class="line">    <span class="string">&#x27;Polygon&#x27;</span>: Polygon</span><br><span class="line">&#125;)</span><br><span class="line">submit.to_csv(<span class="string">&#x27;track2_submit.csv&#x27;</span>, index=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><ul><li><strong><code>import pandas as pd</code></strong>: 导入 <code>pandas</code> 库，用于处理数据并生成 CSV 文件。</li><li><strong><code>submit = pd.DataFrame(&#123;...&#125;)</code></strong>: 创建一个 pandas 数据框 <code>submit</code>，包含两列：<ul><li><code>&#39;Path&#39;</code>: 存储每张图像的<font color="#ff0000">文件名</font>（通过 <code>x.split(&#39;/&#39;)[-1]</code> 从路径中提取文件名）。</li><li><code>&#39;Polygon&#39;</code>: 存储每张图像的分割结果（存储在 <code>Polygon</code> 列表中）。</li></ul></li><li><strong><code>submit.to_csv(&#39;track2_submit.csv&#39;, index=None)</code></strong>: 将 <code>submit</code> 数据框保存为一个名为 <code>track2_submit.csv</code> 的 CSV 文件，<code>index=None</code> 表示不保存行索引。</li></ul><h3 id="总结-3"><a href="#总结-3" class="headerlink" title="总结"></a>总结</h3><ul><li>这段代码使用YOLO模型处理一批图像，提取图像中的分割掩码边界（多边形），并将这些结果存储到一个CSV文件中。</li><li><code>tqdm</code> 用来展示处理进度，<code>pandas</code> 则用来生成最终的提交文件（<code>track2_submit.csv</code>）。</li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>【lagent】agent搭建</title>
      <link href="/2024/09/18/%E3%80%90lagent%E3%80%91agent%E6%90%AD%E5%BB%BA/"/>
      <url>/2024/09/18/%E3%80%90lagent%E3%80%91agent%E6%90%AD%E5%BB%BA/</url>
      
        <content type="html"><![CDATA[<h1 id="启动webui服务"><a href="#启动webui服务" class="headerlink" title="启动webui服务"></a>启动webui服务</h1><p>==使用lmdeploy启动一个api_server==</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda activate agent_camp3</span><br><span class="line">lmdeploy serve api_server /share/new_models/Shanghai_AI_Laboratory/internlm2_5-7b-chat --model-name internlm2_5-7b-chat</span><br></pre></td></tr></table></figure><p><img src="1.png" alt=""></p><p>==另开一个终端==，<font color="#ff0000">使用stremlit启动agent_web应用</font></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /root/agent_camp3/lagent</span><br><span class="line">conda activate agent_camp3</span><br><span class="line">streamlit run examples/internlm2_agent_web_demo.py</span><br></pre></td></tr></table></figure><p><img src="2.png" alt=""></p><p>==本地powershell建立ssh连接，进行端口映射==</p><p><img src="3.png" alt=""></p><h1 id="Q-amp-A"><a href="#Q-amp-A" class="headerlink" title="Q&amp;A"></a>Q&amp;A</h1><h2 id="遇到的问题："><a href="#遇到的问题：" class="headerlink" title="遇到的问题："></a>遇到的问题：</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ModuleNotFoundError: No module named &#x27;griffe.enumerations</span><br></pre></td></tr></table></figure><h2 id="解决方法："><a href="#解决方法：" class="headerlink" title="解决方法："></a>解决方法：</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Due to griffe&#x27;s recent 1.x release, the `griffe.enumerations` module has been removed, resulting in a break change, which can be resolved by</span><br><span class="line">`pip install griffe==0.48`.</span><br></pre></td></tr></table></figure><h1 id="修改模型名称以及模型IP地址"><a href="#修改模型名称以及模型IP地址" class="headerlink" title="修改模型名称以及模型IP地址"></a>修改模型名称以及模型IP地址</h1><p>==启动streamlit的web应用如下==：</p><p><img src="4.png" alt=""></p><p>==修改红框内的内容==</p><p><img src="5.png" alt=""></p><p>==终端的反馈==：</p><p>PS:很是可惜，没有找到我想要的内容<a href="https://arxiv.org/abs/1706.03762">[1706.03762] Attention Is All You Need (arxiv.org)</a></p><p><img src="6.png" alt=""></p><h1 id="自定义工具"><a href="#自定义工具" class="headerlink" title="自定义工具"></a>自定义工具</h1><p><img src="7.png" alt=""></p><p>==进入lagent_web_demo的py文件中==</p><p>==添加&amp;修改代码：==</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> lagent.actions <span class="keyword">import</span> ActionExecutor, ArxivSearch, IPythonInterpreter</span><br><span class="line">+ <span class="keyword">from</span> lagent.actions.magicmaker <span class="keyword">import</span> MagicMaker</span><br><span class="line"><span class="keyword">from</span> lagent.agents.internlm2_agent <span class="keyword">import</span> INTERPRETER_CN, META_CN, PLUGIN_CN, Internlm2Agent, Internlm2Protocol</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line">        action_list = [</span><br><span class="line">            ArxivSearch(),</span><br><span class="line">+             MagicMaker(),</span><br><span class="line">        ]</span><br></pre></td></tr></table></figure><p><img src="8.png" alt=""></p><p>==重新启动agent_web服务==</p><p>使用<code>MagicMaker</code>工具绘画</p><p>==Prompt==：帮我画一个微笑的女孩，穿着校服在学校的走廊上，阳光照耀在她身上</p><p><img src="9.png" alt=""></p><p><img src="10.png" alt=""></p><p><img src="11.png" alt=""></p><p>==可以看到对于用户输入的提示词，有自动进行填充完善==</p><p><img src="12.png" alt=""></p><p><img src="13.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 书生·浦语三期实战营 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>【评测】opencompass-司南</title>
      <link href="/2024/09/04/%E3%80%90%E8%AF%84%E6%B5%8B%E3%80%91opencompass-%E5%8F%B8%E5%8D%97/"/>
      <url>/2024/09/04/%E3%80%90%E8%AF%84%E6%B5%8B%E3%80%91opencompass-%E5%8F%B8%E5%8D%97/</url>
      
        <content type="html"><![CDATA[<h1 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h1><p><a href="https://github.com/InternLM/Tutorial/tree/camp3/docs/L1/OpenCompass">Tutorial/docs/L1/OpenCompass at camp3 · InternLM/Tutorial (github.com)</a></p><h1 id="任务内容"><a href="#任务内容" class="headerlink" title="任务内容"></a>任务内容</h1><p><img src="0.png" alt=""></p><h1 id="任务复现过程"><a href="#任务复现过程" class="headerlink" title="任务复现过程"></a>任务复现过程</h1><p>列出所有跟 InternLM 及 C-Eval 相关的配置：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python tools/list_configs.py internlm ceval</span><br></pre></td></tr></table></figure><p><img src="1.png" alt=""></p><p><img src="2.png" alt=""></p><p>==评测结束==</p><p><img src="3.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 书生·浦语三期实战营 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>【Fine-tuning】XTuner微调个人小助手</title>
      <link href="/2024/09/04/%E3%80%90Fine-tuning%E3%80%91XTuner%E5%BE%AE%E8%B0%83%E4%B8%AA%E4%BA%BA%E5%B0%8F%E5%8A%A9%E6%89%8B/"/>
      <url>/2024/09/04/%E3%80%90Fine-tuning%E3%80%91XTuner%E5%BE%AE%E8%B0%83%E4%B8%AA%E4%BA%BA%E5%B0%8F%E5%8A%A9%E6%89%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="任务内容"><a href="#任务内容" class="headerlink" title="任务内容"></a>任务内容</h1><p><img src="1.png" alt=""></p><h1 id="完成任务截图"><a href="#完成任务截图" class="headerlink" title="完成任务截图"></a>完成任务截图</h1><p><img src="2.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 书生·浦语三期实战营 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>【RAG】使用Llamaindex框架部署InternLM2-1.8B</title>
      <link href="/2024/09/04/%E3%80%90RAG%E3%80%91%E4%BD%BF%E7%94%A8Llamaindex%E6%A1%86%E6%9E%B6%E9%83%A8%E7%BD%B2InternLM2-1-8B-0/"/>
      <url>/2024/09/04/%E3%80%90RAG%E3%80%91%E4%BD%BF%E7%94%A8Llamaindex%E6%A1%86%E6%9E%B6%E9%83%A8%E7%BD%B2InternLM2-1-8B-0/</url>
      
        <content type="html"><![CDATA[<h1 id="一、前置知识"><a href="#一、前置知识" class="headerlink" title="一、前置知识"></a>一、前置知识</h1><ul><li><strong>给模型注入新知识的方式</strong>：<ul><li>内部方式：更新模型的权重，但训练代价较大。</li><li>外部方式：给模型注入额外的上下文或外部信息，不改变其权重。</li></ul></li><li><strong>RAG 工作原理</strong>：<ul><li>将问题编码成向量，在向量数据库中找到最相关的文档块（top-k chunks）。</li><li>将知识源分割成小块，编码成向量并存储在向量数据库中。</li><li>将检索到的文档块与原始问题一起作为提示输入到 LLM 中，生成最终的回答。</li></ul></li><li><strong>RAG 效果比对</strong>：<ul><li>由于 <code>xtuner</code> 是较新的框架，<code>InternLM2-Chat-1.8B</code> 训练数据库中未收录相关信息，使用 RAG 前问答均未给出准确答案，使用后能获得想要的答案。</li></ul></li></ul><h1 id="二、环境、模型准备"><a href="#二、环境、模型准备" class="headerlink" title="二、环境、模型准备"></a>二、环境、模型准备</h1><h2 id="（一）配置基础环境"><a href="#（一）配置基础环境" class="headerlink" title="（一）配置基础环境"></a>（一）配置基础环境</h2><ul><li><p>在 <code>Intern Studio</code> 服务器上部署 <code>LlamaIndex</code>：</p><ul><li>打开 <code>Intern Studio</code> 界面，点击 <code>创建开发机</code> 配置开发机系统。</li><li>填写 <code>开发机名称</code> 后，点击 <code>选择镜像</code> 使用 <code>Cuda11.7-conda</code> 镜像，在资源配置中选择 <code>30% A100 * 1</code> 的选项，立即创建开发机器。</li><li>进入开发机后，创建新的 <code>conda</code> 环境，命名为 <code>llamaindex</code>，运行以下命令：</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">conda create -n llamaindex python=3.10</span><br><span class="line">conda <span class="built_in">env</span> list</span><br><span class="line">conda activate llamaindex</span><br><span class="line">conda install pytorch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2 pytorch-cuda=11.7 -c pytorch -c nvidia</span><br><span class="line">pip install einops==0.7.0 protobuf==5.26.1</span><br></pre></td></tr></table></figure><ul><li>环境激活后，命令行左边会显示当前环境名称。</li></ul></li></ul><h2 id="（二）安装-LlamaIndex"><a href="#（二）安装-LlamaIndex" class="headerlink" title="（二）安装 LlamaIndex"></a>（二）安装 LlamaIndex</h2><ul><li><p>安装 <code>LlamaIndex</code> 和相关的包：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda activate llamaindex</span><br><span class="line">pip install llama-index==0.10.38 llama-index-llms-huggingface==0.2.0 <span class="string">&quot;transformers[torch]==4.41.1&quot;</span> <span class="string">&quot;huggingface_hub[inference]==0.23.1&quot;</span> huggingface_hub==0.23.1 sentence-transformers==2.7.0 sentencepiece==0.2.0</span><br></pre></td></tr></table></figure></li></ul><h2 id="（三）下载-Sentence-Transformer-词嵌入模型"><a href="#（三）下载-Sentence-Transformer-词嵌入模型" class="headerlink" title="（三）下载 Sentence Transformer 词嵌入模型"></a>（三）下载 Sentence Transformer 词嵌入模型</h2><ul><li><p>新建一个 <code>python</code> 文件，贴入以下代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置环境变量</span></span><br><span class="line">os.environ[<span class="string">&#x27;HF_ENDPOINT&#x27;</span>] = <span class="string">&#x27;https://hf-mirror.com&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载模型</span></span><br><span class="line">os.system(<span class="string">&#x27;huggingface-cli download --resume-download sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2 --local-dir /root/model/sentence-transformer&#x27;</span>)</span><br></pre></td></tr></table></figure></li><li><p>在 <code>/root/llamaindex_demo</code> 目录下执行该脚本自动开始下载。</p></li></ul><h2 id="（四）下载-NLTK-相关资源"><a href="#（四）下载-NLTK-相关资源" class="headerlink" title="（四）下载 NLTK 相关资源"></a>（四）下载 NLTK 相关资源</h2><ul><li><p>使用以下命令下载 <code>nltk</code> 资源并解压到服务器上：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /root</span><br><span class="line">git <span class="built_in">clone</span> https://gitee.com/yzy0612/nltk_data.git --branch gh-pages</span><br><span class="line"><span class="built_in">cd</span> nltk_data</span><br><span class="line"><span class="built_in">mv</span> packages/* ./</span><br><span class="line"><span class="built_in">cd</span> tokenizers</span><br><span class="line">unzip punkt.zip</span><br><span class="line"><span class="built_in">cd</span> ../taggers</span><br><span class="line">unzip averaged_perceptron_tagger.zip</span><br></pre></td></tr></table></figure></li></ul><h1 id="三、LlamaIndex-HuggingFaceLLM"><a href="#三、LlamaIndex-HuggingFaceLLM" class="headerlink" title="三、LlamaIndex HuggingFaceLLM"></a>三、LlamaIndex HuggingFaceLLM</h1><ul><li><p>运行以下指令，把 <code>InternLM2 1.8B</code> 软连接出来：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~/model</span><br><span class="line"><span class="built_in">ln</span> -s /root/share/new_models/Shanghai_AI_Laboratory/internlm2-chat-1_8b/ ./</span><br></pre></td></tr></table></figure></li><li><p>新建一个 <code>python</code> 文件，贴入以下代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> llama_index.llms.huggingface <span class="keyword">import</span> HuggingFaceLLM</span><br><span class="line"><span class="keyword">from</span> llama_index.core.llms <span class="keyword">import</span> ChatMessage</span><br><span class="line"></span><br><span class="line">llm = HuggingFaceLLM(</span><br><span class="line">    model_name=<span class="string">&quot;/root/model/internlm2-chat-1_8b&quot;</span>,</span><br><span class="line">    tokenizer_name=<span class="string">&quot;/root/model/internlm2-chat-1_8b&quot;</span>,</span><br><span class="line">    model_kwargs=&#123;<span class="string">&quot;trust_remote_code&quot;</span>: <span class="literal">True</span>&#125;,</span><br><span class="line">    tokenizer_kwargs=&#123;<span class="string">&quot;trust_remote_code&quot;</span>: <span class="literal">True</span>&#125;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">rsp = llm.chat(messages=[ChatMessage(content=<span class="string">&quot;xtuner 是什么？&quot;</span>)])</span><br><span class="line"><span class="built_in">print</span>(rsp)</span><br></pre></td></tr></table></figure></li><li><p>运行以下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conda activate llamaindex</span><br><span class="line"><span class="built_in">cd</span> ~/llamaindex_demo/</span><br><span class="line">python llamaindex_internlm.py</span><br></pre></td></tr></table></figure></li><li><p>结果回答效果并不好，不是想要的 <code>xtuner</code>。</p></li></ul><h1 id="四、LlamaIndex-RAG"><a href="#四、LlamaIndex-RAG" class="headerlink" title="四、LlamaIndex RAG"></a>四、LlamaIndex RAG</h1><ul><li><p>安装 <code>LlamaIndex</code> 词嵌入向量依赖：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda activate llamaindex</span><br><span class="line">pip install llama-index-embeddings-huggingface==0.2.0 llama-index-embeddings-instructor==0.1.3</span><br></pre></td></tr></table></figure></li><li><p>获取知识库：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~/llamaindex_demo</span><br><span class="line"><span class="built_in">mkdir</span> data</span><br><span class="line"><span class="built_in">cd</span> data</span><br><span class="line">git <span class="built_in">clone</span> https://github.com/InternLM/xtuner.git</span><br><span class="line"><span class="built_in">mv</span> xtuner/README_zh-CN.md ./</span><br></pre></td></tr></table></figure></li><li><p>新建一个 <code>python</code> 文件，贴入以下代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> llama_index.core <span class="keyword">import</span> VectorStoreIndex, SimpleDirectoryReader, Settings</span><br><span class="line"><span class="keyword">from</span> llama_index.embeddings.huggingface <span class="keyword">import</span> HuggingFaceEmbedding</span><br><span class="line"><span class="keyword">from</span> llama_index.llms.huggingface <span class="keyword">import</span> HuggingFaceLLM</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化一个 HuggingFaceEmbedding 对象，用于将文本转换为向量表示</span></span><br><span class="line">embed_model = HuggingFaceEmbedding(</span><br><span class="line">    model_name=<span class="string">&quot;/root/model/sentence-transformer&quot;</span></span><br><span class="line">)</span><br><span class="line">Settings.embed_model = embed_model</span><br><span class="line"></span><br><span class="line">llm = HuggingFaceLLM(</span><br><span class="line">    model_name=<span class="string">&quot;/root/model/internlm2-chat-1_8b&quot;</span>,</span><br><span class="line">    tokenizer_name=<span class="string">&quot;/root/model/internlm2-chat-1_8b&quot;</span>,</span><br><span class="line">    model_kwargs=&#123;<span class="string">&quot;trust_remote_code&quot;</span>: <span class="literal">True</span>&#125;,</span><br><span class="line">    tokenizer_kwargs=&#123;<span class="string">&quot;trust_remote_code&quot;</span>: <span class="literal">True</span>&#125;</span><br><span class="line">)</span><br><span class="line">Settings.llm = llm</span><br><span class="line"></span><br><span class="line"><span class="comment"># 从指定目录读取所有文档，并加载数据到内存中</span></span><br><span class="line">documents = SimpleDirectoryReader(<span class="string">&quot;/root/llamaindex_demo/data&quot;</span>).load_data()</span><br><span class="line">index = VectorStoreIndex.from_documents(documents)</span><br><span class="line">query_engine = index.as_query_engine()</span><br><span class="line">response = query_engine.query(<span class="string">&quot;xtuner 是什么?&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(response)</span><br></pre></td></tr></table></figure></li><li><p>运行以下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conda activate llamaindex</span><br><span class="line"><span class="built_in">cd</span> ~/llamaindex_demo/</span><br><span class="line">python llamaindex_RAG.py</span><br></pre></td></tr></table></figure></li><li><p>结果借助 RAG 技术后，能获得想要的答案。</p></li></ul><h1 id="五、LlamaIndex-Web"><a href="#五、LlamaIndex-Web" class="headerlink" title="五、LlamaIndex Web"></a>五、LlamaIndex Web</h1><ul><li><p>安装依赖：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install streamlit==1.36.0</span><br></pre></td></tr></table></figure></li><li><p>新建一个 <code>python</code> 文件，贴入以下代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> streamlit <span class="keyword">as</span> st</span><br><span class="line"><span class="keyword">from</span> llama_index.core <span class="keyword">import</span> VectorStoreIndex, SimpleDirectoryReader, Settings</span><br><span class="line"><span class="keyword">from</span> llama_index.embeddings.huggingface <span class="keyword">import</span> HuggingFaceEmbedding</span><br><span class="line"><span class="keyword">from</span> llama_index.llms.huggingface <span class="keyword">import</span> HuggingFaceLLM</span><br><span class="line"></span><br><span class="line">st.set_page_config(page_title=<span class="string">&quot;llama_index_demo&quot;</span>, page_icon=<span class="string">&quot;🦜🔗&quot;</span>)</span><br><span class="line">st.title(<span class="string">&quot;llama_index_demo&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化模型</span></span><br><span class="line"><span class="meta">@st.cache_resource</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">init_models</span>():</span><br><span class="line">    embed_model = HuggingFaceEmbedding(</span><br><span class="line">        model_name=<span class="string">&quot;/root/model/sentence-transformer&quot;</span></span><br><span class="line">    )</span><br><span class="line">    Settings.embed_model = embed_model</span><br><span class="line"></span><br><span class="line">    llm = HuggingFaceLLM(</span><br><span class="line">        model_name=<span class="string">&quot;/root/model/internlm2-chat-1_8b&quot;</span>,</span><br><span class="line">        tokenizer_name=<span class="string">&quot;/root/model/internlm2-chat-1_8b&quot;</span>,</span><br><span class="line">        model_kwargs=&#123;<span class="string">&quot;trust_remote_code&quot;</span>: <span class="literal">True</span>&#125;,</span><br><span class="line">        tokenizer_kwargs=&#123;<span class="string">&quot;trust_remote_code&quot;</span>: <span class="literal">True</span>&#125;</span><br><span class="line">    )</span><br><span class="line">    Settings.llm = llm</span><br><span class="line"></span><br><span class="line">    documents = SimpleDirectoryReader(<span class="string">&quot;/root/llamaindex_demo/data&quot;</span>).load_data()</span><br><span class="line">    index = VectorStoreIndex.from_documents(documents)</span><br><span class="line">    query_engine = index.as_query_engine()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> query_engine</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查是否需要初始化模型</span></span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;query_engine&#x27;</span> <span class="keyword">not</span> <span class="keyword">in</span> st.session_state:</span><br><span class="line">    st.session_state[<span class="string">&#x27;query_engine&#x27;</span>] = init_models()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">greet2</span>(<span class="params">question</span>):</span><br><span class="line">    response = st.session_state[<span class="string">&#x27;query_engine&#x27;</span>].query(question)</span><br><span class="line">    <span class="keyword">return</span> response</span><br></pre></td></tr></table></figure></li></ul><pre><code># Store LLM generated responsesif &quot;messages&quot; not in st.session_state.keys():    st.session_state.messages = [&#123;&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;你好，我是你的助手，有什么我可以帮助你的吗？&quot;&#125;]# Display or clear chat messagesfor message in st.session_state.messages:    with st.chat_message(message[&quot;role&quot;]):        st.write(message[&quot;content&quot;])def clear_chat_history():    st.session_state.messages = [&#123;&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;你好，我是你的助手，有什么我可以帮助你的吗？&quot;&#125;]st.sidebar.button(&#39;Clear Chat History&#39;, on_click=clear_chat_history)# Function for generating LLaMA2 responsedef generate_llama_response(question):    response = greet2(question)    return response# User-provided promptif prompt := st.chat_input(&quot;What&#39;s on your mind?&quot;):    st.chat_message(&quot;user&quot;).write(prompt)    with st.chat_message(&quot;assistant&quot;):        message_placeholder = st.empty()        response = generate_llama_response(prompt)        message_placeholder.write(response)    st.session_state.messages.append(&#123;&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: response&#125;)<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- 启动 Streamlit 服务：</span><br><span class="line"></span><br><span class="line">  ```bash</span><br><span class="line">  cd ~/llamaindex_demo/</span><br><span class="line">  streamlit run llamaindex_streamlit.py</span><br></pre></td></tr></table></figure></code></pre><ul><li>打开浏览器，访问 <code>https://locahost:XXX</code>。</li></ul><h1 id="六、总结"><a href="#六、总结" class="headerlink" title="六、总结"></a>六、总结</h1><ul><li>本文介绍如何结合 <code>LlamaIndex</code> 和 <code>InternLM2</code> 部署 <code>RAG</code>，为大模型注入最新知识库，效果显著。</li></ul><h1 id="七、作业"><a href="#七、作业" class="headerlink" title="七、作业"></a>七、作业</h1><p><img src="1.png" alt=""></p><p>==RAG前==</p><p><img src="2.png" alt=""></p><p>==RAG后==</p><p><img src="3.png" alt=""></p><p>==使用Streamlit部署webui（使用RAG）==</p><p><img src="4.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 书生·浦语三期实战营 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>【提示词工程】LangGPT结构化提示词编写</title>
      <link href="/2024/09/03/%E3%80%90%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E3%80%91LangGPT%E7%BB%93%E6%9E%84%E5%8C%96%E6%8F%90%E7%A4%BA%E8%AF%8D%E7%BC%96%E5%86%99/"/>
      <url>/2024/09/03/%E3%80%90%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E3%80%91LangGPT%E7%BB%93%E6%9E%84%E5%8C%96%E6%8F%90%E7%A4%BA%E8%AF%8D%E7%BC%96%E5%86%99/</url>
      
        <content type="html"><![CDATA[<h1 id="参考内容："><a href="#参考内容：" class="headerlink" title="参考内容："></a>参考内容：</h1><p>1.LangGPT社区：<a href="https://langgptai.feishu.cn/wiki/QaArwzc7biR5nqkSo3mcwzGfnhf">‌‌‬﻿⁠﻿⁠⁠﻿‌⁠‬‌⁠‍‬⁠‬‬﻿‬‌‌‌‍﻿﻿‌‌﻿‬⁠LangGPT结构化提示词 - 飞书云文档</a><br>2.浦语开源文档<a href="https://github.com/InternLM/Tutorial/tree/camp3/docs/L1/Prompt">书生浦语-浦语提示词工程实践</a><br>3.文档：<a href="https://mp.weixin.qq.com/s/N9BrkDqvkIHQD7TTnhNk6Q">系统论述文章： 构建高性能 Prompt 之路——结构化 Prompt</a></p><hr><h1 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h1><p>step0：前期准备<br>0.1：创建虚拟环境-&gt;激活虚拟环境-&gt;安装必要包文件<br>0.2：创建项目路径-&gt;进入项目<br>0.3：安装必要软件，如tmux</p><p>step1：模型部署<br>模型下载-&gt;部署模型为OpenAI server-&gt;图形化界面调用<br>‬﻿⁠﻿⁠⁠﻿<br>step3：langgpt结构化提示词⁠‬编写⁠‍‬⁠‬‬﻿‬‌‌‌‍﻿﻿‌‌﻿<br>偷懒大法：GPTS有LangGPT提示词专家，用大模型生成即可</p><hr><h1 id="tmux扫盲"><a href="#tmux扫盲" class="headerlink" title="tmux扫盲"></a>tmux扫盲</h1><pre><code>tmux可以在终端中创建终端，将进程维持在后台。当我们下载模型时，使用tmux在后台下载，即便我们断开ssh连接，下载也不会中断。</code></pre><p>step1：部署模型为OpenAI server</p><h2 id="tmux常见命令"><a href="#tmux常见命令" class="headerlink" title="tmux常见命令"></a>tmux常见命令</h2><p>1.<strong>创建窗口命令</strong>：</p><p>==PS：t表示target(目标)，用于指定会话、窗口或面板的名称==<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tmux new -t &lt;session_name&gt;</span><br></pre></td></tr></table></figure></p><p>PS：创建完成后，运行下面的命令进入新的命令窗口(==首次创建自动进入，之后需要连接==)：<br>其中<code>a</code> 是 <strong><code>attach</code></strong> 的简写<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tmux a -t &lt;session_name&gt;</span><br></pre></td></tr></table></figure></p><p>2.<strong>查看当前 tmux 会话</strong>：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tmux ls</span><br></pre></td></tr></table></figure><p>3.<strong>连接到特定的 tmux 会话</strong>：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tmux attach -t &lt;session_name&gt;</span><br></pre></td></tr></table></figure><p>将 <code>&lt;session_name&gt;</code> 替换为你要连接的会话的实际名称或编号。</p><p>4.<strong>杀死整个 tmux 会话：</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tmux kill-session -t &lt;session_name&gt;</span><br></pre></td></tr></table></figure><p>5.<strong>退出tmux</strong>:</p><p>Ctrl+B进入<code>tmux</code>的控制模式，然后按d退出窗口连接</p><h2 id="模型部署"><a href="#模型部署" class="headerlink" title="模型部署"></a>模型部署</h2><p>进入命令窗口后，需要在新窗口中再次激活环境，命令参考<strong>0.1节</strong>。然后，使用LMDeploy进行部署，参考如下命令：</p><p>使用LMDeploy进行部署，参考如下命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=0 lmdeploy serve api_server /share/new_models/Shanghai_AI_Laboratory/internlm2-chat-1_8b --server-port 23333 --api-keys internlm2</span><br></pre></td></tr></table></figure><p>更多设置参考：<a href="https://lmdeploy.readthedocs.io/en/latest/index.html">https://lmdeploy.readthedocs.io/en/latest/index.html</a></p><p>部署成功后，可以利用如下脚本调用部署的InternLM2-chat-1_8b模型并测试是否部署成功。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> openai <span class="keyword">import</span> OpenAI</span><br><span class="line"></span><br><span class="line">client = OpenAI(</span><br><span class="line">    api_key = <span class="string">&quot;internlm2&quot;</span>,</span><br><span class="line">    base_url = <span class="string">&quot;http://0.0.0.0:23333/v1&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">response = client.chat.completions.create(</span><br><span class="line">    model=client.models.<span class="built_in">list</span>().data[<span class="number">0</span>].<span class="built_in">id</span>,</span><br><span class="line">    messages=[</span><br><span class="line">        &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;请介绍一下你自己&quot;</span>&#125;</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(response.choices[<span class="number">0</span>].message.content)</span><br></pre></td></tr></table></figure><p>服务启动完成后，可以按Ctrl+B进入<code>tmux</code>的控制模式，然后按D退出窗口连接，更多操作<a href="https://aik9.top/">参考</a>。</p><hr><h1 id="作业："><a href="#作业：" class="headerlink" title="作业："></a>作业：</h1><p>基础任务 (完成此任务即完成闯关)：</p><ul><li><p><strong>背景问题</strong>：近期相关研究发现，LLM在对比浮点数字时表现不佳，经验证，internlm2-chat-1.8b (internlm2-chat-7b)也存在这一问题，例如认为<code>13.8&lt;13.11</code>。</p></li><li><p><strong>任务要求</strong>：利用LangGPT优化提示词，使LLM输出正确结果。<strong>完成一次并提交截图即可</strong></p></li></ul><p>使用GPTS中LangGPT提示词专家，配合我们的需求生成LangGPT结构化提示词</p><p><img src="1.png" alt=""><br>==生成结果如下==：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"># Role: 数学助手</span><br><span class="line"></span><br><span class="line">## Profile</span><br><span class="line">- author: LangGPT</span><br><span class="line">- version: 1.0</span><br><span class="line">- language: 中文</span><br><span class="line">- description: 一个能够进行基本数学加减法运算，并能够比较两个数字大小的助手。</span><br><span class="line"></span><br><span class="line">## Skills</span><br><span class="line">1. 能够进行基本的数学加法和减法运算。</span><br><span class="line">2. 能够比较两个数字的大小，并给出相应的判断。</span><br><span class="line">3. 能够理解用户输入的简单数学表达式或问题描述。</span><br><span class="line"></span><br><span class="line">## Rules</span><br><span class="line">1. 用户输入可以是任意两个数字或一个包含加法、减法的表达式。</span><br><span class="line">2. 当输入两个数字时，助手应比较它们的大小，并返回结果。</span><br><span class="line">3. 当输入一个加法或减法表达式时，助手应计算出结果并返回。</span><br><span class="line">4. 如果用户输入有误或不符合数学表达式规则，助手应给出提示并要求重新输入。</span><br><span class="line"></span><br><span class="line">## Workflows</span><br><span class="line">1. 接收用户输入的数字或数学表达式。</span><br><span class="line">2. 判断输入的类型（两个数字或数学表达式）。</span><br><span class="line">3. 如果是两个数字，执行大小比较，并返回结果。</span><br><span class="line">4. 如果是数学表达式，进行加法或减法计算，返回结果。</span><br><span class="line">5. 如果输入不符合预期格式，返回错误提示，要求用户重新输入。</span><br><span class="line"></span><br><span class="line">## Init</span><br><span class="line">1. 向用户介绍助手的功能和使用方法。</span><br><span class="line">2. 提示用户可以输入两个数字进行比较，或输入一个加法、减法表达式进行计算。</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>==加入系统提示词前：==<br>PS：估计InternLM2-chat-1_8b版本太久远了，所以回答不出来🤔<br><img src="2.png" alt=""></p><p>==加入系统提示词后：==<br>PS：效果明显变好了😋<br><img src="3.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 书生·浦语三期实战营 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>8G显存玩转书生大模型Demo</title>
      <link href="/2024/08/20/8G%E6%98%BE%E5%AD%98%E7%8E%A9%E8%BD%AC%E4%B9%A6%E7%94%9F%E5%A4%A7%E6%A8%A1%E5%9E%8BDemo/"/>
      <url>/2024/08/20/8G%E6%98%BE%E5%AD%98%E7%8E%A9%E8%BD%AC%E4%B9%A6%E7%94%9F%E5%A4%A7%E6%A8%A1%E5%9E%8BDemo/</url>
      
        <content type="html"><![CDATA[<h1 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># 创建环境</span><br><span class="line">conda create -n demo python=3.10 -y</span><br><span class="line"># 激活环境</span><br><span class="line">conda activate demo</span><br><span class="line"># 安装 torch</span><br><span class="line">conda install pytorch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 pytorch-cuda=12.1 -c pytorch -c nvidia -y</span><br><span class="line"># 安装其他依赖</span><br><span class="line">pip install transformers==4.38</span><br><span class="line">pip install sentencepiece==0.1.99</span><br><span class="line">pip install einops==0.8.0</span><br><span class="line">pip install protobuf==5.27.2</span><br><span class="line">pip install accelerate==0.33.0</span><br><span class="line">pip install streamlit==1.37.0</span><br></pre></td></tr></table></figure><p><img src="P1.png" alt=""></p><h1 id="InternLM2-Chat-1-8B-模型部署"><a href="#InternLM2-Chat-1-8B-模型部署" class="headerlink" title="InternLM2-Chat-1.8B 模型部署"></a>InternLM2-Chat-1.8B 模型部署</h1><h2 id="一、用Cli-Demo-部署"><a href="#一、用Cli-Demo-部署" class="headerlink" title="一、用Cli Demo 部署"></a>一、用Cli Demo 部署</h2><p>1.创建<code>demo</code>文件夹，用于存放代码。并创建 <code>cli_demo.py</code>文件</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /root/demo</span><br><span class="line">touch /root/demo/cli_demo.py</span><br></pre></td></tr></table></figure><p><img src="P2.png" alt=""></p><p> 其中<code>cli_demo.py</code> 的代码为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer, AutoModelForCausalLM</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model_name_or_path = <span class="string">&quot;/root/share/new_models/Shanghai_AI_Laboratory/internlm2-chat-1_8b&quot;</span></span><br><span class="line"></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, trust_remote_code=<span class="literal">True</span>, device_map=<span class="string">&#x27;cuda:0&#x27;</span>)</span><br><span class="line">model = AutoModelForCausalLM.from_pretrained(model_name_or_path, trust_remote_code=<span class="literal">True</span>, torch_dtype=torch.bfloat16, device_map=<span class="string">&#x27;cuda:0&#x27;</span>)</span><br><span class="line">model = model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">system_prompt = <span class="string">&quot;&quot;&quot;You are an AI assistant whose name is InternLM (书生·浦语).</span></span><br><span class="line"><span class="string">- InternLM (书生·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be helpful, honest, and harmless.</span></span><br><span class="line"><span class="string">- InternLM (书生·浦语) can understand and communicate fluently in the language chosen by the user such as English and 中文.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">messages = [(system_prompt, <span class="string">&#x27;&#x27;</span>)]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;=============Welcome to InternLM chatbot, type &#x27;exit&#x27; to exit.=============&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    input_text = <span class="built_in">input</span>(<span class="string">&quot;\nUser  &gt;&gt;&gt; &quot;</span>)</span><br><span class="line">    input_text = input_text.replace(<span class="string">&#x27; &#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line">    <span class="keyword">if</span> input_text == <span class="string">&quot;exit&quot;</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    length = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> response, _ <span class="keyword">in</span> model.stream_chat(tokenizer, input_text, messages):</span><br><span class="line">        <span class="keyword">if</span> response <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="built_in">print</span>(response[length:], flush=<span class="literal">True</span>, end=<span class="string">&quot;&quot;</span>)</span><br><span class="line">            length = <span class="built_in">len</span>(response)</span><br></pre></td></tr></table></figure><p>2.在终端执行<code>python /root/demo/cli_demo.py</code>命令启动Demo</p><p>3.使用 Cli Demo 完成 InternLM2-Chat-1.8B 模型的部署，并生成 300 字小故事</p><p><img src="P3.png" alt=""></p><h2 id="二、用Streamlit-Web-Demo-部署"><a href="#二、用Streamlit-Web-Demo-部署" class="headerlink" title="二、用Streamlit Web Demo 部署"></a>二、用Streamlit Web Demo 部署</h2><p>1.clone InternLM 的github仓库 到本地：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /root/demo</span><br><span class="line">git clone https://github.com/InternLM/Tutorial.git</span><br></pre></td></tr></table></figure><p>2.启动Streamlit 服务：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /root/demo</span><br><span class="line">streamlit run /root/demo/Tutorial/tools/streamlit_demo.py --server.address 127.0.0.1 --server.port 6006</span><br></pre></td></tr></table></figure><p><img src="P4.png" alt=""></p><p>3.在<strong>本地</strong>的 PowerShell 中输入以下命令，将端口映射到本地：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -CNg -L 6006:127.0.0.1:6006 root@ssh.intern-ai.org.cn -p 你的 ssh 端口号</span><br></pre></td></tr></table></figure><p><img src="P5.png" alt=""></p><p>4.完成端口映射后，通过浏览器访问 <code>http://localhost:6006</code> 来启动我们的 Demo。</p><p><img src="P6.png" alt=""></p><h1 id="LMDeploy-部署"><a href="#LMDeploy-部署" class="headerlink" title="LMDeploy 部署"></a>LMDeploy 部署</h1><h2 id="一、InternLM-XComposer2-VL-1-8B-模型"><a href="#一、InternLM-XComposer2-VL-1-8B-模型" class="headerlink" title="一、InternLM-XComposer2-VL-1.8B 模型"></a>一、InternLM-XComposer2-VL-1.8B 模型</h2><h3 id="模型介绍："><a href="#模型介绍：" class="headerlink" title="模型介绍："></a>模型介绍：</h3><p>InternLM-XComposer2 是一款基于 InternLM2 的视觉语言大模型，其擅长自由形式的文本图像合成和理解。其主要特点包括：</p><ul><li>自由形式的交错文本图像合成：InternLM-XComposer2 可以根据大纲、详细文本要求和参考图像等不同输入，生成连贯且上下文相关，具有交错图像和文本的文章，从而实现高度可定制的内容创建。</li><li>准确的视觉语言问题解决：InternLM-XComposer2 基于自由形式的指令准确地处理多样化和具有挑战性的视觉语言问答任务，在识别，感知，详细标签，视觉推理等方面表现出色。</li></ul><h3 id="部署步骤："><a href="#部署步骤：" class="headerlink" title="部署步骤："></a>部署步骤：</h3><p>1.激活环境并安装 LMDeploy 以及其他依赖。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conda activate demo</span><br><span class="line">pip install lmdeploy[all]==0.5.1</span><br><span class="line">pip install timm==1.0.7</span><br></pre></td></tr></table></figure><p><img src="P7.png" alt=""></p><p>2.使用 LMDeploy 启动一个与 InternLM-XComposer2-VL-1.8B 模型交互的 Gradio 服务。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lmdeploy serve gradio /share/new_models/Shanghai_AI_Laboratory/internlm-xcomposer2-vl-1_8b --cache-max-entry-count 0.1</span><br></pre></td></tr></table></figure><p><img src="P8.png" alt=""></p><p>3.若已关闭端口映射，重新输入以下代码即可:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -CNg -L 6006:127.0.0.1:6006 root@ssh.intern-ai.org.cn -p 36558</span><br></pre></td></tr></table></figure><p><img src="P9.png" alt=""></p><p>通过浏览器访问 <code>http://localhost:6006</code> 来启动==InternLM-XComposer2-VL-1.8B==模型</p><p><img src="P10.png" alt=""></p><p>输入图片并询问图片里有什么：</p><p><img src="cat.png" alt=""></p><p>输出：</p><p><img src="P11.png" alt=""></p><h2 id="二、InternVL2-2B-模型"><a href="#二、InternVL2-2B-模型" class="headerlink" title="二、InternVL2-2B 模型"></a>二、InternVL2-2B 模型</h2><h3 id="模型介绍"><a href="#模型介绍" class="headerlink" title="模型介绍:"></a>模型介绍:</h3><p>InternVL2 是上海人工智能实验室推出的新一代视觉-语言多模态大模型，是首个综合性能媲美国际闭源商业模型的开源多模态大模型。InternVL2 系列从千亿大模型到端侧小模型全覆盖，通专融合，支持多种模态。</p><h3 id="部署步骤：-1"><a href="#部署步骤：-1" class="headerlink" title="部署步骤："></a>部署步骤：</h3><p>1.通过下面的命令来启动 InternVL2-2B 模型的 Gradio 服务:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda activate demo</span><br><span class="line">lmdeploy serve gradio /share/new_models/OpenGVLab/InternVL2-2B --cache-max-entry-count 0.1</span><br></pre></td></tr></table></figure><p>2.若已关闭端口映射，重新输入以下代码即可:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -CNg -L 6006:127.0.0.1:6006 root@ssh.intern-ai.org.cn -p 36558</span><br></pre></td></tr></table></figure><p><img src="P9.png" alt=""></p><p>通过浏览器访问 <code>http://localhost:6006</code> 来启动==InternVL2-2B==模型</p><p>输入图片并询问详细描述图片内容：</p><p><img src="cat2.png" alt=""><br>输出：</p><p><img src="P12.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 书生·浦语三期实战营 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>博客：书生·浦语大模型全链路开源开放体系及其最新发展</title>
      <link href="/2024/08/08/%E4%B9%A6%E7%94%9F%C2%B7%E6%B5%A6%E8%AF%AD%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%85%A8%E9%93%BE%E8%B7%AF%E5%BC%80%E6%BA%90%E5%BC%80%E6%94%BE%E4%BD%93%E7%B3%BB%E5%8F%8A%E5%85%B6%E6%9C%80%E6%96%B0%E5%8F%91%E5%B1%95/"/>
      <url>/2024/08/08/%E4%B9%A6%E7%94%9F%C2%B7%E6%B5%A6%E8%AF%AD%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%85%A8%E9%93%BE%E8%B7%AF%E5%BC%80%E6%BA%90%E5%BC%80%E6%94%BE%E4%BD%93%E7%B3%BB%E5%8F%8A%E5%85%B6%E6%9C%80%E6%96%B0%E5%8F%91%E5%B1%95/</url>
      
        <content type="html"><![CDATA[<h1 id="博客：书生·浦语大模型全链路开源开放体系及其最新发展"><a href="#博客：书生·浦语大模型全链路开源开放体系及其最新发展" class="headerlink" title="博客：书生·浦语大模型全链路开源开放体系及其最新发展"></a>博客：书生·浦语大模型全链路开源开放体系及其最新发展</h1><p><img src="1.png" alt=""></p><p>在现代人工智能技术的迅猛发展浪潮中，书生·浦语大模型全链路开源开放体系以其独特的优势和卓越的性能，在各个领域中不断取得突破性进展。本文将详细介绍该体系的发展历程、最新版本的特征、基于规则、模型和反馈的数据生成方法，以及mind search项目、开源数据提取工具和预训练框架、EXTINA的评测和部署、知识管理工具等各个方面的应用与优化策略。</p><h2 id="书生·浦语大模型全链路开源开放体系的历程及最新版本的特征"><a href="#书生·浦语大模型全链路开源开放体系的历程及最新版本的特征" class="headerlink" title="书生·浦语大模型全链路开源开放体系的历程及最新版本的特征"></a>书生·浦语大模型全链路开源开放体系的历程及最新版本的特征</h2><p>书生·浦语大模型开源开放体系在多个方面表现出色，包括数据收集整理、模型训练、微调、评测和搜索引擎AI应用的部署等方面。最新版本书生·浦语大模型2.5在推理能力和短期记忆等方面有质的飞跃，并开放了label LLM项目，方便标注数据。此外，视频还介绍了模型的性能天梯和应用前景。</p><ul><li><strong>书生浦语大模型开源开放体系</strong></li><li><strong>InputLM2.5性能飞跃</strong></li><li><strong>迭代发展过程中的数据驱动模型性能</strong></li></ul><h2 id="基于规则、模型和反馈的数据生成方法，以及如何使用开源项目进行标注和推理"><a href="#基于规则、模型和反馈的数据生成方法，以及如何使用开源项目进行标注和推理" class="headerlink" title="基于规则、模型和反馈的数据生成方法，以及如何使用开源项目进行标注和推理"></a>基于规则、模型和反馈的数据生成方法，以及如何使用开源项目进行标注和推理</h2><p>反映模型的数据生成方法在模型优化和训练过程中至关重要，以下是一些关键方法的介绍：</p><ul><li><strong>基于模型的反馈数据生成方法</strong>：包括相似度对齐和基于反馈的强化训练。</li><li><strong>大海捞针实验</strong>：介绍模型的推理能力和大海捞针实验，模型在处理稀长背景知识的表现。</li><li><strong>问题匹配分块</strong>：介绍问题匹配分块的方法，可以用于语言模型的索引和问题理解。</li></ul><h2 id="mind-search项目"><a href="#mind-search项目" class="headerlink" title="mind search项目"></a>mind search项目</h2><p>mind search项目展示了其在语言模型、预训练模型、微调框架、部署工具等方面的强大功能和应用潜力。</p><ul><li><strong>Mindsearch项目和书生普与开源模型谱系</strong></li><li><strong>部署工具和评测工具</strong></li><li><strong>应用方面的工具和框架</strong></li></ul><h2 id="开源数据提取工具Minor-U和预训练框架XTNER"><a href="#开源数据提取工具Minor-U和预训练框架XTNER" class="headerlink" title="开源数据提取工具Minor U和预训练框架XTNER"></a>开源数据提取工具Minor U和预训练框架XTNER</h2><p>Minor U和XTNER提供了无缝衔接和数据格式兼容性的功能，极大地加速了模型的训练和优化过程。</p><ul><li><strong>智能体框架和开源工具无缝衔接</strong></li><li><strong>微调框架和数据格式兼容性</strong></li><li><strong>使用XTNER进行微调的方法和流程</strong></li></ul><h2 id="EXTINA的评测和部署"><a href="#EXTINA的评测和部署" class="headerlink" title="EXTINA的评测和部署"></a>EXTINA的评测和部署</h2><p>EXTINA通过微调和Open Compass评测模型，以及lm deploy的推理性能对比，构建了智能体框架建设方案。</p><ul><li><strong>使用EXTINA微调和Open Compass评测模型</strong></li><li><strong>lm deploy模型部署框架和智能体框架</strong></li><li><strong>基于AI的搜索引擎和知识插件</strong></li></ul><h2 id="知识管理工具笞香豆的企业级应用"><a href="#知识管理工具笞香豆的企业级应用" class="headerlink" title="知识管理工具笞香豆的企业级应用"></a>知识管理工具笞香豆的企业级应用</h2><p>知识管理工具笞香豆通过可视化、强生和知识图谱生成，支持搜索和思考过程的展示，推动了开源生态系统的完善和实践营的创新发展。</p><ul><li><strong>思维可视化</strong>：通过搜索和思考1900年和1924年的相关信息，展示了模拟人脑思维逻辑的可视化过程。</li><li><strong>支持检索增强生成和知识图谱</strong>：理解群体行为。</li><li><strong>赋能创新</strong>：通过开源生态实践营，持续以高质量的开源赋能创新。</li></ul><p>在人工智能的快速发展中，书生·浦语大模型全链路开源开放体系无疑是一颗璀璨的明珠。它不仅在技术上不断推陈出新，在应用上也不断拓展，为各行各业带来了无限的可能。期待未来它能为更多领域提供支持，推动社会的智能化发展。</p>]]></content>
      
      
      <categories>
          
          <category> 书生·浦语三期实战营 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>电力预测task3笔记</title>
      <link href="/2024/07/20/%E7%94%B5%E5%8A%9B%E9%A2%84%E6%B5%8Btask3%E7%AC%94%E8%AE%B0/"/>
      <url>/2024/07/20/%E7%94%B5%E5%8A%9B%E9%A2%84%E6%B5%8Btask3%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Datawhale AI夏令营</span><br></pre></td></tr></table></figure><p>时间序列分析中的特征提取与优化策略</p><p>在时间序列分析中，特征提取是影响模型性能的关键步骤。以下是关键特征提取方法及其分析：</p><h4 id="1-日期变量"><a href="#1-日期变量" class="headerlink" title="1. 日期变量"></a>1. 日期变量</h4><p>时间序列数据通常包含日期信息，可以细分为年、月、周、日、小时等。将这些日期变量转换为数值特征，便于模型处理。</p><h4 id="2-周期性"><a href="#2-周期性" class="headerlink" title="2. 周期性"></a>2. 周期性</h4><p>许多时间序列表现出周期性，如每日、每周或每月的模式。识别并利用这些周期特征有助于捕捉数据的内在规律。</p><h4 id="3-趋势性"><a href="#3-趋势性" class="headerlink" title="3. 趋势性"></a>3. 趋势性</h4><p>趋势性是指时间序列的长期变化趋势。可以通过移动平均或线性回归提取，作为模型的输入特征。</p><h4 id="4-时间差"><a href="#4-时间差" class="headerlink" title="4. 时间差"></a>4. 时间差</h4><p>计算与特定日期的时间差（如重要事件日），帮助模型了解数据点的相对位置。</p><h4 id="5-时间特征组合"><a href="#5-时间特征组合" class="headerlink" title="5. 时间特征组合"></a>5. 时间特征组合</h4><p>组合不同的时间单位（如年和周）提供更丰富的时间信息，揭示复杂模式。</p><h4 id="6-特殊日期"><a href="#6-特殊日期" class="headerlink" title="6. 特殊日期"></a>6. 特殊日期</h4><p>识别特殊事件（如节假日）并将其作为特征，有助于解释相关数据波动。</p><h4 id="7-异常点"><a href="#7-异常点" class="headerlink" title="7. 异常点"></a>7. 异常点</h4><p>异常点与其他数据显著不同，正确处理这些点对提高预测精度至关重要。</p><h4 id="8-时序相关特征"><a href="#8-时序相关特征" class="headerlink" title="8. 时序相关特征"></a>8. 时序相关特征</h4><ul><li><strong>历史平移</strong>：使用过去的值预测未来。</li><li><strong>滑窗统计</strong>：在时间窗口内计算统计量，如均值、中位数等，帮助捕捉局部数据特性。</li></ul><h4 id="9-强相关特征"><a href="#9-强相关特征" class="headerlink" title="9. 强相关特征"></a>9. 强相关特征</h4><p>识别与目标变量强相关的特征，构建预测模型。</p><h3 id="特征优化方法"><a href="#特征优化方法" class="headerlink" title="特征优化方法"></a>特征优化方法</h3><ol><li><p><strong>提取更多特征</strong>：思考哪些信息能提高预测精度，并将其转化为模型输入。</p></li><li><p><strong>尝试不同模型</strong>：通过实验和试错，找到最佳模型组合。</p></li></ol><h3 id="特征优化技术"><a href="#特征优化技术" class="headerlink" title="特征优化技术"></a>特征优化技术</h3><ul><li><strong>历史平移特征</strong>：获取过去阶段的信息。</li><li><strong>差分特征</strong>：捕捉相邻阶段的增长变化，构建相邻数据比值变化和二阶差分。</li><li><strong>窗口统计特征</strong>：不同窗口大小下的统计量反映最近阶段的数据变化。</li></ul><h3 id="模型融合"><a href="#模型融合" class="headerlink" title="模型融合"></a>模型融合</h3><p>使用多个模型结果进行融合（如CatBoost、XGBoost、LightGBM），常用方法包括加权平均和Stacking：</p><ul><li><strong>Stacking</strong>：<ul><li><strong>第一层</strong>：对各个模型进行交叉验证，生成预测标签。</li><li><strong>第二层</strong>：使用第一层输出作为特征，再次训练模型。</li></ul></li></ul><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>时间序列预测不断发展，以下是未来的研究方向：</p><ul><li><strong>复杂模型结构</strong>：如引入注意力机制的LSTM模型。</li><li><strong>多模态数据融合</strong>：结合时间序列与其他数据类型。</li><li><strong>模型解释性</strong>：提高对预测结果的理解。</li><li><strong>自动化特征工程</strong>：减少手动特征提取。</li><li><strong>实时预测</strong>：提高实时数据预测能力。</li><li><strong>模型鲁棒性</strong>：增强对异常值和噪声的处理能力。</li></ul><p>随着技术进步，时间序列预测的准确性和应用范围将显著提升。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>python-debug</title>
      <link href="/2024/07/19/python-debug/"/>
      <url>/2024/07/19/python-debug/</url>
      
        <content type="html"><![CDATA[<h1 id="任务一"><a href="#任务一" class="headerlink" title="任务一"></a>任务一</h1><p>  请用Python实现一个wordcount函数，统计英文字符串中每个单词出现的次数。返回一个字典，key为单词，value为对应单词出现的次数。</p><h2 id="源程序："><a href="#源程序：" class="headerlink" title="源程序："></a>源程序：</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;  请用Python实现一个wordcount函数，统计英文字符串中每个单词出现的次数。返回一个字典，key为单词，value为对应单词出现的次数。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    TIPS：记得先去掉标点符号,然后把每个单词转换成小写。不需要考虑特别多的标点符号，只需要考虑实例输入中存在的就可以。&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">text = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Got this panda plush toy for my daughter&#x27;s birthday,</span></span><br><span class="line"><span class="string">who loves it and takes it everywhere. It&#x27;s soft and</span></span><br><span class="line"><span class="string">super cute, and its face has a friendly look. It&#x27;s</span></span><br><span class="line"><span class="string">a bit small for what I paid though. I think there</span></span><br><span class="line"><span class="string">might be other options that are bigger for the</span></span><br><span class="line"><span class="string">same price. It arrived a day earlier than expected,</span></span><br><span class="line"><span class="string">so I got to play with it myself before I gave it</span></span><br><span class="line"><span class="string">to her.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">wordcount</span>(<span class="params">text</span>):</span><br><span class="line"></span><br><span class="line">    text=text.replace(<span class="string">&quot;,&quot;</span>,<span class="string">&quot;&quot;</span>)</span><br><span class="line">    text=text.replace(<span class="string">&quot;.&quot;</span>,<span class="string">&quot;&quot;</span>)</span><br><span class="line">    text=text.replace(<span class="string">&quot;\n&quot;</span>,<span class="string">&quot;&quot;</span>)</span><br><span class="line"></span><br><span class="line">    text_list=text.split(<span class="string">&quot; &quot;</span>)</span><br><span class="line">    text_dict=&#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> text_list:</span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> text_dict:</span><br><span class="line">            text_dict[i]=<span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            text_dict[i]+=<span class="number">1</span></span><br><span class="line">            </span><br><span class="line">    <span class="keyword">return</span> text_dict</span><br><span class="line">    </span><br><span class="line"><span class="built_in">print</span>(wordcount(text))</span><br></pre></td></tr></table></figure><h1 id="任务二"><a href="#任务二" class="headerlink" title="任务二"></a>任务二</h1><p>请使用本地vscode连接远程开发机，将上面你写的wordcount函数在开发机上进行debug，体验debug的全流程，并完成一份debug笔记(需要截图)。</p><p>1.首先重命名debug命令</p><p>在bashrc配置文件中输入:<br><code>alias pyd=&#39;python -m debugpy --wait-for-client --listen 5678&#39;</code></p><p>再输入保存命令：<br><code>source ~/.bashrc</code></p><p><img src="1.png" alt=""></p><p>2.执行debug命令，启动服务端</p><p><code>pyd ./wordcount.py</code></p><p><img src="2.png" alt=""></p><p>3.启动客户端</p><p><img src="3.png" alt=""></p><p>响应返回：</p><p><img src="4.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>时间序列</title>
      <link href="/2024/05/17/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/"/>
      <url>/2024/05/17/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> 数学建模 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>🍉Book-10章-降维与度量学习</title>
      <link href="/2024/05/16/%F0%9F%8D%89Book-10%E7%AB%A0-%E9%99%8D%E7%BB%B4%E4%B8%8E%E5%BA%A6%E9%87%8F%E5%AD%A6%E4%B9%A0/"/>
      <url>/2024/05/16/%F0%9F%8D%89Book-10%E7%AB%A0-%E9%99%8D%E7%BB%B4%E4%B8%8E%E5%BA%A6%E9%87%8F%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> 🍉Book </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>🍉Book-9章-聚类</title>
      <link href="/2024/05/16/%F0%9F%8D%89Book-9%E7%AB%A0-%E8%81%9A%E7%B1%BB/"/>
      <url>/2024/05/16/%F0%9F%8D%89Book-9%E7%AB%A0-%E8%81%9A%E7%B1%BB/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> 🍉Book </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>🍉Book-8章-集成学习</title>
      <link href="/2024/05/16/%F0%9F%8D%89Book-8%E7%AB%A0-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/"/>
      <url>/2024/05/16/%F0%9F%8D%89Book-8%E7%AB%A0-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> 🍉Book </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>🍉Book-7章-贝叶斯分类器</title>
      <link href="/2024/05/16/%F0%9F%8D%89Book-7%E7%AB%A0-%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8/"/>
      <url>/2024/05/16/%F0%9F%8D%89Book-7%E7%AB%A0-%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> 🍉Book </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>🍉Book-6章-支持向量机</title>
      <link href="/2024/05/16/%F0%9F%8D%89Book-6%E7%AB%A0-%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/"/>
      <url>/2024/05/16/%F0%9F%8D%89Book-6%E7%AB%A0-%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/</url>
      
        <content type="html"><![CDATA[<h1 id="章节介绍"><a href="#章节介绍" class="headerlink" title="章节介绍"></a>章节介绍</h1><p>统计学领域名声赫赫的<strong>SVM</strong>与<strong>核方法</strong>是时至今日仍在高频使用的经典算法。</p><h1 id="笔记介绍"><a href="#笔记介绍" class="headerlink" title="笔记介绍"></a>笔记介绍</h1><p>对本章各节知识点进行汇总，主要分为<u>引入原因，原理思想，和一些思考</u>，对于数学推导内容介绍较少，有需要的可以先阅读西瓜书，再参考南瓜书的数学推导。</p><h1 id="数学知识"><a href="#数学知识" class="headerlink" title="数学知识"></a>数学知识</h1><p>大部分都是规划类、最优化的问题，最好先进行相关知识的学习。</p><p>这里<strong>推荐一本书</strong>：最优化：建模、算法与理论 (刘浩洋 户将 李勇锋 文再文)</p><h1 id="SVM-支持向量机"><a href="#SVM-支持向量机" class="headerlink" title="SVM-支持向量机"></a>SVM-支持向量机</h1><h2 id="引入原因："><a href="#引入原因：" class="headerlink" title="引入原因："></a>引入原因：</h2><p>在<strong>线性可分</strong>的条件下，我们在训练集做分类任务时，最基本的想法就是在样本空间中找到一个<strong>超平面</strong>进行划分,<br>但是对于分类任务，我们可以画出很多个超平面，这时候就需要引入<strong>损失函数</strong>，对超平面进行选择，而使得==两个异类支持向量==的<u>距离最大化</u>，就是我们所说的支持向量机的<strong>基本型</strong>。</p><p><img src="1.jpg" alt=""></p><h2 id="数学公式及其原理："><a href="#数学公式及其原理：" class="headerlink" title="数学公式及其原理："></a>数学公式及其原理：</h2><p>仍用<strong>线性模型</strong>来表示一个<strong>超平面</strong>：</p><script type="math/tex; mode=display">w ^ { T } x + b = 0</script><p>而<strong>点到超平面的距离</strong>表示为：<br>参考<u>点到直线距离公式</u>即可理解</p><script type="math/tex; mode=display">r = \frac { | w ^ { T } x + b | } { | | w | | }</script><p>两个<strong>异类支持向量到超平面的距离</strong>（称为==间隔== margin）表示为：<br>参考<u>平行直线间的距离公式</u>即可理解<br>（此处分子为2的原因是==假设==正负类标记为+1与-1）</p><script type="math/tex; mode=display">\gamma = \frac { 2 } { | | w | | }</script><p><img src="2.jpg" alt=""></p><p>我们的目标是使得<u>间隔最大化</u>，即意味着要取得$| | w | |$​最小化，也就是$| | w | | ^ { 2 }$​最小化<br>所以我们最终可以的到SVM基本型：<br><img src="3.jpg" alt=""></p><h2 id="求解方法："><a href="#求解方法：" class="headerlink" title="求解方法："></a>求解方法：</h2><p>涉及到二次规划问题，使用==拉格朗日乘子法==解决问题，我们会得到<u>基本型</u>的“<strong>对偶问题</strong>”</p><p>具体方法不做详解，此处仅做大概阐述：</p><ol><li>在SVM基本型的每条约束上增加一个拉格朗日乘子a，得到新的函数</li><li>新函数对w和b分别求偏导=0，得到w和b关于a的表达式</li><li>将表达式回代入函数，就得到了仅依赖于a的函数，就将约束问题转化成无约束问题</li><li>此时使用梯度下降、牛顿法等无约束优化算法可得出a，回代表达式得出w和b，完成原本函数的求解</li></ol><h1 id="核函数"><a href="#核函数" class="headerlink" title="核函数"></a>核函数</h1><h2 id="引入原因：-1"><a href="#引入原因：-1" class="headerlink" title="引入原因："></a>引入原因：</h2><p>由于前面的讨论都是基于训练集是==线性可分的假设==<br>而对于非线性可分的数据集，我们就可以采用核方法将<strong>数据集</strong>变成<u>线性可分</u>的</p><h2 id="升维思想："><a href="#升维思想：" class="headerlink" title="升维思想："></a>升维思想：</h2><blockquote><p>找到一个函数(即核函数)将非线性可分的数据映射为线性可分的数据</p></blockquote><h2 id="常用核函数："><a href="#常用核函数：" class="headerlink" title="常用核函数："></a>常用核函数：</h2><p>下面给出常用核函数：</p><p><img src="4.jpg" alt=""></p><h1 id="软间隔和正则化："><a href="#软间隔和正则化：" class="headerlink" title="软间隔和正则化："></a>软间隔和正则化：</h1><h2 id="引入原因：-2"><a href="#引入原因：-2" class="headerlink" title="引入原因："></a>引入原因：</h2><p>前面进行分类任务都是基于训练样本<u>线性可分的假设</u>，<br>而实际应用中，训练集存在噪声 或 难以找到合适的核函数将数据转化为线性可分的数据<br>如果找到了核函数也很有可能这个<u>线性可分的结果</u>是因为<u>模型过拟合</u>造成的。</p><p>所以我们引入了==软间隔==<strong>Soft Magrin</strong>这个概念，即<u>允许部分样本划分出错</u>。<br>而相应的，先前我们<u>让所有样本正确分类</u>就叫做==硬间隔==。</p><h2 id="正则化思想："><a href="#正则化思想：" class="headerlink" title="正则化思想："></a>正则化思想：</h2><p>其实软间隔也就是一种正则化，通过对不希望的到的结果进行惩罚，使得优化过程趋向于希望目标。</p><h1 id="支持向量回归"><a href="#支持向量回归" class="headerlink" title="支持向量回归"></a>支持向量回归</h1><h2 id="引入原因：-3"><a href="#引入原因：-3" class="headerlink" title="引入原因："></a>引入原因：</h2><p>我们一开始引入SVM就是为了解决分类问题，而对于回归问题是否也能通过SVM解决呢？🤔</p><p>为了解决回归问题，我们引入了==支持向量回归==，简称SVR(Support Vector Regression)</p><h2 id="方法思想："><a href="#方法思想：" class="headerlink" title="方法思想："></a>方法思想：</h2><p>在<strong>损失函数</strong>方面，与<u>传统的回归模型</u>用预测和标记的差别计算损失<u>不同</u>，</p><p>SVR<u>容忍</u>预测和标记之间<u>存在偏差</u>e，在偏差2e内都被判定为正确预测</p>]]></content>
      
      
      <categories>
          
          <category> 🍉Book </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>🍉Book-5章-神经网络</title>
      <link href="/2024/05/16/%F0%9F%8D%89Book-5%E7%AB%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
      <url>/2024/05/16/%F0%9F%8D%89Book-5%E7%AB%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<h1 id="神经网络模型"><a href="#神经网络模型" class="headerlink" title="神经网络模型"></a>神经网络模型</h1><p>1943年一直沿用至今的M-P神经网络模型</p><h2 id="M-P神经网络模型"><a href="#M-P神经网络模型" class="headerlink" title="M-P神经网络模型"></a>M-P神经网络模型</h2><h3 id="模型解释："><a href="#模型解释：" class="headerlink" title="模型解释："></a><strong>模型解释</strong>：</h3><p>将输入神经元的x乘上相应==权重w==并求和，将结果与==阈值==$\theta$做差，再经过==激活函数f==得到输出值y</p><h3 id="名词解释："><a href="#名词解释：" class="headerlink" title="名词解释："></a><strong>名词解释</strong>：</h3><p><strong>阈值</strong>(threshold / bias):<br>表示神经元电位超过阈值则被激活</p><p><strong>激活函数</strong>(activation function)：<br>也称<u>挤压函数</u>或<u>响应函数</u>，用于将输入值映射为0/1或(0，1)</p><h3 id="训练目标："><a href="#训练目标：" class="headerlink" title="训练目标："></a><strong>训练目标</strong>：</h3><p>通过训练模型，得出合适的w和$\theta$，其中训练算法最常见的就是下面会说到的BP算法</p><p><img src="1.png" alt=""></p><h2 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h2><p>回顾第三章线性模型中的<strong>对数几率回归</strong>模型和<strong>单位阶跃函数</strong></p><p>最理想状态是用==单位阶跃函数==输入值映射为0/1，但由于其不连续、不光滑的性质，<br>我们使用==Sigmoid函数==将输入值映射为(0，1)，Sigmoid函数即型为S的函数，其中我们最常用的就是对数几率函数：</p><script type="math/tex; mode=display">s i g m o i d ( x ) = \frac { 1 } { 1 + e ^ { - x } }</script><p><strong>对率函数</strong>有很好的==性质==：<script type="math/tex">f ^ { \prime } ( x ) = f \left( x \right) ( 1 - f \left( x \right) )</script></p><h1 id="万有逼近能力"><a href="#万有逼近能力" class="headerlink" title="万有逼近能力"></a>万有逼近能力</h1><h3 id="名词概念："><a href="#名词概念：" class="headerlink" title="名词概念："></a>名词概念：</h3><p>仅需一个包含足够多神经元的隐层，多层前馈神经网络就能以任意精度逼近任意复杂度的连续函数</p><h3 id="引入原因："><a href="#引入原因：" class="headerlink" title="引入原因："></a>引入原因：</h3><p>很多算法都具有万有逼近能力，不是神经网络所特有的，如决策树、支持向量机等等。<br>而之所以在神经网络中强调其万有逼近能力，是因为其数学公理方面的理论薄弱，为了证明其有效性而进行说明。</p><h1 id="BP算法"><a href="#BP算法" class="headerlink" title="BP算法"></a>BP算法</h1><p><strong>误差逆传播</strong>(error BackPropagation，简称BP)算法，亦称<strong>反向传播算法</strong></p><p>BP算法是一种迭代算法，基于==梯度下降==(gradient descent)策略，<br>数学推导过程不多做阐述，详见西瓜书or南瓜书</p><p><img src="2.png" alt=""></p><h1 id="缓解过拟合"><a href="#缓解过拟合" class="headerlink" title="缓解过拟合"></a>缓解过拟合</h1><p>由于神经网络强大的表示能力，其经常容易<strong>过拟合</strong>，为此我们有以下两种<strong>策略</strong></p><h2 id="1-早停-early-stopping"><a href="#1-早停-early-stopping" class="headerlink" title="1.早停(early stopping)"></a>1.早停(early stopping)</h2><p>将数据集分为训练集和验证集，若验证集得到的误差升高，则停止训练。</p><p>但是很显然神经网络的误差可能是细微的波动，但却造成了训练的停止，有点像决策树中的预剪枝，基于贪心的策略。</p><p>所以采用：</p><ul><li>若训练误差<strong>连续α轮</strong>的变化小于b，则停止训练使用验证集</li><li>若训练误差降低、验证误差升高，则停止训练</li></ul><h2 id="2-正则化-regularization"><a href="#2-正则化-regularization" class="headerlink" title="2.正则化(regularization)"></a>2.正则化(regularization)</h2><p>在误差目标函数中增加一项描述网络复杂度</p><script type="math/tex; mode=display">E = \lambda \frac { 1 } { m } \sum _ { k = 1 } ^ { m } E _ { k } + ( 1 - \lambda ) \sum _ { i } w _ { i } ^ { 2 }</script><p>偏好比较小的连接权和阀值，使网络输出更“光滑”</p>]]></content>
      
      
      <categories>
          
          <category> 🍉Book </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>🍉Book-5章-神经网络</title>
      <link href="/2024/05/16/%F0%9F%8D%89Book-8%E7%AB%A0-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/%F0%9F%8D%89Book-5%E7%AB%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
      <url>/2024/05/16/%F0%9F%8D%89Book-8%E7%AB%A0-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/%F0%9F%8D%89Book-5%E7%AB%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<h1 id="神经网络模型"><a href="#神经网络模型" class="headerlink" title="神经网络模型"></a>神经网络模型</h1><p>1943年一直沿用至今的M-P神经网络模型</p><h2 id="M-P神经网络模型"><a href="#M-P神经网络模型" class="headerlink" title="M-P神经网络模型"></a>M-P神经网络模型</h2><h3 id="模型解释："><a href="#模型解释：" class="headerlink" title="模型解释："></a><strong>模型解释</strong>：</h3><p>将输入神经元的x乘上相应==权重w==并求和，将结果与==阈值==$\theta$做差，再经过==激活函数f==得到输出值y</p><h3 id="名词解释："><a href="#名词解释：" class="headerlink" title="名词解释："></a><strong>名词解释</strong>：</h3><p><strong>阈值</strong>(threshold / bias):<br>表示神经元电位超过阈值则被激活</p><p><strong>激活函数</strong>(activation function)：<br>也称<u>挤压函数</u>或<u>响应函数</u>，用于将输入值映射为0/1或(0，1)</p><h3 id="训练目标："><a href="#训练目标：" class="headerlink" title="训练目标："></a><strong>训练目标</strong>：</h3><p>通过训练模型，得出合适的w和$\theta$，其中训练算法最常见的就是下面会说到的BP算法</p><p>![[Pasted image 20240531074642.png]]</p><h2 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h2><p>回顾第三章线性模型中的<strong>对数几率回归</strong>模型和<strong>单位阶跃函数</strong></p><p>最理想状态是用==单位阶跃函数==输入值映射为0/1，但由于其不连续、不光滑的性质，<br>我们使用==Sigmoid函数==将输入值映射为(0，1)，Sigmoid函数即型为S的函数，其中我们最常用的就是对数几率函数：</p><script type="math/tex; mode=display">s i g m o i d ( x ) = \frac { 1 } { 1 + e ^ { - x } }</script><p><strong>对率函数</strong>有很好的==性质==：<script type="math/tex">f ^ { \prime } ( x ) = f \left( x \right) ( 1 - f \left( x \right) )</script></p><h1 id="万有逼近能力"><a href="#万有逼近能力" class="headerlink" title="万有逼近能力"></a>万有逼近能力</h1><h3 id="名词概念："><a href="#名词概念：" class="headerlink" title="名词概念："></a>名词概念：</h3><p>仅需一个包含足够多神经元的隐层，多层前馈神经网络就能以任意精度逼近任意复杂度的连续函数</p><h3 id="引入原因："><a href="#引入原因：" class="headerlink" title="引入原因："></a>引入原因：</h3><p>很多算法都具有万有逼近能力，不是神经网络所特有的，如决策树、支持向量机等等。<br>而之所以在神经网络中强调其万有逼近能力，是因为其数学公理方面的理论薄弱，为了证明其有效性而进行说明。</p><h1 id="BP算法"><a href="#BP算法" class="headerlink" title="BP算法"></a>BP算法</h1><p><strong>误差逆传播</strong>(error BackPropagation，简称BP)算法，亦称<strong>反向传播算法</strong></p><h1 id="缓解过拟合"><a href="#缓解过拟合" class="headerlink" title="缓解过拟合"></a>缓解过拟合</h1>]]></content>
      
      
      <categories>
          
          <category> 🍉Book </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>🍉Book-4章-决策树</title>
      <link href="/2024/05/16/%F0%9F%8D%89Book-4%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/"/>
      <url>/2024/05/16/%F0%9F%8D%89Book-4%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/</url>
      
        <content type="html"><![CDATA[<h1 id="递归终止条件"><a href="#递归终止条件" class="headerlink" title="递归终止条件"></a>递归终止条件</h1><p>决策树使用递归实现，而递归终止条件有以下三种：</p><ol><li>当前结点所有样本属于同类，无需划分</li><li>当前属性集为空，无法划分，选取==此节点==中数量更多的标记作为类别标记</li><li>当前样本集为空，不能划分，依据==父节点==中数量更多的标记作为类别标记</li></ol><h1 id="名词概念"><a href="#名词概念" class="headerlink" title="名词概念"></a>名词概念</h1><p>1.纯度：同类聚集程度高、不同类越分散，则纯度越高<br>2.信息熵：纯度的量化指标，来源于信息论<br>3.剪枝：防止决策树过拟合，减去部分划分属性。分为预剪枝和后剪枝</p><h1 id="信息熵"><a href="#信息熵" class="headerlink" title="信息熵"></a>信息熵</h1><p>==信息熵计算公式==：</p><script type="math/tex; mode=display">E n t ( D ) = - \sum _ { k = 1 } ^ { | y | } p _ { k } \log _ { 2 } p _ { k }</script><p>==信息熵用于衡量信息的不确定性或信息的混乱程度==，我们可以将其用于<strong>量化纯度</strong><br>信息熵越大，数据分布越均匀、随机、杂乱无章，明显这不是我们想要的。<br>我们想要的是相同类靠近，不同类远离的效果，即<strong>需要越小的信息熵</strong></p><p>$p_k$表示选到k类别的<strong>概率</strong>，而 $-\log _ { 2 } p _ { k }$则表示<strong>信息量</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">我们可以理解对于某一事件，其发生的概率越小，那么其信息量越大；发生的概率越大，那么其信息量越小。所有对两者求期望即得到信息熵。</span><br></pre></td></tr></table></figure><p>==注意==：此处计算公式里的Y的<strong>输出值种类</strong>，如二分类问题中Y=2</p><h1 id="划分选择"><a href="#划分选择" class="headerlink" title="划分选择"></a>划分选择</h1><p>决策树中<u>最重要</u>的部分，用于<strong>选择最佳划分属性</strong></p><h2 id="1-信息增益-Information-Gain"><a href="#1-信息增益-Information-Gain" class="headerlink" title="1.信息增益(Information Gain)"></a>1.信息增益(Information Gain)</h2><p>计算==某属性==的信息增益，用<u>根节点</u>的信息熵-属性<u>各个</u>属性值的<u>信息熵的加权平均值</u><br><strong>信息增益越大，意味着使用属性a进行划分获得的纯度提升越大</strong></p><script type="math/tex; mode=display">Gain ( D , a ) = E n t ( D ) - \sum _ { v = 1 } ^ { V } \frac { | D ^ { v } | } { | D | } E n t ( D ^ { v } )</script><h2 id="2-增益率-Gain-Ratio"><a href="#2-增益率-Gain-Ratio" class="headerlink" title="2.增益率(Gain Ratio)"></a>2.增益率(Gain Ratio)</h2><p>由于<strong>信息增益</strong>对于<u>取值数目较多</u>的属性==有所偏好==，所以引进<strong>增益率</strong>进行选择最优划分属性，比如著名的<u>C4.5决策树算法</u></p><p>==当属性a的可能取值数目越多时(即V越大)，IV(a)越小，相应的增益率就越大==<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">我们可以这样理解，IV(a)计算的其实就是信息熵，当属性值数目越多时，样本分类就越多且彼此之间就越分散越混乱，而我们希望分类效果越好，就需要减少属性值可能取值个数。</span><br></pre></td></tr></table></figure></p><script type="math/tex; mode=display">Gain \space R a t i o ( D , a ) = \frac { G ain( D , a ) } { I V ( a ) }</script><script type="math/tex; mode=display">I V ( a ) = - \sum _ { v } ^ { V } \frac { | D ^ { v } | } { D } \log _ { 2 } \frac { | D ^ { v } | } { D }</script><h3 id="思考🤔："><a href="#思考🤔：" class="headerlink" title="思考🤔："></a>思考🤔：</h3><p>增益率可以减少 <u>信息增益对于属性值较多的属性有所偏好</u> 的问题，<br>但是同样的，==增益率对于属性值较少的属性有所偏好==<br>所以实际处理时，对于不同的属性的划分选择可以采取不同的方法，但是在==同一层==属性划分选择时只能使用同一种方法。</p><h2 id="3-基尼指数-Gini-Index"><a href="#3-基尼指数-Gini-Index" class="headerlink" title="3.基尼指数(Gini Index)"></a>3.基尼指数(Gini Index)</h2><p>含义：==反映从数据集中随机抽取两个样本，其类别标记不一致的概率==</p><p>用于<strong>CART决策树</strong>，既可以用于==分类==问题，也可以用于==回归==问题</p><p><strong>基尼指数越小，则数据集纯度越高</strong></p><script type="math/tex; mode=display">G i n i ( D ) = 1 - \sum _ { k = 1 } ^ { | y | } p _ { k } ^ { 2 }$$$$ G i n i \space I n d e x ( D , a ) = \sum _ { v = 1 } ^ { V } \frac { | D ^ { v } | } { | D | } G i n i ( D ^ { v } )</script><h1 id="剪枝-Pruning"><a href="#剪枝-Pruning" class="headerlink" title="剪枝(Pruning)"></a>剪枝(Pruning)</h1><p>为了==防止决策树模型过拟合==而采取的手段<br>分为<strong>预剪枝</strong>与<strong>后剪枝</strong>两种方法</p><p>==PS==：需要先选定 <u>评估方法</u>和<u>性能度量</u>（第二章知识内容）<br>下列假设使用<strong>留出法</strong>，以<strong>精度</strong>为性能度量</p><h2 id="预剪枝-Prepruning"><a href="#预剪枝-Prepruning" class="headerlink" title="预剪枝(Prepruning)"></a>预剪枝(Prepruning)</h2><p>运用==贪心思想==，可能有弊端</p><p>在建立决策树的<u>过程中</u>进行剪枝，代入测试数据<br>将 当前精度 与 增加划分属性后的精度 进行比较，<br><strong>判断是否需要增加划分属性</strong></p><h2 id="后剪枝-Postpruning"><a href="#后剪枝-Postpruning" class="headerlink" title="后剪枝 (Postpruning)"></a>后剪枝 (Postpruning)</h2><p>在决策树建立<u>完成后</u>进行剪枝，代入测试数据<br>将 当前精度 与 把该结点属性变成叶子节点后的精度 进行比较<br><strong>判断是否需要剪去不要的树枝</strong><br><strong>优点</strong>：欠拟合风险小，泛化性能较好</p>]]></content>
      
      
      <categories>
          
          <category> 🍉Book </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>🍉Book-3章-线性模型</title>
      <link href="/2024/05/16/%F0%9F%8D%89Book-3%E7%AB%A0-%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/"/>
      <url>/2024/05/16/%F0%9F%8D%89Book-3%E7%AB%A0-%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="所需数学知识"><a href="#所需数学知识" class="headerlink" title="所需数学知识"></a>所需数学知识</h1><ol><li>求偏导</li><li>矩阵求导</li><li>求逆矩阵</li></ol><h1 id="名词解释"><a href="#名词解释" class="headerlink" title="名词解释"></a>名词解释</h1><p>1.<strong>序关系</strong></p><pre><code>有序：属性之间可进行相对比较（如大、中、小）无序：属性之间不可进行相对比较（如南瓜、西瓜、冬瓜）</code></pre><p>2.<strong>符号</strong>arg与s.t.</p><pre><code>arg：即argument（参数），用于表示求出指定函数时的**参数取值**    例如：    arg min 就是使后面这个式子达到最小值时的 变量的取值    arg max 就是使后面这个式子达到最大值时的 变量的取值s.t.：即subject to，意思是受限于...，后面紧跟约束条件</code></pre><p>3.<strong>闭式解</strong></p><pre><code>也叫做 解析解，闭式解就是一些严格的公式,给出任意的自变量就可以求出其因变量,也就是问题的解南瓜书中说闭式解是指可以通过具体的表达式解出待解参数</code></pre><h1 id="模型介绍"><a href="#模型介绍" class="headerlink" title="模型介绍"></a>模型介绍</h1><h2 id="表示形式"><a href="#表示形式" class="headerlink" title="表示形式"></a>表示形式</h2><p>对于拥有d个属性的示例 x，表示为：<script type="math/tex">x = ( x _ { 1 } ; x _ { 2 } ; \ldots ; x _ { d } )</script><br>其中$x_i$表示第i个属性的<strong>属性值</strong><br>而我们将<strong>各属性的线性组合</strong>作为线性模型，表示为：</p><script type="math/tex; mode=display">f ( x ) = w _ { 1 } x _ { 1 } + w _ { 2 } x _ { 2 } + \ldots + w _ { d } x _ { d } + b</script><center>也可写成向量形式</center>$$ f ( x ) = w ^ { T } x + b ,$$其中$w$和$x$均为列向量，其中$w$可以理解成为不同属性的**偏好**而赋予的**权重**故线性模型具有很强的**可解释性**## 模型优点1. 简单（模型表示、数学公式简单）2. 基本（通过引入**层级结构**或**高维映射**可以得到许多**非线性模型**）3. 可理解性好（通过**权重**可以看出对属性的**偏好**）# 属性数值化**总结**：==离散属性的处理：若有“序”(order)，则连续化；否则，转化为 𝑘维向量==对于线性模型的求解，我们首先需要明确**参数**的<u>输入</u>和<u>求解</u>两个部分我们知道**模型的输入**为各个示例 $x_i$，其中的$x_i$由d个属性组成，而我们用**d个属性值**表示一个**具体**的示例$x_i$作为输入这时我们会发现我们需要注意属性值的**数据类型**于是这里我们把属性分为两类1. 连续属性 2. 离散属性    * **有序**的离散属性    * **无序**的离散属性对于**有序**的属性，我们用**相对值**表示属性值，如大、中、小分别用1，0.5，0来表示对于**无序**的属性，我们用**0/1**表示属性值，我们记改属性有m种属性值，则一个属性值需要**m维列向量**进行表示。比如对于属性瓜的类别，有西瓜，南瓜，冬瓜 三种属性值，则表示为$$ x _ { 1 } = ( 1 ; 0 ; 0 ) , x _ { 2 } = (  0 ; 1 ; 0 ) , x _ { 3 } = (  0 ; 0 ; 1 ) $$这里表示示例$x_1,x_2,x_3$**分别**为西瓜，南瓜，冬瓜---对于==回归==，==二分类==，==多分类==任务，我们给出不同的线性模型![[西瓜书学习/西瓜书-第3章/1.png]]# 回归任务## 最小二乘法>在**第二章**中我们知道均方误差是**回归**任务的常见**性能度量**>均方误差本身也具有很好的**几何意义**，对于**欧氏距离****定义**：基于**均方误差最小化**进行模型求解，使得样本到直线的欧式距离之和最小**数学知识**：涉及求偏导数##  1.一元线性回归<center>1.假设方程</center>$$f\left(x_{i}\right)=w x_{i}+b, 使得 f\left(x_{i}\right) \simeq y_{i}.$$<center>2.均方误差最小化时的w和b的值</center>$$\begin{aligned}\left(w^{*}, b^{*}\right) & =\underset{(w, b)}{\arg \min } \sum_{i=1}^{m}\left(f\left(x_{i}\right)-y_{i}\right)^{2} \\ & =\underset{(w, b)}{\arg \min } \sum_{i=1}^{m}\left(y_{i}-w x_{i}-b\right)^{2} .\end{aligned}$$<center>3.均方误差对𝑤与𝑏求偏导</center>$$\begin{array}{l}\frac{\partial E_{(w, b)}}{\partial w}=2\left(w \sum_{i=1}^{m} x_{i}^{2}-\sum_{i=1}^{m}\left(y_{i}-b\right) x_{i}\right), \\ \frac{\partial E_{(w, b)}}{\partial b}=2\left(m b-\sum_{i=1}^{m}\left(y_{i}-w x_{i}\right)\right),\end{array}$$此处$E_{(w, b)}$是是关于w和b的凸函数**注意**：此处凸函数定义与 数学分析 中相同，与 高等数学 中相反<center>4.令偏导为0，得到闭式解，解得w和b</center>$$\begin{array}{c}w=\frac{\sum_{i=1}^{m} y_{i}\left(x_{i}-\bar{x}\right)}{\sum_{i=1}^{m} x_{i}^{2}-\frac{1}{m}\left(\sum_{i=1}^{m} x_{i}\right)^{2}}, \\ b=\frac{1}{m} \sum_{i=1}^{m}\left(y_{i}-w x_{i}\right)\end{array}$$## 2.多元线性回归**额外数学知识**:==矩阵求导==>基于本人数学系所教授的高等代数中无此内容，故认为需要额外补充学习详见西瓜书附录P400 `A.2 导数`<center>1.假设方程</center>$$f\left(\boldsymbol{x}_{i}\right)=\boldsymbol{w}^{\mathrm{T}} \boldsymbol{x}_{i}+b, 使得 f\left(\boldsymbol{x}_{i}\right) \simeq y_{i},$$<center>2.为便于讨论，把w和b吸收入向量形式 ，数据集表示为</center><script type="math/tex; mode=display">\mathbf{X}=\left(\begin{array}{ccccc}x_{11} & x_{12} & \ldots & x_{1 d} & 1 \\ x_{21} & x_{22} & \ldots & x_{2 d} & 1 \\ \vdots & \vdots & \ddots & \vdots & \vdots \\ x_{m 1} & x_{m 2} & \ldots & x_{m d} & 1\end{array}\right)=\left(\begin{array}{cc}\boldsymbol{x}_{1}^{\mathrm{T}} & 1 \\ \boldsymbol{x}_{2}^{\mathrm{T}} & 1 \\ \vdots & \vdots \\ \boldsymbol{x}_{m}^{\mathrm{T}} & 1\end{array}\right)</script><p><strong>示例中的属性值为列向量</strong>，同时将<strong>标记</strong>写成<strong>向量形式</strong>  $y = ( y _ { 1 } ; y _ { 2 } ; \ldots ; y _ { m } )$</p><p><strong>注意</strong>：此处将$f\left(\boldsymbol{x}_{i}\right)=\boldsymbol{w}^{\mathrm{T}} \boldsymbol{x}_{i}+b$中的 $b$ 拆成<code>b*1</code>的形式，用$x$吸收$1$，用$w$吸收$b$变成$\hat{\boldsymbol{w}}$</p><p>![[西瓜书学习/西瓜书-第3章/2.png]]<br><code>[图片源于周志华老师]</code></p><center>3.解得w</center>$$\hat{\boldsymbol{w}}^{*}=\left(\mathbf{X}^{\mathrm{T}} \mathbf{X}\right)^{-1} \mathbf{X}^{\mathrm{T}} \boldsymbol{y}$$<center>4.最终解得模型为：</center>$$f\left(\hat{\boldsymbol{x}}_{i}\right)=\hat{\boldsymbol{x}}_{i}^{\mathrm{T}}\left(\mathbf{X}^{\mathrm{T}} \mathbf{X}\right)^{-1} \mathbf{X}^{\mathrm{T}} \boldsymbol{y}.$$$1.若 X ^ { T } X 满 秩 或 正 定 , 则 w ^ { * } = ( X ^ { T } X ) ^ { - 1 } X ^ { T } y$$2.若X ^ { T } X 不 满 秩 , 则 可 解 出 多 个 \widehat { w }$此时需求助于**归纳偏好**，常见做法是引入 **正则化项**（详见6.4节，11.4节）>通过在损失函数中添加惩罚项来限制模型的复杂度，常见的正则化方法包括>岭回归（Ridge Regression）、Lasso回归和弹性网（Elastic Net）PS：$\widehat { w } ^ { * }$转换成**二次型**矩阵相乘还挺有意思的，推导详见南瓜书P35，P36## 3.广义线性模型(GLM)>令预测值逼近 y 的衍生物### 对数线性模型>假设我们认为示例所对应的输出标记是在**指数尺度**上变化，>那就可将**输出标记的对数**作为线性模型逼近的目标**个人理解**：其实就是我们在原样本中，通过数值或者散点图，观察到**输出标记**在**指数尺度**上变化，故**很难直接**用一条直线拟合输出标记，因为标记值本身为**非线性增长**。而对在指数尺度上变化的输出标记**取对数**后，就可以将输出标记**映射**到**线性尺度**上变化，故易于用直线拟合$$ y = w ^ { T } x + b $$<center>将输出标记 y 取对数转变为形式上的线性回归方程</center><script type="math/tex; mode=display">\ln y = w ^ { T } x + b</script><blockquote><p>实际上是在试图让$e ^ { w ^T x} + b$逼近y</p><p>这里的<strong>对数函数</strong>起到了将线性回归模型的<strong>预测值</strong>与<strong>真实标记</strong>联系起来的作用</p><p>但实质上已是在求取输入空间到输出空间的<strong>非线性函数映射</strong></p></blockquote><hr><p>我们知道，<strong>对数线性模型</strong>是使用<strong>对数函数</strong>将输出标记进行<strong>映射</strong></p><p>那么如果我们选取不同的<strong>函数</strong>对输出标记进行<strong>映射</strong>，<br>就能将一个<strong>非线性变化</strong>的样本用<strong>线性模型</strong>进行拟合了。</p><p>而此时问题就转变为<strong>映射函数的寻找</strong>了，需要找到一个合适的映射函数，将原来的标记值<strong>数据形态</strong>映射成线性的🤔</p><p>这里就涉及到模型的<strong>优化</strong>了，找到映射函数得到<strong>新的</strong>线性模型，并在<strong>某一性能度量</strong>下进行比较，结合<strong>需求</strong>选择模型。</p><hr><p>而由此我们引出了<strong>广义线性模型</strong>（Generalized Linear Model）的定义：</p><script type="math/tex; mode=display">y = g ^ { - 1 } ( w ^ { T } x + b )</script><p>其中$g ( \cdot )$为<strong>连续</strong>且<strong>充分光滑</strong>的<strong>单调可微</strong>函数，称为<strong>联系函数</strong>(link function)</p><blockquote><p>广义线性模型的<strong>参数估计</strong>常通过加权最小二乘法或极大似然法进行</p></blockquote><p>显然，<strong>对数线性回归</strong>是<strong>广义线性模型</strong>在 $g ( \cdot )$=$ln ( \cdot )$时的特例<br>显然，<strong>一元线性回归</strong>也是如此</p><h1 id="分类任务"><a href="#分类任务" class="headerlink" title="分类任务"></a>分类任务</h1><h2 id="引导"><a href="#引导" class="headerlink" title="引导"></a>引导</h2><p>在先前的文章：<code>西瓜书-第3章-线性模型 (Part 1) 中 我们介绍了</code></p><p><U>一元线性回归、多元线性回归、广义线性回归（对数线性回归）</U>的模型,<br>用于解决==回归类==问题</p><p>那么对于==分类==问题，我们又该使用哪种模型呢？<br>我们知道分类问题可以分成<U>二分类</U>与<U>多分类</U>问题</p><p>此处我们先介绍<U>二分类</U>问题所使用的模型</p><p>我们刚学过回归类问题的模型，此时我们运用==广义线性回归==的思想，<br>只要我们能找到一个==联系函数==，能够将<U>连续值变成离散值</U>，<br>即可将<U>回归类模型</U>运用到<U>分类问题</U>上。</p><h2 id="对数几率回归"><a href="#对数几率回归" class="headerlink" title="对数几率回归"></a>对数几率回归</h2><p>这里我们先给出“单位阶跃函数“(unit-step function)</p><p>此函数能够将输出范围在R上的标记 转换为离散值</p><blockquote><p>若预测值大于零就判为正例，小于零则判为反例，预测值为临界值零则可<br>   任意判别</p></blockquote><p><img src="https://img-blog.csdnimg.cn/direct/b1e0d606699d4ad0bf0fb4904882bd78.jpeg#pic_center" alt="在这里插入图片描述"><br>我们可以看出这个函数的效果是很不错的<br>但是因为其函数性质很差，不连续也不可微，不符合联系函数的定义</p><p>所以我们引进了==对数几率函数==，简称“对率函数”</p><script type="math/tex; mode=display">y = \frac { 1 } { 1 + e ^ { - z } } .</script><p>故有</p><script type="math/tex; mode=display">\ln \frac { y } { 1 - y } = w ^ { T } x + b .</script><p><img src="https://img-blog.csdnimg.cn/direct/62ffa64366c94340af6113681861aed6.png" alt="在这里插入图片描述"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">若将y 视为样本x 作为正例的可能性，则1 - y 是其反例可能性,两者的比值称为“几率”(odds),反映了x作为正例的相对可能性。</span><br></pre></td></tr></table></figure><p>最小二乘法仅可解决凸函数的问题，并对于高阶函数不易用，<br>而且对于多元回归的函数，矩阵可能无法求逆，因为其可能是不满秩的(奇异矩阵/非正定矩阵)</p><p>故我们通过极大似然法+梯度下降法进行求解</p>]]></content>
      
      
      <categories>
          
          <category> 🍉Book </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>🍉Book-2章-模型评估与选择</title>
      <link href="/2024/05/16/%F0%9F%8D%89Book-2%E7%AB%A0-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%B8%8E%E9%80%89%E6%8B%A9/"/>
      <url>/2024/05/16/%F0%9F%8D%89Book-2%E7%AB%A0-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%B8%8E%E9%80%89%E6%8B%A9/</url>
      
        <content type="html"><![CDATA[<h1 id="术语名词"><a href="#术语名词" class="headerlink" title="术语名词"></a>术语名词</h1><p>1.泛化误差与经验误差</p><blockquote><p>泛化误差：在“未来”样本上的误差</p><p>经验误差：在训练集上的误差，亦称“训练误差”</p></blockquote><p>训练集样本数越接近数据集数量，经验误差就越小。<br>但是经验误差越小，模型效果就越好吗？</p><p>请注意，我们是为了得到泛化能力强的模型，而<strong>经验误差≠泛化误差</strong></p><p>经验误差很小，会使模型学习到训练样本中的许多<strong>无用特征</strong>，导致<strong>泛化能力变弱</strong><br>我们称其为<strong>过拟合</strong>(overfitting)</p><p>而与之相对的概念，我们称为<strong>欠拟合</strong>(underfitting)，其表示的就是模型<strong>没有很好的学习</strong>到训练样本上的特征，从而也导致<strong>泛化能力变弱</strong></p><p>2.过拟合与欠拟合</p><blockquote><p>过拟合：模型在训练数据上表现得过于复杂，以至于在未见过的数据上表现不佳。<br>欠拟合：模型在训练数据上表现得过于简单，无法捕捉到数据的内在结构和模式。</p></blockquote><p><strong>出现原因</strong>：<br>1.出现<strong>欠拟合</strong>的情况，一般是由于<u>样本特征少</u>，<u>模型复杂度低</u>等</p><p>2.出现<strong>过拟合</strong>的情况，一般是由于<u>样本数量少、噪声多</u>，<u>模型复杂度过高</u>等</p><p>经验误差就是<strong>训练程度</strong>的体现，<u>经验误差越小则训练程度越强</u><br>所以现在，我们可以得出训练程度<strong>不能过大也不能过小</strong>的结论</p><p>那我们能找到一个<strong>最佳方案</strong>得出<strong>最佳的训练程度</strong>吗🤔</p><blockquote><p>答案是———————-&gt;不能🙅‍</p></blockquote><p><strong>原因</strong>是：<br>对于千禧年七大数学问题之——“P=NP”问题，只要我们相信”P≠NP”，就无法找出最优解</p><p>但是我们依然有相应的解决方法，用于欠拟合与过拟合的问题<br>此处的解决方法我们留待以后解决……</p><p>好了，回归本章主题—模型评估与选择</p><p>对于<strong>模型的选择</strong>，我们有三个<strong>关键问题</strong>：</p><blockquote><p>如何获得<strong>测试集</strong>？———&gt;<u>评估方法</u></p><p>如何评价<strong>性能</strong>优劣？———&gt;<u>性能度量</u></p><p>如何判断模型<strong>实质</strong>差别———&gt;<u>比较检验</u></p></blockquote><h1 id="1-评估方法"><a href="#1-评估方法" class="headerlink" title="1.评估方法"></a>1.评估方法</h1><p>因为我们无法得知未来数据的输出标记<br>故而需要得到<strong>测试集</strong>用来评估模型</p><p>而测试集有多种<strong>划分方法</strong>，这里我们给出<strong>以下三种</strong></p><h2 id="1-1-留出法-hold-out-："><a href="#1-1-留出法-hold-out-：" class="headerlink" title="1.1 留出法(hold-out)："></a>1.1 <strong>留出法</strong>(hold-out)：</h2><blockquote><p>将数据集<strong>直接划分</strong>为训练集和测试集</p></blockquote><p>留出法：对数据集的<strong>划分方法</strong>会影响模型结果；训练集和测试集的<strong>数据分布</strong>必须保持一致；测试集过大会使模型拟合效果变差，太小会使得测试估计偏小；有一些数据可能从未被训练过</p><p><strong>总结</strong>：</p><ol><li>保证数据分布一致性（比如分层取样）</li><li>多次重复划分 (例如: 100次随机划分)</li><li>测试集不能太大或太小（例如：1/5~1/3，其实二八分偏多）</li><li>可能遗漏数据（随机划分没取到该数据进行训练）</li></ol><h2 id="1-2-交叉验证法"><a href="#1-2-交叉验证法" class="headerlink" title="1.2 交叉验证法"></a>1.2 交叉验证法</h2><p>对于 <strong>留出法</strong>出现 可能<strong>遗漏数据</strong>（随机划分没取到该数据进行训练）的问题</p><p>我们引入<strong>新的划分方法</strong> <u>k-折交叉验证法</u> 可以有效解决该问题</p><p><img src="1.jpg" alt=""></p><p>以该图为例：</p><blockquote><p>首先将数据集D随机划分为10个子集，<br>进行十次操作，<br>每一次取其中1个子集为测试集，其余为训练集（实际也可以选取多个子集为测试集）<br>将结果做平均处理</p></blockquote><p>而对于再划分子集的阶段，将测试集中只留有一个数据的方法叫做<strong>留一法</strong><br>留一法，使得<strong>训练集</strong>极大地逼近了真实模型，但是却让<strong>测试误差变得很大</strong></p><p><strong>优缺点</strong>：<br>从而我们能得出，尽管交叉检验法保证了<u>所有的数据均被训练</u>，<br>但仍然存在<u>受限于样本大小</u>的问题；</p><p>并且对于<u>较大的k值</u>，会使得<u>计算成本显著增加</u>；</p><p>而且对于<u>子集的划分</u>，仍然是一个难题，如果测试集和训练集之间的划分不够随机或不够独立，可能会导致数据泄露，影响模型评估的准确性。</p><h2 id="1-3-自助法"><a href="#1-3-自助法" class="headerlink" title="1.3 自助法"></a>1.3 自助法</h2><p><img src="2.jpg" alt=""></p><p>“自助法”(bootstrapping)<br>基于==放回取样== 亦称“可重复采样”</p><p>故其可以使最终<U>训练集</U>的样本个数=<U>数据集</U>的样本个数，<br>我们记数据集的样本个数为m，<br>则由<U>洛必达法则</U>可得出 未被取出即未进行训练的样本，<br>我们称为==包外估计==(out-of-bag estimate)的占比为：</p><script type="math/tex; mode=display">\lim _ { m \rightarrow \infty } ( 1 - \frac { 1 } { m } ) ^ { m } \rightarrow \frac { 1 } { e } \approx 0 . 3 6 8</script><p>我们将其作为训练集即可</p><p><strong>优缺点</strong>：</p><p><strong>优点</strong>：<br>自助法在数据集较小、难以有效划分训练/测试集时很有用，<br>自助法能从初始数据集中产生多个不同的训练集,这对==集成学习==等方法有很大的好处。</p><p><strong>缺点</strong>：<br>自助法产生的数据集改变了初始数据集的分布，这会引入估计偏差。但是通过增加数据划分的次数，就可以缓解该影响。</p><h2 id="1-4-调参与验证集"><a href="#1-4-调参与验证集" class="headerlink" title="1.4 调参与验证集"></a>1.4 调参与验证集</h2><p>在模型评估与选择的过程中，我们既要选择学习算法，还要对算法的参数进行设定</p><p>训练过程中的参数分为<strong>两种</strong>：</p><ul><li>算法参数：亦称“超参数”，由人工设定</li><li>模型参数：由训练集训练而成</li></ul><h2 id="1-5-重新训练"><a href="#1-5-重新训练" class="headerlink" title="1.5 重新训练"></a>1.5 重新训练</h2><p><strong>重新训练</strong>：在调整和优化模型之后，可能需要使用整个数据集（包括之前划分的训练集和测试集）重新训练模型，以利用所有可用数据来提高模型的性能。</p><p>故之所以<strong>划分训练集和测试集</strong>，仅仅是为了选定==算法==的<strong>种类</strong>和<strong>参数</strong><br>当我们确定使用该算法后，我们应将<strong>整个数据集</strong>放入该算法进行训练，从而得到<strong>模型的参数</strong></p><h1 id="2-性能度量"><a href="#2-性能度量" class="headerlink" title="2.性能度量"></a>2.性能度量</h1><h2 id="2-1-错误率和精度"><a href="#2-1-错误率和精度" class="headerlink" title="2.1 错误率和精度"></a>2.1 错误率和精度</h2><p>错误率定义：</p><script type="math/tex; mode=display">E(f;D)=\frac{1}{m}\sum_{i=1}^{m}\mathbb{I}\left(f\left(\boldsymbol{x}_{i}\right)\neq y_{i}\right)</script><p>精度定义：</p><script type="math/tex; mode=display">\begin{aligned}\operatorname{acc}(f;D)&=\quad\frac{1}{m}\sum_{i=1}^{m}\mathbb{I}\left(f\left(\boldsymbol{x}_{i}\right)=y_{i}\right)\\&=\quad1-E(f;D) \end{aligned}</script><p>然而对于不同的任务需求，仅仅用错误率和精度是不够的，故引出<code>查准率、查全率、F1</code>的概念</p><h2 id="2-2-查准率、查全率、F1"><a href="#2-2-查准率、查全率、F1" class="headerlink" title="2.2 查准率、查全率、F1"></a>2.2 查准率、查全率、F1</h2><h3 id="二分类任务："><a href="#二分类任务：" class="headerlink" title="二分类任务："></a>二分类任务：</h3><pre><code>现有一瓜田含10000个瓜，其中有100个好瓜，利用学习器挑瓜查准率：即准确率（precision），如挑出瓜中好瓜的比例查全率：即召回率（recall），如所有好瓜中被挑出的比例F1-score：即查准率与查全率的调和平均</code></pre><p>在选瓜任务中我们的目标是：</p><ol><li>在挑出来的瓜中尽可能都是好瓜</li><li>瓜田中的好瓜尽可能多地被挑出来<br>很直观的可以感受到查全率越大(如挑出越多的瓜，好瓜被挑出的比例也就越大），查准率就会越低</li></ol><p>==混淆矩阵==：</p><p><img src="3.png" alt=""></p><p>其中查准率P和查全率R的定义为：</p><script type="math/tex; mode=display">P=\frac{TP}{TP+FP}</script><script type="math/tex; mode=display">R=\frac{TP}{TP+FN}</script><p>F1即综合考虑两者效果:</p><script type="math/tex; mode=display">\frac1{F1}=\frac12\cdot\left(\frac1P+\frac1R\right)</script><h3 id="多分类任务："><a href="#多分类任务：" class="headerlink" title="多分类任务："></a>多分类任务：</h3><h2 id="2-3-ROC与AUC"><a href="#2-3-ROC与AUC" class="headerlink" title="2.3 ROC与AUC"></a>2.3 ROC与AUC</h2><h1 id="3-比较检验"><a href="#3-比较检验" class="headerlink" title="3.比较检验"></a>3.比较检验</h1>]]></content>
      
      
      <categories>
          
          <category> 🍉Book </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>🍉Book-1章-绪论</title>
      <link href="/2024/05/15/%F0%9F%8D%89Book-1%E7%AB%A0-%E7%BB%AA%E8%AE%BA/"/>
      <url>/2024/05/15/%F0%9F%8D%89Book-1%E7%AB%A0-%E7%BB%AA%E8%AE%BA/</url>
      
        <content type="html"><![CDATA[<h1 id="本书的使用："><a href="#本书的使用：" class="headerlink" title="本书的使用："></a>本书的使用：</h1><p><img src="1.png" alt=""><br>第1章-绪论</p><h2 id="计算学习理论"><a href="#计算学习理论" class="headerlink" title="计算学习理论"></a>计算学习理论</h2><p><strong>概率近似正确</strong> 模型：<strong>PAC</strong> (Probably Approximate Correct)</p><p>公式：<script type="math/tex">P ( | f ( x ) - y | \leq \epsilon ) \geq 1 - \delta</script></p><p>其中 f 表示模型，y表示真相，x为样本</p><p><strong>公式分析</strong>：</p><p>其中$ | f ( x ) - y | \leq \epsilon$  用于计算模型的误差，判断模型的优劣</p><p>由于模型基于不同的算法和数据是不唯一的</p><p>故用<script type="math/tex">P ( ...... ) \geq 1 - \delta</script> 表示取得该模型的概率</p><p>故当<script type="math/tex">\delta=0，\epsilon=0</script>时，即表示每次都取到最优解的模型</p><p>这时就出现了P=NP的问题</p><p>只要我们相信P≠NP，那么就不可能每次都取到最优模型</p><blockquote><p>P=NP问题是计算机科学中的一个著名未解之谜，它询问的是两个问题类别——P类问题和NP类问题——是否相等。P类问题是指那些可以被快速解决的计算问题，即存在一个多项式时间算法来解决这些问题。NP类问题则是指那些虽然可能很难快速解决，但如果给出一个解决方案，我们可以快速验证这个解决方案是否正确的问题。</p><p>简单来说，P=NP问题问的是：所有可以快速验证答案的问题，是否都可以快速解决？</p></blockquote><h2 id="术语名词"><a href="#术语名词" class="headerlink" title="术语名词"></a>术语名词</h2><p>1.示例 = 特征向量，样本</p><ul><li>名词解释:<code>即对某个事件或者对象的 全局 描述</code></li><li>构成元素:<code>多组(特征:特征值)</code></li><li>样本 要根据上下文来判断含义</li></ul><p>2.特征 = 属性</p><ul><li>名词解释：<code>即对某个事件或对象的一个 具体 特征的描述</code></li></ul><p>3.样本空间 = 属性空间 = 输入空间</p><ul><li>名词解释：<code>即特征张成的空间，空间中每个点对应一个特征向量即样本</code></li></ul><p>4.数据集，训练集，测试集</p><ul><li>数据集=训练集+测试集（一般二八分，训练集更多）</li></ul><p>数据集一般这样表示：</p><script type="math/tex; mode=display">D =\left\{x_{ 1 },x_{2},\ldots,x_{ m }\right\}</script><p>由m个样本X构成，每个样本有相同的d个特征，即样本的维数为d</p><p>5.样例，标记，标记空间</p><ul><li>样例=样本+标记</li></ul><p><strong>标记</strong>：即想预测的结果的 实际信息，比如想预测瓜的好坏，实际样本中的信息为”好瓜”/“坏瓜”，</p><p>一般这样表示：</p><script type="math/tex; mode=display">( x _ { i } , y _ { i } )</script><p><strong>标记空间</strong> or <strong>输出空间</strong>：所有标记的集合</p><p>6.假设空间，版本空间</p><pre><code>假设：学得模型关于数据的潜在规律真实or真相：潜在规律本身假设空间：所有假设构成的集合版本空间：与训练集一致的假设构成的集合，由一个或多个假设空间的子集构成</code></pre><p>……</p><h2 id="基本假设"><a href="#基本假设" class="headerlink" title="基本假设"></a>基本假设</h2><p>我们知道训练出的模型是为了对<strong>未知数据</strong>进行结果预测</p><p>但是为什么模型可以对未知数据进行预测呢？</p><p>这里我们引出了机器学习的基本假设。</p><h3 id="1-未知分布D"><a href="#1-未知分布D" class="headerlink" title="1.未知分布D"></a>1.未知分布D</h3><blockquote><p>通常假设样本空间中全体样本服从一个未知“分布” D</p><p>此处的“分布”指的是概率论中的概率分布</p></blockquote><p>我们假设数据（包括 源数据集 和 未知数据）背后满足某种规律，</p><p>即数据的<strong>采样</strong>来自一个未知的、潜在的 <strong>分布</strong>D</p><h3 id="2-独立同分布（i-i-d）"><a href="#2-独立同分布（i-i-d）" class="headerlink" title="2.独立同分布（i.i.d）"></a>2.独立同分布（i.i.d）</h3><p>我们获得的每个样本都是独立地从这个分布上采样获得的，即“独立同分布”（简称i.i.d）</p><p>或者说 所有样本都是独立同分布的</p><p>一般而言，训练样本越多，我们得到的关于D的信息也越多</p><h3 id="3-一些思考"><a href="#3-一些思考" class="headerlink" title="3.一些思考"></a>3.一些思考</h3><p>在现实生活中，大多数样本之间不是独立同分布的，而是相互影响的。</p><p>比如说：在淘宝上 买衣服的人 和 买裤子的人，它们之间可能来自不同的分布，可能买衣服的人推荐买裤子的人来淘宝购物。</p><p>所以现在在机器学习的前沿领域，</p><p><strong>如何突破独立同分布的限制</strong> 是一个重大课题</p><h2 id="归纳偏好"><a href="#归纳偏好" class="headerlink" title="归纳偏好"></a>归纳偏好</h2><blockquote><p>归纳偏好对应了学习算法本身所做出的关于“什么样的模型更好”的假设</p></blockquote><p>对假设空间 筛选 后所得到的 版本空间中 可能有多个假设<br>这些假设都能够匹配训练集中的训练样本</p><p>而如何对版本空间中的假设进行选择呢？🤔</p><p>这里引入一个原则or方法论：</p><p><strong>奥卡姆剃刀</strong>：</p><blockquote><p>若非必要勿增实体</p><p>选取多个假设中最简单的。</p></blockquote><p>但是其实感觉没啥用，因为”简单“的定义难以量化。</p><blockquote><p>一个“随机乱猜”的算法有可能优于精心选择的算法</p></blockquote><p><strong>“没有免费的午餐”（NFL）定理：</strong></p><pre><code>任意算法的“训练集外误差”相等，即不同算法的误差期望相同，无绝对意义上的更优算法。</code></pre><p><img src="2.jpg" alt=""></p><p>所以 <strong>不能摆脱具体问题</strong> 谈论算法的<strong>优劣</strong></p><p><strong>实际上</strong>：还是看<strong>测试集</strong>再模型上的效果，以及结合<strong>特定领域的需求</strong>对模型进行选择</p><h2 id="机器学习分类"><a href="#机器学习分类" class="headerlink" title="机器学习分类"></a>机器学习分类</h2><h3 id="1-监督学习-有导师学习"><a href="#1-监督学习-有导师学习" class="headerlink" title="1.监督学习-有导师学习"></a>1.监督学习-有导师学习</h3><p><strong>样本有标记</strong></p><p>1.1 <strong>分类</strong>问题-预测 <strong>离散值</strong></p><ul><li><p>二分类-正类/负类(反类)</p><p><code>一般取值0/1，文本可通过 特征工程 转换为数值型变量</code></p><p><code>一般假设正类和负类是可交换的</code></p></li><li><p>多分类<br><code>涉及 多类别 的预测输出</code></p><p><code>可以转换成二分类问题</code></p></li></ul><p>1.2 <strong>回归</strong>问题-预测 <strong>连续值</strong></p><pre><code>预测结果 ∈ R</code></pre><h3 id="2-非监督学习-无导师学习"><a href="#2-非监督学习-无导师学习" class="headerlink" title="2.非监督学习-无导师学习"></a>2.非监督学习-无导师学习</h3><p><strong>样本无标记</strong></p><p>2.1 <strong>聚类</strong>算法</p><ul><li><p>离散型变量的分类、分组别</p></li><li><p>连续型变量的统计个数，进行密度估计</p><p>  了解数据内在规律</p></li></ul><p>2.2 <strong>降维</strong>算法</p><ul><li>如PCA主成分分析等</li></ul><p>……</p><h2 id="机器学习的发展"><a href="#机器学习的发展" class="headerlink" title="机器学习的发展"></a>机器学习的发展</h2><ul><li><p><strong>符号主义</strong>：源于数学逻辑，产生明确的概念表示</p><p>  符号主义认为人工智能源于数理逻辑后来又发展了 启发式算法&gt;专家系统&gt;知识工程理论与技术</p><p>  主要方向：决策树 和 基于逻辑的学习</p><pre><code>  决策树-&gt;模拟人类对概念的判定树形过程  基于逻辑的学习--&gt;典型代表：归纳逻辑程序设计(ILP)</code></pre></li><li><p><strong>连接主义</strong>：基于神经网络</p><p>  算法复杂度高，假设空间大，且参数设置缺乏理论指导</p><p>  经典代表：BP反向传播算法</p></li><li><p><strong>统计学习</strong>：支持向量机(SVM)，核方法</p><p>  与连接主义关系密切</p></li><li><p><strong>深度学习</strong>：早期连接主义的衍生，基于神经网络，现阶段很流行</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 🍉Book </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>定义类和方法</title>
      <link href="/2024/05/14/%E5%AE%9A%E4%B9%89%E7%B1%BB%E5%92%8C%E6%96%B9%E6%B3%95/"/>
      <url>/2024/05/14/%E5%AE%9A%E4%B9%89%E7%B1%BB%E5%92%8C%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<p>对象是实例化的类，所以对象也叫做实例。</p><p>一个实例(对象)由 <strong>属性</strong> (变量or数据)和 <strong>方法</strong> (行为)构成</p><p>所以属性和方法叫做对象的 <strong>成员</strong></p><p>对象的  属性  叫做 成员变量or实例变量(这俩也有点区别)</p><p>对象的  方法  叫做 成员方法</p><hr><p>在面向对象编程中，成员变量和实例变量通常指的是相同的概念，但它们的使用和含义略有不同，具体取决于上下文：</p><ol><li><p><strong>成员变量</strong>：</p><ul><li>成员变量是类的一部分，它们定义了类的状态或属性。</li><li>每个成员变量都是类的蓝图，用于创建对象时存储数据。</li><li>成员变量可以是静态的或非静态的（实例变量）。</li></ul></li><li><p><strong>实例变量</strong>（非静态变量）：</p><ul><li>实例变量是成员变量的一种，它们属于类的特定实例（对象）。</li><li>每个实例变量的副本都存储在创建的对象中，这意味着每个对象都有自己的实例变量副本。</li><li>实例变量的值对于每个对象都是独立的，一个对象的实例变量改变不会影响另一个对象的相应变量。</li></ul></li><li><p><strong>静态变量</strong>（类变量）：</p><ul><li>静态变量也是成员变量的一种，但它们不属于任何特定的实例。</li><li>静态变量只有单一的副本，所有类的实例共享这个副本。</li><li>静态变量通常用于存储类级别的数据，如配置信息或计数器。</li></ul></li></ol><p>以下是一些关键点的对比：</p><ul><li><strong>作用域</strong>：实例变量属于对象，每个对象都有其独立的副本；静态变量属于类，所有实例共享同一个副本。</li><li><strong>生命周期</strong>：实例变量随对象的创建而存在，随对象的销毁而消失；静态变量随类的加载而存在，随程序结束或类被卸载而消失。</li><li><strong>访问</strong>：实例变量可以通过对象的引用访问；静态变量可以通过类名直接访问，也可以通过对象引用访问。</li></ul><p>下面是一个简单的Java类示例，展示了实例变量和静态变量的使用：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Car</span> &#123;</span><br><span class="line">    <span class="comment">// 实例变量，每个Car对象都有自己的颜色和速度</span></span><br><span class="line">    String color;</span><br><span class="line">    <span class="type">int</span> speed;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 静态变量，所有Car对象共享同一个制造数量</span></span><br><span class="line">    <span class="keyword">static</span> <span class="type">int</span> <span class="variable">manufacturingCount</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">Car</span><span class="params">(String color)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.color = color;</span><br><span class="line">        <span class="comment">// 每创建一个Car对象，制造数量增加</span></span><br><span class="line">        manufacturingCount++;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">drive</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="comment">// 实例方法，影响特定对象的速度</span></span><br><span class="line">        speed += <span class="number">10</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="type">int</span> <span class="title function_">getManufacturingCount</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="comment">// 静态方法，返回所有Car对象共享的制造数量</span></span><br><span class="line">        <span class="keyword">return</span> manufacturingCount;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在这个例子中，<code>color</code> 和 <code>speed</code> 是实例变量，因为它们属于每个 <code>Car</code> 对象。而 <code>manufacturingCount</code> 是一个静态变量，因为它属于 <code>Car</code> 类本身，并且所有 <code>Car</code> 实例共享这个变量。<code>drive</code> 方法是一个实例方法，因为它操作特定 <code>Car</code> 对象的速度。<code>getManufacturingCount</code> 是一个静态方法，因为它返回的是类级别的信息。</p><hr><p>在Java中，类（Class）是用来创建对象的模板或蓝图。类本身不直接持有数据，但类定义中可以包含成员变量（也称为字段或属性），这些成员变量是用来存储数据的。当你根据类创建一个对象（实例）时，每个对象都会有自己的成员变量副本，这些副本中存储的就是数据。</p><p>例如，假设有一个名为 <code>Person</code> 的类：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Person</span> &#123;</span><br><span class="line">    String name;</span><br><span class="line">    <span class="type">int</span> age;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">Person</span><span class="params">(String name, <span class="type">int</span> age)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.name = name;</span><br><span class="line">        <span class="built_in">this</span>.age = age;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 其他方法...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在这个 <code>Person</code> 类中，<code>name</code> 和 <code>age</code> 就是成员变量，它们可以在类的实例中存储数据。当你创建 <code>Person</code> 类的对象时：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Person</span> <span class="variable">person1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Person</span>(<span class="string">&quot;Alice&quot;</span>, <span class="number">30</span>);</span><br><span class="line"><span class="type">Person</span> <span class="variable">person2</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Person</span>(<span class="string">&quot;Bob&quot;</span>, <span class="number">25</span>);</span><br></pre></td></tr></table></figure><p><code>person1</code> 和 <code>person2</code> 都是 <code>Person</code> 类的实例，它们各自拥有自己的 <code>name</code> 和 <code>age</code> 数据。<code>person1</code> 的 <code>name</code> 是 “Alice”，<code>age</code> 是 30；而 <code>person2</code> 的 <code>name</code> 是 “Bob”，<code>age</code> 是 25。</p><p>类本身只是一个定义，它不包含数据，但是它定义了如何创建可以包含数据的对象。</p><hr><p>在面向对象编程（OOP）中，成员是类的一部分，它代表了类的特性（属性）或行为（方法）。成员是构成类的基本元素，它们定义了类的功能和数据结构。以下是成员的两种主要类型：</p><ol><li><p><strong>成员变量（属性）</strong>：</p><ul><li>成员变量是类的一部分，用于存储数据。它们是类的属性，通常用于描述对象的状态。</li><li>成员变量可以是私有的（private），这意味着它们只能被类内部的方法访问，或者可以是公有的（public），这意味着它们可以被任何其他类访问。</li><li>成员变量可以有默认的访问修饰符（没有显式指定），这通常是包级私有的（即同一个包内的其他类可以访问）。</li></ul></li><li><p><strong>成员方法（行为）</strong>：</p><ul><li>成员方法是类的一部分，定义了对象的行为。它们是类的操作，用于描述对象可以执行的动作。</li><li>成员方法可以有不同的访问修饰符，如public、private或protected，这决定了它们可以被谁调用。</li><li>方法还可以是静态的（static），这意味着它们属于类而不是类的实例，并且可以在不创建类实例的情况下被调用。</li></ul></li></ol><p>除了成员变量和成员方法，类的成员还可以包括：</p><ul><li><strong>构造方法</strong>：特殊的方法，用于创建类的对象。它们的名字必须与类名相同，并且没有返回类型。</li><li><strong>静态初始化块</strong>：用于初始化静态变量的代码块，它在类加载时执行一次。</li><li><strong>实例初始化块</strong>：用于初始化非静态变量的代码块，它在每次创建类的新实例时执行。</li><li><strong>内部类</strong>：定义在另一个类内部的类，它可以访问外部类的成员，包括私有成员。</li></ul><p>成员变量和方法的可见性和行为可以通过使用不同的访问修饰符和非访问修饰符来控制。例如：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ExampleClass</span> &#123;</span><br><span class="line">    <span class="comment">// 成员变量</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> privateVar;</span><br><span class="line">    <span class="keyword">protected</span> <span class="type">int</span> protectedVar;</span><br><span class="line">    <span class="type">int</span> packageVar; <span class="comment">// 默认访问修饰符，也称为包级私有</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> publicVar;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 构造方法</span></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">ExampleClass</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="comment">// 构造逻辑</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 成员方法</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">publicMethod</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="comment">// 方法逻辑</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">privateMethod</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="comment">// 私有方法逻辑</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 静态方法</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">staticMethod</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="comment">// 静态方法逻辑</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 实例初始化块</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">// 实例初始化逻辑</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 静态初始化块</span></span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        <span class="comment">// 静态初始化逻辑</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在这个例子中，<code>ExampleClass</code> 包含了不同类型的成员，包括私有和公有的成员变量，一个构造方法，公有和私有的成员方法，以及静态方法。静态初始化块和实例初始化块分别用于初始化静态成员和非静态成员。</p><hr><p>在Java语言中，<code>this</code> 是一个特殊的关键字，它指向当前对象的引用。每个对象都有一个隐式的 <code>this</code> 引用，指向它自己。以下是 <code>this</code> 关键字的一些常见用法：</p><ol><li><p><strong>区分成员变量和局部变量</strong>：当局部变量名与成员变量名相同时，可以使用 <code>this</code> 关键字来区分它们。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyClass</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> number;</span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">MyClass</span><span class="params">(<span class="type">int</span> number)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.number = number; <span class="comment">// 使用 this 来引用成员变量</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><strong>在构造函数中调用另一个构造函数</strong>：可以使用 <code>this()</code> 来调用同一个类中的另一个构造函数。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyClass</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> number;</span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">MyClass</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>(<span class="number">0</span>); <span class="comment">// 默认构造函数调用带参数的构造函数</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">MyClass</span><span class="params">(<span class="type">int</span> number)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.number = number;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><strong>在方法中返回当前对象的引用</strong>：有时，方法需要返回调用该方法的对象的引用，这时可以使用 <code>this</code>。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyClass</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> MyClass <span class="title function_">getNext</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="comment">// 一些逻辑...</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">this</span>; <span class="comment">// 返回当前对象的引用</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><strong>在参数中传递当前对象</strong>：当需要将当前对象作为参数传递给另一个方法时，可以使用 <code>this</code>。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyClass</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">doSomething</span><span class="params">(MyClass other)</span> &#123;</span><br><span class="line">        other.copy(<span class="built_in">this</span>); <span class="comment">// 将当前对象作为参数传递</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">copy</span><span class="params">(MyClass other)</span> &#123;</span><br><span class="line">        <span class="comment">// 复制逻辑...</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><strong>在匿名类和内部类中引用外部类的实例</strong>：在匿名类或内部类中，可以使用 <code>this</code> 关键字来引用外部类的实例。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">OuterClass</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">doSomething</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Thread</span>(<span class="keyword">new</span> <span class="title class_">Runnable</span>() &#123;</span><br><span class="line">            <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">                OuterClass.<span class="built_in">this</span>.doWork(); <span class="comment">// 调用外部类的 doWork 方法</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;).start();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">doWork</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="comment">// 工作逻辑...</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><strong>在重载方法中使用</strong>：当类中有多个同名方法但参数列表不同时，可以使用 <code>this</code> 调用其他重载的方法。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyClass</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">print</span><span class="params">(<span class="type">int</span> number)</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;Number: &quot;</span> + number);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">print</span><span class="params">(String text)</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;Text: &quot;</span> + text);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">printAll</span><span class="params">(<span class="type">int</span> number, String text)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.print(number); <span class="comment">// 调用第一个 print 方法</span></span><br><span class="line">        <span class="built_in">this</span>.print(text); <span class="comment">// 调用第二个 print 方法</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><p><code>this</code> 关键字是Java中一个非常有用的工具，它允许程序员在各种情况下引用当前对象。</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Hexo搭建实遇问题</title>
      <link href="/2024/05/13/Hexo%E6%90%AD%E5%BB%BA%E5%AE%9E%E9%81%87%E9%97%AE%E9%A2%98/"/>
      <url>/2024/05/13/Hexo%E6%90%AD%E5%BB%BA%E5%AE%9E%E9%81%87%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h1 id="1-spawn-failed问题"><a href="#1-spawn-failed问题" class="headerlink" title="1.spawn_failed问题"></a>1.spawn_failed问题</h1><h2 id="原因分析："><a href="#原因分析：" class="headerlink" title="原因分析："></a>原因分析：</h2><p>其实出现这个问题，很大可能是因为https和http的proxy的对应的分别是https和http开proxy server，</p><p>而https的proxy server可能无法正常工作。</p><h2 id="解决办法："><a href="#解决办法：" class="headerlink" title="解决办法："></a>解决办法：</h2><p>修改_config.yml文件的deploy部分，将https 修改为http url 或者 设置为git url, 配置为https oauth2 加token</p><ul><li>设置为git url(推荐) 亲测有效</li></ul><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">deploy:</span><br><span class="line">    type: git</span><br><span class="line">    repo: git@github.com:your_github_id/your_github_id.github.io.git</span><br><span class="line">    branch: gh-pages</span><br></pre></td></tr></table></figure><h1 id="2-头像无法显示问题"><a href="#2-头像无法显示问题" class="headerlink" title="2.头像无法显示问题"></a>2.头像无法显示问题</h1><h2 id="原因分析：-1"><a href="#原因分析：-1" class="headerlink" title="原因分析："></a>原因分析：</h2><p>不明原因，猜测是路径问题</p><h2 id="解决方法1："><a href="#解决方法1：" class="headerlink" title="解决方法1："></a>解决方法1：</h2><ol><li>将想要显示的头像图片存入本地文件夹</li><li>在根目录下进入git bash使用hexo g和hexo d上传代码到github仓库</li><li>在github仓库找到该图片，鼠标右键复制图片链接</li><li>修改主题配置文件，如我修改的为config.butterfly.yml文件</li></ol><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Avatar (頭像)</span></span><br><span class="line"><span class="attr">avatar:</span></span><br><span class="line">  <span class="attr">img:</span> <span class="string">输入你复制的图片链接</span></span><br><span class="line">  <span class="comment"># effect为true 则鼠标放于图片上，会使图片一直旋转</span></span><br><span class="line">  <span class="attr">effect:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure><h2 id="解决方法2："><a href="#解决方法2：" class="headerlink" title="解决方法2："></a>解决方法2：</h2><p>更改默认头像路径</p><p>默认路径：<code>&quot;C:\Users\陈荣伟\Desktop\Blog\Hexo-blog\blog\themes\butterfly\source\img\friend_404.gif&quot;</code></p><p>把需要的 头像 名称改为<code>friend_404.gif</code>，把<code>friend_404.gif</code> 重命名 成别的即可</p><p>_config.butterfly.yml内的配置文件</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Replace Broken Images (替换无法显示的图片)</span></span><br><span class="line"><span class="attr">error_img:</span></span><br><span class="line">  <span class="attr">flink:</span> <span class="string">/img/friend_404.gif</span></span><br><span class="line">  <span class="attr">post_page:</span> <span class="string">/img/404.jpg</span></span><br></pre></td></tr></table></figure><h1 id="3-本地预览正常，但部署到GitHub-网站背景图片不加载"><a href="#3-本地预览正常，但部署到GitHub-网站背景图片不加载" class="headerlink" title="3.本地预览正常，但部署到GitHub 网站背景图片不加载"></a>3.本地预览正常，但部署到GitHub 网站背景图片不加载</h1><h2 id="解决方法："><a href="#解决方法：" class="headerlink" title="解决方法："></a>解决方法：</h2><ol><li>分清背景图片是放在本地还是别处？</li><li>记得用图片的网络链接，确保图片地址没有错误。</li><li>然后<strong>清除浏览器缓存</strong>再试试</li></ol><h2 id="hexo-clean命令"><a href="#hexo-clean命令" class="headerlink" title="hexo clean命令"></a>hexo clean命令</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo clean</span><br></pre></td></tr></table></figure><p>清除缓存文件 <code>db.json</code> 和已生成的静态文件 <code>public</code>。</p><ul><li>网站显示异常时可以执行这条命令试试。</li></ul><p>接着依次运行代码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo g</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo d</span><br></pre></td></tr></table></figure><h2 id="终极方法"><a href="#终极方法" class="headerlink" title="终极方法"></a>终极方法</h2><p>删除<code>.deploy_git</code>和<code>public</code>文件</p><h1 id="4-插入图片的显示问题"><a href="#4-插入图片的显示问题" class="headerlink" title="4.插入图片的显示问题"></a>4.插入图片的显示问题</h1><p>参考文章：</p><p><a href="https://blog.csdn.net/2301_77285173/article/details/130189857">在hexo博客中插入图片的方法_hexo插入图片-CSDN博客</a></p><p>插入图片的方法<br>在完成了博客搭建、发布文章后，如果我们想在文章中插入图片，该怎么做呢？</p><p>如果图片保存在本地</p><h2 id="方法一：全局资源文件夹"><a href="#方法一：全局资源文件夹" class="headerlink" title="方法一：全局资源文件夹"></a>方法一：全局资源文件夹</h2><p>即，将所有文章的资源统一用一个全局资源文件夹管理。</p><p>此方法的优点是比较简便，并且当多篇文章需要引用同一资源时，也比较方便。</p><p>缺点是当文章很多时，各个文章的图片都在同一文件夹，不便管理。</p><p><strong>具体方法</strong>：<br>在hexo文件夹下的source目录下，新建一个文件夹叫images(名字随意)，将要插入的图片放在该文件夹中。<br>md文档内，使用<code>![图片](图片链接地址)</code>的格式，圆括号内的链接地址写<code>(/images/name.jpeg)</code>。<br>这里的 / 指的是根目录，对于hexo，资源文件的根目录就是source(可以在config文件里修改资源的根目录)</p><p>例如，在md文档中写：<code>![图片](/images/20.jpeg &quot;甘雨&quot;)</code><br>同时将“20.jpeg”这个图片文件放在hexo文件夹<code>/source/images</code>下，则图片可以上传到博客。</p><h2 id="方法二：文章资源文件夹"><a href="#方法二：文章资源文件夹" class="headerlink" title="方法二：文章资源文件夹"></a>方法二：文章资源文件夹</h2><p>即，对于每篇文章，使用一个文件夹管理资源。</p><p>此方法的优点是，当文章很多时，便于结构化管理。</p><p>缺点是，比方法一麻烦一点。</p><p><strong>具体方法</strong>：</p><p>2.1 修改hexo文件夹中的_config.yml文件，如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">post_asset_folder:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">marked:</span></span><br><span class="line">  <span class="attr">prependRoot:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">postAsset:</span> <span class="literal">true</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>2.2 在终端cd到hexo文件夹，<code>hexo new 文章名</code>命令创建一篇新文章，此时会在hexo文件夹的source目录下，自动创建一个文件夹和文章名.md文件。</p><p><strong>注</strong>：如果文章名中有空格，务必将整个文章名用双引号引起来。如果文章名中没有空格，可以加双引号，也可以不加。</p><p>例如，执行hexo new “如何发布文章到hexo博客上”，如下：</p><p>会在<code>source/_post</code>文件夹下生成一个”如何发布文章到hexo博客上.md”文件。如下：</p><p>可以看到，同时还生成了一个同名的资源文件夹。</p><p>2.3 我们可以将所有与该文章有关的资源（包括图片）放在这个关联文件夹中<br>2.4 通过<strong>相对路径</strong>来引用图片资源。</p><p>例如，将“1.jpeg”这个图片资源放在该文件夹中，并在.md文件中像这样引用图片：<code>![图片](1.jpeg)</code>，这个方法在资源较多时方便管理。</p><p>另附Typora编辑器中不显示图片的解决方案：<br>安装下面的插件，可以使Typora等Markdown编辑器预览以及Hexo发布预览时，均能正常显示图片。<br><code>npm install hexo-asset-img --save</code><br>这样，如果你使用Typora编辑markdown文档，在typora内也可以显示图片了。</p><h1 id="5-4000端口占用问题"><a href="#5-4000端口占用问题" class="headerlink" title="5.4000端口占用问题"></a>5.4000端口占用问题</h1><h2 id="查看端口"><a href="#查看端口" class="headerlink" title="查看端口:"></a>查看端口:</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">netstat -ano</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">  每一列分别对应：协议、本地地址、外部地址、状态、PID  </span><br><span class="line"></span><br><span class="line">参数详解：</span><br><span class="line">  -a            显示所有连接和侦听端口。</span><br><span class="line">  -n            以数字形式显示地址和端口号。</span><br><span class="line">  -o            显示拥有的与每个连接关联的进程 ID。</span><br></pre></td></tr></table></figure><p>注：其余参数可使用help命令查看：</p><p><code>netstat -help</code></p><p>​        查询出的端口数量很多，我们可使用findstr命令进行过滤：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">netstat -ano | findstr &quot;被占用的端口&quot;</span><br></pre></td></tr></table></figure><h2 id="释放被占用的端口："><a href="#释放被占用的端口：" class="headerlink" title="释放被占用的端口："></a><strong>释放被占用的端口</strong>：</h2><p>​      过滤出需要释放的端口后，在cmd窗口输入<code>task kill命令</code>可释放被占用的端口：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">taskkill -f -t /pid &quot;占用端口的程序的pid&quot;</span><br></pre></td></tr></table></figure><h1 id="6-网页渲染Latex问题"><a href="#6-网页渲染Latex问题" class="headerlink" title="6.网页渲染Latex问题"></a>6.网页渲染Latex问题</h1><p>修改主题配置文件<code>_config.butterfly.yml</code>：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">mathjax:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="comment"># true 表示每一頁都加載mathjax.js</span></span><br><span class="line">  <span class="comment"># false 需要時加載，須在使用的Markdown Front-matter 加上 mathjax: true</span></span><br><span class="line">  <span class="attr">per_page:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure><p>以下操作在你 hexo 博客的目录下 (不是 Butterfly 的目录):</p><ol><li>安装插件</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">npm uninstall hexo-renderer-marked --save</span><br><span class="line">npm install hexo-renderer-kramed --save</span><br></pre></td></tr></table></figure><ol><li>配置 hexo 根目录的配置文件<code>_config.yml</code></li></ol><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kramed:</span></span><br><span class="line">  <span class="attr">gfm:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">pedantic:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">sanitize:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">tables:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">breaks:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">smartLists:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">smartypants:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><h1 id="7-引入CSS文件"><a href="#7-引入CSS文件" class="headerlink" title="7.引入CSS文件"></a>7.引入CSS文件</h1><p>打开config.butterfly.yml文件</p><p>CTRL+F 搜索下面的代码，增加<code>&lt;link&gt;</code>标签即可</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">inject:</span></span><br><span class="line">  <span class="attr">head:</span></span><br><span class="line">    <span class="comment"># - &lt;link rel=&quot;stylesheet&quot; href=&quot;/xxx.css&quot;&gt;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&lt;link</span> <span class="string">rel=&quot;stylesheet&quot;</span> <span class="string">href=&quot;/css/categories_dark_fit.css&quot;&gt;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&lt;link</span> <span class="string">rel=&quot;stylesheet&quot;</span> <span class="string">href=&quot;/css/butterfly_article_double_row.css&quot;&gt;</span></span><br><span class="line">  <span class="attr">bottom:</span></span><br><span class="line">    <span class="comment"># - &lt;script src=&quot;xxxx&quot;&gt;&lt;/script&gt;</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Blog搭建 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Front-matter模板</title>
      <link href="/2024/05/12/Front-matter%E6%A8%A1%E6%9D%BF/"/>
      <url>/2024/05/12/Front-matter%E6%A8%A1%E6%9D%BF/</url>
      
        <content type="html"><![CDATA[<p><code>Front-matter</code> 是 markdown 文件最上方以<code>---</code>分隔的区域，用于指定个别档案的变数</p><ul><li>Page Front-matter 用于页面配置</li><li>Post Front-matter 用于文章页配置</li></ul><p>如果标注可选的参数，可根据自己需要添加，不用全部都写</p><p><strong>Page Front-matter：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">MARKDOWN</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">title:</span><br><span class="line">date:</span><br><span class="line">updated:</span><br><span class="line">type:</span><br><span class="line">comments:</span><br><span class="line">description:</span><br><span class="line">keywords:</span><br><span class="line">top_img:</span><br><span class="line">mathjax:</span><br><span class="line">katex:</span><br><span class="line">aside:</span><br><span class="line">aplayer:</span><br><span class="line">highlight_shrink:</span><br><span class="line">---</span><br></pre></td></tr></table></figure><div class="table-container"><table><thead><tr><th style="text-align:left">写法</th><th>解释</th></tr></thead><tbody><tr><td style="text-align:left">title</td><td>【必需】页面标题</td></tr><tr><td style="text-align:left">date</td><td>【必需】页面创建日期</td></tr><tr><td style="text-align:left">type</td><td>【必需】标籤、分类和友情链接三个页面需要配置</td></tr><tr><td style="text-align:left">updated</td><td>【可选】页面更新日期</td></tr><tr><td style="text-align:left">description</td><td>【可选】页面描述</td></tr><tr><td style="text-align:left">keywords</td><td>【可选】页面关键字</td></tr><tr><td style="text-align:left">comments</td><td>【可选】显示页面评论模块(默认 true)</td></tr><tr><td style="text-align:left">top_img</td><td>【可选】页面顶部图片</td></tr><tr><td style="text-align:left">mathjax</td><td>【可选】显示mathjax(当设置mathjax的per_page: false时，才需要配置，默认 false)</td></tr><tr><td style="text-align:left">kates</td><td>【可选】显示katex(当设置katex的per_page: false时，才需要配置，默认 false)</td></tr><tr><td style="text-align:left">aside</td><td>【可选】显示侧边栏 (默认 true)</td></tr><tr><td style="text-align:left">aplayer</td><td>【可选】在需要的页面加载aplayer的js和css,请参考文章下面的音乐 配置</td></tr><tr><td style="text-align:left">highlight_shrink</td><td>【可选】配置代码框是否展开(true/false)(默认为设置中highlight_shrink的配置)</td></tr></tbody></table></div><p><strong>Post Front-matter：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">MARKDOWN</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">title:</span><br><span class="line">date:</span><br><span class="line">updated:</span><br><span class="line">tags:</span><br><span class="line">categories:</span><br><span class="line">keywords:</span><br><span class="line">description:</span><br><span class="line">top_img:</span><br><span class="line">comments:</span><br><span class="line">cover:</span><br><span class="line">toc:</span><br><span class="line">toc_number:</span><br><span class="line">toc_style_simple:</span><br><span class="line">copyright:</span><br><span class="line">copyright_author:</span><br><span class="line">copyright_author_href:</span><br><span class="line">copyright_url:</span><br><span class="line">copyright_info:</span><br><span class="line">mathjax:</span><br><span class="line">katex:</span><br><span class="line">aplayer:</span><br><span class="line">highlight_shrink:</span><br><span class="line">aside:</span><br><span class="line">---</span><br></pre></td></tr></table></figure><div class="table-container"><table><thead><tr><th>写法</th><th>解释</th></tr></thead><tbody><tr><td>title</td><td>【必需】文章标题</td></tr><tr><td>date</td><td>【必需】文章创建日期</td></tr><tr><td>updated</td><td>【可选】文章更新日期</td></tr><tr><td>tags</td><td>【可选】文章标籤</td></tr><tr><td>categories</td><td>【可选】文章分类</td></tr><tr><td>keywords</td><td>【可选】文章关键字</td></tr><tr><td>description</td><td>【可选】文章描述</td></tr><tr><td>top_img</td><td>【可选】文章顶部图片</td></tr><tr><td>cover</td><td>【可选】文章缩略图(如果没有设置top_img,文章页顶部将显示缩略图，可设为false/图片地址/留空)</td></tr><tr><td>comments</td><td>【可选】显示文章评论模块(默认 true)</td></tr><tr><td>toc</td><td>【可选】显示文章TOC(默认为设置中toc的enable配置)</td></tr><tr><td>toc_number</td><td>【可选】显示toc_number(默认为设置中toc的number配置)</td></tr><tr><td>toc_style_simple</td><td>【可选】显示 toc 简洁模式</td></tr><tr><td>copyright</td><td>【可选】显示文章版权模块(默认为设置中post_copyright的enable配置)</td></tr><tr><td>copyright_author</td><td>【可选】文章版权模块的文章作者</td></tr><tr><td>copyright_author_href</td><td>【可选】文章版权模块的文章作者链接</td></tr><tr><td>copyright_url</td><td>【可选】文章版权模块的文章连结链接</td></tr><tr><td>copyright_info</td><td>【可选】文章版权模块的版权声明文字</td></tr><tr><td>mathjax</td><td>【可选】显示mathjax(当设置mathjax的per_page: false时，才需要配置，默认 false)</td></tr><tr><td>katex</td><td>【可选】显示katex(当设置katex的per_page: false时，才需要配置，默认 false)</td></tr><tr><td>aplayer</td><td>【可选】在需要的页面加载aplayer的js和css,请参考文章下面的音乐 配置</td></tr><tr><td>highlight_shrink</td><td>【可选】配置代码框是否展开(true/false)(默认为设置中highlight_shrink的配置)</td></tr><tr><td>aside</td><td>【可选】显示侧边栏 (默认 true)</td></tr></tbody></table></div><p>注意：我的博客根目录路径为 【D:/Blog/】，下文所说的根目录都是此路径，将用[BlogRoot]代替。</p>]]></content>
      
      
      <categories>
          
          <category> Blog搭建 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>My first blog</title>
      <link href="/2024/04/23/My-first-blog/"/>
      <url>/2024/04/23/My-first-blog/</url>
      
        <content type="html"><![CDATA[<h1 id="大事件"><a href="#大事件" class="headerlink" title="大事件"></a>大事件</h1><p>芜湖！成功部署blog！૮(˶ᵔ ᵕ ᵔ˶)ა</p><p>以后就在这上面写学习总结输出了！</p><p>之后还要完善页面渲染哈，今天就先收工啦 ૮(∪｡∪)ა｡｡｡zzzzz</p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
